{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVSn6Rda6yRM",
        "outputId": "9511a24e-badd-425e-9879-c928c9e623e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data Loaded Successfully!\n",
            "Training Data: (760, 256, 256, 1)\n",
            "Testing Data: (190, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "mask_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Masks\"\n",
        "\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "def load_data(img_folder, mask_folder):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for filename in os.listdir(img_folder):\n",
        "        img = cv2.imread(os.path.join(img_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(os.path.join(mask_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if img is not None and mask is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE) / 255.0  # Normalize\n",
        "            mask = cv2.resize(mask, IMG_SIZE) / 255.0  # Normalize\n",
        "\n",
        "            images.append(img.reshape(256, 256, 1))  # Add channel dimension\n",
        "            masks.append(mask.reshape(256, 256, 1))  # Add channel dimension\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "X, Y = load_data(data_path, mask_path)\n",
        "\n",
        "# Split into Train/Test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"✅ Data Loaded Successfully!\")\n",
        "print(\"Training Data:\", X_train.shape)\n",
        "print(\"Testing Data:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCgy7kfc6yxI",
        "outputId": "9511a24e-badd-425e-9879-c928c9e623e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data Loaded Successfully!\n",
            "Training Data: (760, 256, 256, 1)\n",
            "Testing Data: (190, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "mask_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Masks\"\n",
        "\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "def load_data(img_folder, mask_folder):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for filename in os.listdir(img_folder):\n",
        "        img = cv2.imread(os.path.join(img_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(os.path.join(mask_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if img is not None and mask is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE) / 255.0  # Normalize\n",
        "            mask = cv2.resize(mask, IMG_SIZE) / 255.0  # Normalize\n",
        "\n",
        "            images.append(img.reshape(256, 256, 1))  # Add channel dimension\n",
        "            masks.append(mask.reshape(256, 256, 1))  # Add channel dimension\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "X, Y = load_data(data_path, mask_path)\n",
        "\n",
        "# Split into Train/Test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"✅ Data Loaded Successfully!\")\n",
        "print(\"Training Data:\", X_train.shape)\n",
        "print(\"Testing Data:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3iif-G3NKjg",
        "outputId": "476507f6-fc53-4bdf-c6c5-bb7a17b958df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir4bsvJDOAMV",
        "outputId": "f2753707-0bb2-484c-a7de-5317068cb3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Path: ['Stroke', 'Normal']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/\"\n",
        "print(\"Dataset Path:\", os.listdir(data_path))  # Check if files are accessible\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFkuGijVP2dW",
        "outputId": "00f2c703-8834-414d-feb6-ee279969639a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contents of brain_data_organised: ['Stroke', 'Normal']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/\"\n",
        "\n",
        "# List contents of brain_data_organised\n",
        "print(\"Contents of brain_data_organised:\", os.listdir(data_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vDv1YSAiQPyL",
        "outputId": "2d53da53-f627-43ad-ce56-e11941b98265"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/brain_stroke/brain_data_organised/Normal'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-316faccd4d67>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstroke_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stroke\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Normal Images:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stroke Images:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/brain_stroke/brain_data_organised/Normal'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/brain_data_organised/\"\n",
        "normal_path = os.path.join(data_path, \"Normal\")\n",
        "stroke_path = os.path.join(data_path, \"Stroke\")\n",
        "\n",
        "print(\"Normal Images:\", len(os.listdir(normal_path)))\n",
        "print(\"Stroke Images:\", len(os.listdir(stroke_path)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0oGJZIyQwqn",
        "outputId": "e7669b65-9be9-4157-cc32-12f37b4b8e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Folder NOT found. Check your Drive structure.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/brain_data_organised/\"\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(\"✅ Folder exists:\", data_path)\n",
        "else:\n",
        "    print(\"❌ Folder NOT found. Check your Drive structure.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF8XeaVjQ4tt",
        "outputId": "4193020e-b365-4b67-a634-335c8d85b0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folders in MyDrive: ['Copy of UNIT-I.docx', 'Photo album.gslides', 'Untitled presentation (2).gslides', \"I am sharing 'Seminar ppt\", 'SANTHIYA.....19PPT', 'abstract (2).pptx', 'micro (1).pptx', 'micro.pptx', 'abstract (1).pptx', 'abstract.pptx', 'seminar (1).pptx', 'E-learning ppt.pptx', 'SCREENLESS DISPLAY TECHNOLOGY (1).pptx', 'SCREENLESS DISPLAY TECHNOLOGY.pptx', 'seminar.pptx', 'data to the spreadsheet.png', 'template sheet.png', 'currency to US Dollars.png', 'country column.png', 'difference between discount and sale price.png', 'average.png', 'sum of prices.png', 'freeze 1st row.png', 'cell format.png', 'Untitled document (18).gdoc', 'CS3362 - DATA SCIENCE.docx', 'Excel 1 completed...xlsx', 'Li-Fi.docx', 'Untitled presentation (1).gslides', 'Copy of Eleanor · SlidesCarnival (4).gslides', 'Copy of Eleanor · SlidesCarnival (3).gslides', 'Copy of Eleanor · SlidesCarnival (2).gslides', 'Copy of Eleanor · SlidesCarnival (1).gslides', 'Copy of Eleanor · SlidesCarnival.gslides', 'Untitled presentation.gslides', 'Untitled document (17).gdoc', 'Untitled document (16).gdoc', 'Untitled document (15).gdoc', 'Untitled document (14).gdoc', 'Untitled document (13).gdoc', 'Untitled document (12).gdoc', 'Untitled document (11).gdoc', 'Untitled document (10).gdoc', 'Colab Notebooks', 'State Bank Collect sandy (1).jpg', 'State Bank Collect sandy.jpg', 'code galata certificate.pdf', 'Untitled document (9).gdoc', '<html>.gdoc', 'Untitled document (8).gdoc', 'Untitled document (7).gdoc', 'Presentation (1).pptx', 'Presentation (1).gslides', 'ADS_Phase_1.pdf', 'payment screenshot ', 'ADS_Phase_1 (2).gdoc', 'ADS_Phase_1 (1).gdoc', 'ADS_Phase_1.gdoc', 'ADS_Phase_3 (1).docx.pdf', 'ADS_Phase_3.docx.gdoc', 'ADS_Phase_3.docx.pdf', 'ADS_Phase_4 (1).docx.gdoc', 'ADS_Phase_4.docx.pdf', 'DAC_Phase 5.pdf', 'project video.mp4', 'DAC_Phase 5.gdoc', 'final project.mp4', 'Copy of final project.mp4', 'ADS_Phase_4.docx.gdoc', 'Untitled document (6).gdoc', 'Mini Project Evaluation Sheet 2.docx', 'Untitled document (5).gdoc', 'Untitled document (4).gdoc', 'Untitled document (3).gdoc', 'Untitled document (2).gdoc', 'Kaniska M P Resume final (1).pdf', 'Kaniska M P Resume final (2).gdoc', 'Kaniska M P Resume final.pdf', 'Kaniska M P Resume final (1).gdoc', 'Kaniska M P Resume final.gdoc', 'santhiya final resume (1).docx', 'sarumathi final resume.gdoc', 'santhiya final resume.docx.pdf', 'santhiya final resume.docx', 'santhiya final resume (1).docx.gdoc', 'Aysha (1).pdf', 'Aysha (2).gdoc', 'santhiya final resume.docx.gdoc', 'Aysha.pdf', 'PROBLEM STATEMENT KARUR & NAMAKKAL -ECE.xlsx', 'geetha resume.docx.pdf', 'SANTHIYA 1.docx.pdf', 'amd.pdf', 'Aysha - Bar chart 1.gsheet', 'Aysha (1).gdoc', 'Resume (2).gdoc', 'Resume.gdoc', 'SANTHIYA 1 (1).docx', 'SANTHIYA 1 (2).docx.gdoc', 'students namelist 6th sem cse.xlsx.pdf', 'Copy of SArumathi 1.docx.gdoc', 'Untitled document (1).gdoc', 'SANTHIYA 1.docx', 'SANTHIYA 1 (1).docx.gdoc', 'geetha resume.docx.gdoc', 'geetha.docx', 'SARUMATHI A.docx', 'SARUMATHI A (1).gdoc', 'geetha.gdoc', 'M. NAGALAKSHMI .docx', 'K.HARSHAVARTHINI .docx', 'K.HARSHAVARTHINI .gdoc', 'Project Confirmation.pdf', 'Project Confirmation (1).gdoc', 'Project Confirmation.gdoc', 'Project Confirmation.docx', 'Project Confirmation .............docx', 'null-2 (1).docx', 'null-2.docx', 'HOMOMORPHISM - Copy (1).docx', 'HOMOMORPHISM - Copy.docx', 'HOMOMORPHISM - Copy.docx (1).pdf', 'Chettinad college.pdf', 'Chettinad college.gdoc', 'BATCH-7 ppt (1).pptx', 'BATCH-14 ppt (1).pptx', 'EDII IDEA SUBMISSION.pdf', 'EDII IDEA SUBMISSION.gdoc', 'EDII IDEA SUBMISSION FINAL.docx', 'Mini Project Evaluation With EDII REGI.docx', 'SANTHIYA 1.gdoc', 'BATCH-14 ppt.pptx', 'devops (1).docx', 'devops.docx', 'Question bank all 5 units.pdf', 'Question bank all 5 units.gdoc', 'Untitled document.gdoc', 'library.xlsx', 'library (1).xlsx.pdf', 'library.xlsx.pdf', 'original resume.gdoc', 'SANTHIYA 1.docx.gdoc', 'Aysha.gdoc', 'SARUMATHI A.pdf', 'SARUMATHI A.gdoc', 'Event Inventory - Smart Import.xlsx', 'original resume.pdf', 'Photo.pdf', 'Photo (1).jpg', 'Untitled Jam.gjam', 'Untitled Jam.pdf', 'Charu.docx', 'Resume.docx', 'Resume (1).pdf', 'SIH2024_MY_Presentation and Sample PPT.pptx', 'SIH2024_IDEA_Presentation_Format.pptx', 'Resume (1).gdoc', 'My drive', 'Screenshot 2024-09-22 115938.pdf', 'Int CN Answer Key.pdf', 'Int CN Answer Key.gdoc', 'WhatsApp Image 2024-09-24 at 9.18.17 PM.jpeg', 'Photo', 'cse.xlsx', 'yolo_training', 'model2.zip', 'p15.c - nm program - Visual Studio Code 2024-10-23 20-26-49.mp4', '920221104043_Santhiya K_CN.mp4', 'SANTHIYA (1).pdf', 'MyScraoingProject', 'SANTHIYA K (1).pdf', 'SANTHIYA K.pdf', 'சொல்Spot-Team.pdf', 'Team-சொல்Spot.pdf', 'Add a heading (3).pdf', 'Screenshot_2025-02-20-11-22-34-26_4336b74596784d9a2aa81f87c2016f50.jpg', 'dcm file.zip', 'WhatsApp Audio 2025-03-25 at 11.56.10_a8d1dc53.dat.unknown', 'Copy of WhatsApp Audio 2025-03-25 at 11.56.10_a8d1dc53.dat.unknown', 'final_project', 'brain_stroke', 'unet_model.keras', 'Photo.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "drive_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# List main folders in MyDrive\n",
        "print(\"Folders in MyDrive:\", os.listdir(drive_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd37WBxARMgk",
        "outputId": "83f45e98-2f4c-4dd3-8891-efdbeb6d14df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contents of brain_stroke: ['Brain_Data_Organised']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "brain_stroke_path = \"/content/drive/MyDrive/brain_stroke\"\n",
        "\n",
        "# List all files & folders inside brain_stroke\n",
        "print(\"Contents of brain_stroke:\", os.listdir(brain_stroke_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ0xhGRHRSr_",
        "outputId": "e9c1bfa6-2779-44d5-c193-805ca5513592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Images: 1551\n",
            "Stroke Images: 950\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"  # Use the correct folder name\n",
        "normal_path = os.path.join(data_path, \"Normal\")\n",
        "stroke_path = os.path.join(data_path, \"Stroke\")\n",
        "\n",
        "print(\"Normal Images:\", len(os.listdir(normal_path)))\n",
        "print(\"Stroke Images:\", len(os.listdir(stroke_path)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwtYZ8RgRe4T",
        "outputId": "6e9c575d-2328-4b70-8b81-b88f9c980fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxflMeSQYORS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoZOpng_YS_B"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"\n",
        "normal_path = os.path.join(data_path, \"Normal\")\n",
        "stroke_path = os.path.join(data_path, \"Stroke\")\n",
        "\n",
        "# Define image size\n",
        "IMG_SIZE = (256, 256)  # Change if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVHBO_3xYXEu",
        "outputId": "9c0afd7e-2051-41bd-c004-5b8303bba6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Loaded!\n",
            "Total Images: 2501\n",
            "Image Shape: (2501, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "def load_images_from_folder(folder, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE)  # Resize to fixed dimensions\n",
        "            img = img / 255.0  # Normalize (0-1 range)\n",
        "            images.append(img)\n",
        "            labels.append(label)  # 0 for Normal, 1 for Stroke\n",
        "    return images, labels\n",
        "\n",
        "# Load normal and stroke images\n",
        "normal_images, normal_labels = load_images_from_folder(normal_path, label=0)\n",
        "stroke_images, stroke_labels = load_images_from_folder(stroke_path, label=1)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(normal_images + stroke_images).reshape(-1, 256, 256, 1)  # Adding channel dimension\n",
        "y = np.array(normal_labels + stroke_labels)\n",
        "\n",
        "print(\"Dataset Loaded!\")\n",
        "print(\"Total Images:\", len(X))\n",
        "print(\"Image Shape:\", X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC2SqlAeZc7D",
        "outputId": "0f858ed2-1af6-458e-8b36-f02e64b4c52f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data: 2000\n",
            "Testing Data: 501\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Data:\", len(X_train))\n",
        "print(\"Testing Data:\", len(X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8de4h0YRarqf",
        "outputId": "d184cd0e-efe1-44e5-c689-c579bb1c105b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Masks generated and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "mask_save_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Masks\"\n",
        "\n",
        "os.makedirs(mask_save_path, exist_ok=True)  # Create directory if not exists\n",
        "\n",
        "# Loop through all images\n",
        "for filename in os.listdir(data_path):\n",
        "    img_path = os.path.join(data_path, filename)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "\n",
        "    # Apply thresholding to extract stroke region\n",
        "    _, mask = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)  # Adjust threshold if needed\n",
        "\n",
        "    # Save mask\n",
        "    mask_filename = os.path.join(mask_save_path, filename)\n",
        "    cv2.imwrite(mask_filename, mask)\n",
        "\n",
        "print(\"✅ Masks generated and saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yjk7PKkbBbi",
        "outputId": "6e3d71b0-b899-4551-826b-02b4dd4e3f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras opencv-python numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B2Ma3MJbGg-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MJoMyV3bPky",
        "outputId": "9511a24e-badd-425e-9879-c928c9e623e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data Loaded Successfully!\n",
            "Training Data: (760, 256, 256, 1)\n",
            "Testing Data: (190, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "mask_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Masks\"\n",
        "\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "def load_data(img_folder, mask_folder):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for filename in os.listdir(img_folder):\n",
        "        img = cv2.imread(os.path.join(img_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(os.path.join(mask_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if img is not None and mask is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE) / 255.0  # Normalize\n",
        "            mask = cv2.resize(mask, IMG_SIZE) / 255.0  # Normalize\n",
        "\n",
        "            images.append(img.reshape(256, 256, 1))  # Add channel dimension\n",
        "            masks.append(mask.reshape(256, 256, 1))  # Add channel dimension\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "X, Y = load_data(data_path, mask_path)\n",
        "\n",
        "# Split into Train/Test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"✅ Data Loaded Successfully!\")\n",
        "print(\"Training Data:\", X_train.shape)\n",
        "print(\"Testing Data:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRaYPkxNbeAo",
        "outputId": "b2d8eeac-9edd-4139-dfe9-48916710d882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ U-Net Model Ready!\n"
          ]
        }
      ],
      "source": [
        "def unet_model(input_size=(256, 256, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = layers.UpSampling2D((2, 2))(c3)\n",
        "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    u2 = layers.UpSampling2D((2, 2))(c4)\n",
        "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Initialize U-Net\n",
        "model = unet_model()\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"✅ U-Net Model Ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mrcw6pOoGE7",
        "outputId": "d57f9108-eede-464a-dbf4-157e8e365be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Available: []\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw8Vi8IvoUKP"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (128, 128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69cVtAM3ohMH",
        "outputId": "65c8aeaa-864a-41a9-8e4a-5e3943bcd67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3128s\u001b[0m 33s/step - accuracy: 0.8770 - loss: 0.1240 - val_accuracy: 0.8720 - val_loss: 0.1187\n",
            "Epoch 2/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3100s\u001b[0m 33s/step - accuracy: 0.8807 - loss: 0.1009 - val_accuracy: 0.8755 - val_loss: 0.0897\n",
            "Epoch 3/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3212s\u001b[0m 33s/step - accuracy: 0.8831 - loss: 0.0834 - val_accuracy: 0.8791 - val_loss: 0.0768\n",
            "Epoch 4/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3180s\u001b[0m 33s/step - accuracy: 0.8850 - loss: 0.0722 - val_accuracy: 0.8794 - val_loss: 0.0721\n",
            "Epoch 5/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3046s\u001b[0m 32s/step - accuracy: 0.8864 - loss: 0.0664 - val_accuracy: 0.8810 - val_loss: 0.0702\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5, batch_size=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1kt9JhfkXUQ",
        "outputId": "7d6ee652-48a0-4285-d96e-ec4a4062c748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 35s/step - accuracy: 0.8804 - loss: 0.0704\n",
            "Test Accuracy: 0.8810\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test set\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46IqaXK4ljqD",
        "outputId": "7022da39-507b-42a1-98ff-9034fad213c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ File not found! Check the path.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "img_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke/sample.jpg\"\n",
        "\n",
        "if os.path.exists(img_path):\n",
        "    print(\"✅ File found!\")\n",
        "else:\n",
        "    print(\"❌ File not found! Check the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkQaPQPqlqID",
        "outputId": "4ad65949-092f-41b3-c370-01824350bd84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Folder found! Contents:\n",
            "['58 (10).jpg', '58 (2).jpg', '58 (19).jpg', '58 (17).jpg', '58 (13).jpg', '58 (12).jpg', '58 (21).jpg', '58 (15).jpg', '58 (1).jpg', '58 (20).jpg', '58 (11).jpg', '58 (18).jpg', '58 (25).jpg', '58 (23).jpg', '58 (30).jpg', '58 (24).jpg', '58 (29).jpg', '58 (3).jpg', '58 (32).jpg', '58 (31).jpg', '58 (22).jpg', '58 (28).jpg', '58 (33).jpg', '58 (27).jpg', '58 (26).jpg', '66 (1).jpg', '58 (6).jpg', '58 (34).jpg', '58 (4).jpg', '58 (8).jpg', '58 (9).jpg', '58 (35).jpg', '66 (12).jpg', '58 (5).jpg', '58 (36).jpg', '58 (7).jpg', '66 (10).jpg', '66 (11).jpg', '66 (27).jpg', '66 (13).jpg', '66 (19).jpg', '66 (2).jpg', '66 (29).jpg', '66 (17).jpg', '66 (25).jpg', '66 (3).jpg', '66 (33).jpg', '66 (15).jpg', '66 (21).jpg', '66 (23).jpg', '66 (31).jpg', '66 (7).jpg', '66 (38).jpg', '66 (5).jpg', '66 (39).jpg', '66 (41).jpg', '66 (40).jpg', '66 (6).jpg', '66 (35).jpg', '66 (8).jpg', '66 (37).jpg', '66 (4).jpg', '66 (9).jpg', '67 (11).jpg', '67 (17).jpg', '67 (13).jpg', '67 (12).jpg', '67 (2).jpg', '67 (14).jpg', '67 (15).jpg', '67 (21).jpg', '67 (23).jpg', '67 (16).jpg', '67 (19).jpg', '67 (10).jpg', '67 (1).jpg', '67 (30).jpg', '67 (29).jpg', '67 (3).jpg', '67 (33).jpg', '67 (31).jpg', '67 (25).jpg', '67 (5).jpg', '67 (4).jpg', '67 (6).jpg', '67 (28).jpg', '67 (32).jpg', '67 (27).jpg', '67 (7).jpg', '68 (20).jpg', '68 (10).jpg', '67 (9).jpg', '68 (12).jpg', '67 (8).jpg', '68 (22).jpg', '68 (14).jpg', '68 (26).jpg', '68 (18).jpg', '68 (1).jpg', '68 (2).jpg', '68 (16).jpg', '68 (24).jpg', '68 (4).jpg', '68 (34).jpg', '68 (27).jpg', '68 (35).jpg', '68 (3).jpg', '68 (30).jpg', '68 (31).jpg', '68 (28).jpg', '68 (29).jpg', '68 (36).jpg', '68 (33).jpg', '68 (5).jpg', '68 (32).jpg', '69 (2).jpg', '69 (1).jpg', '68 (8).jpg', '69 (11).jpg', '69 (19).jpg', '69 (17).jpg', '69 (16).jpg', '69 (10).jpg', '68 (6).jpg', '69 (14).jpg', '69 (12).jpg', '69 (13).jpg', '69 (15).jpg', '69 (26).jpg', '69 (23).jpg', '69 (21).jpg', '69 (3).jpg', '69 (28).jpg', '69 (24).jpg', '69 (31).jpg', '69 (27).jpg', '69 (30).jpg', '69 (29).jpg', '69 (25).jpg', '69 (22).jpg', '70 (10).jpg', '69 (36).jpg', '69 (9).jpg', '70 (1).jpg', '69 (6).jpg', '69 (7).jpg', '69 (8).jpg', '69 (33).jpg', '69 (5).jpg', '69 (34).jpg', '69 (4).jpg', '69 (35).jpg', '69 (32).jpg', '70 (15).jpg', '70 (17).jpg', '70 (29).jpg', '70 (13).jpg', '70 (11).jpg', '70 (21).jpg', '70 (3).jpg', '70 (12).jpg', '70 (27).jpg', '70 (19).jpg', '70 (25).jpg', '70 (2).jpg', '70 (23).jpg', '70 (44).jpg', '70 (31).jpg', '70 (37).jpg', '70 (47).jpg', '70 (4).jpg', '70 (45).jpg', '70 (46).jpg', '70 (35).jpg', '70 (42).jpg', '70 (43).jpg', '70 (33).jpg', '70 (39).jpg', '70 (41).jpg', '71 (10).jpg', '71 (14).jpg', '71 (16).jpg', '71 (18).jpg', '70 (6).jpg', '70 (7).jpg', '70 (5).jpg', '70 (8).jpg', '71 (2).jpg', '71 (12).jpg', '70 (9).jpg', '70 (48).jpg', '71 (1).jpg', '71 (34).jpg', '71 (3).jpg', '71 (22).jpg', '71 (4).jpg', '71 (28).jpg', '71 (32).jpg', '71 (24).jpg', '71 (30).jpg', '71 (38).jpg', '71 (20).jpg', '71 (26).jpg', '71 (36).jpg', '71 (5).jpg', '71 (46).jpg', '71 (44).jpg', '71 (6).jpg', '72 (10).jpg', '71 (42).jpg', '72 (1).jpg', '71 (9).jpg', '71 (7).jpg', '71 (48).jpg', '72 (11).jpg', '71 (8).jpg', '71 (40).jpg', '72 (17).jpg', '72 (18).jpg', '72 (22).jpg', '72 (13).jpg', '72 (23).jpg', '72 (24).jpg', '72 (20).jpg', '72 (19).jpg', '72 (15).jpg', '72 (2).jpg', '72 (21).jpg', '72 (16).jpg', '72 (3).jpg', '72 (32).jpg', '72 (4).jpg', '72 (5).jpg', '72 (31).jpg', '72 (28).jpg', '72 (29).jpg', '72 (25).jpg', '72 (27).jpg', '72 (7).jpg', '72 (6).jpg', '72 (30).jpg', '72 (26).jpg', '73 (19).jpg', '73 (18).jpg', '73 (1).jpg', '73 (17).jpg', '73 (13).jpg', '73 (14).jpg', '73 (11).jpg', '73 (15).jpg', '73 (10).jpg', '72 (9).jpg', '73 (12).jpg', '72 (8).jpg', '73 (16).jpg', '73 (28).jpg', '73 (21).jpg', '73 (3).jpg', '73 (22).jpg', '73 (2).jpg', '73 (24).jpg', '73 (34).jpg', '73 (23).jpg', '73 (32).jpg', '73 (30).jpg', '73 (26).jpg', '73 (25).jpg', '73 (20).jpg', '73 (9).jpg', '73 (7).jpg', '73 (39).jpg', '73 (5).jpg', '74 (12).jpg', '73 (8).jpg', '74 (1).jpg', '73 (6).jpg', '73 (38).jpg', '74 (10).jpg', '73 (36).jpg', '74 (11).jpg', '73 (4).jpg', '74 (22).jpg', '74 (25).jpg', '74 (2).jpg', '74 (23).jpg', '74 (20).jpg', '74 (14).jpg', '74 (16).jpg', '74 (18).jpg', '74 (4).jpg', '74 (29).jpg', '74 (27).jpg', '74 (39).jpg', '74 (3).jpg', '74 (33).jpg', '74 (31).jpg', '74 (37).jpg', '74 (35).jpg', '74 (40).jpg', '74 (45).jpg', '74 (41).jpg', '74 (44).jpg', '74 (6).jpg', '74 (42).jpg', '74 (46).jpg', '74 (43).jpg', '74 (5).jpg', '75 (13).jpg', '74 (7).jpg', '75 (11).jpg', '75 (14).jpg', '75 (12).jpg', '75 (10).jpg', '75 (1).jpg', '74 (8).jpg', '74 (9).jpg', '75 (15).jpg', '75 (28).jpg', '75 (26).jpg', '75 (18).jpg', '75 (2).jpg', '75 (34).jpg', '75 (30).jpg', '75 (20).jpg', '75 (22).jpg', '75 (24).jpg', '75 (32).jpg', '75 (3).jpg', '75 (16).jpg', '75 (46).jpg', '75 (49).jpg', '75 (40).jpg', '75 (38).jpg', '75 (8).jpg', '75 (42).jpg', '75 (5).jpg', '75 (6).jpg', '75 (44).jpg', '75 (36).jpg', '75 (7).jpg', '75 (4).jpg', '75 (48).jpg', '76 (23).jpg', '76 (21).jpg', '76 (12).jpg', '76 (25).jpg', '76 (17).jpg', '76 (19).jpg', '75 (9).jpg', '76 (10).jpg', '76 (1).jpg', '76 (2).jpg', '76 (13).jpg', '76 (15).jpg', '76 (41).jpg', '76 (43).jpg', '76 (33).jpg', '76 (27).jpg', '76 (39).jpg', '76 (31).jpg', '76 (42).jpg', '76 (29).jpg', '76 (40).jpg', '76 (37).jpg', '76 (3).jpg', '76 (35).jpg', '76 (4).jpg', '76 (7).jpg', '77 (20).jpg', '77 (16).jpg', '76 (6).jpg', '77 (18).jpg', '77 (12).jpg', '76 (9).jpg', '77 (1).jpg', '77 (10).jpg', '76 (8).jpg', '76 (5).jpg', '77 (14).jpg', '77 (2).jpg', '77 (26).jpg', '77 (38).jpg', '77 (30).jpg', '77 (36).jpg', '77 (22).jpg', '77 (24).jpg', '77 (35).jpg', '77 (34).jpg', '77 (28).jpg', '77 (3).jpg', '77 (32).jpg', '77 (37).jpg', '78 (1).jpg', '77 (4).jpg', '77 (43).jpg', '77 (8).jpg', '77 (41).jpg', '77 (40).jpg', '77 (9).jpg', '77 (7).jpg', '77 (6).jpg', '77 (5).jpg', '77 (42).jpg', '77 (39).jpg', '78 (26).jpg', '78 (19).jpg', '78 (28).jpg', '78 (13).jpg', '78 (11).jpg', '78 (3).jpg', '78 (25).jpg', '78 (21).jpg', '78 (10).jpg', '78 (17).jpg', '78 (23).jpg', '78 (2).jpg', '78 (15).jpg', '78 (32).jpg', '78 (39).jpg', '78 (34).jpg', '78 (37).jpg', '78 (42).jpg', '78 (38).jpg', '78 (36).jpg', '78 (41).jpg', '78 (35).jpg', '78 (4).jpg', '78 (30).jpg', '78 (40).jpg', '79 (17).jpg', '79 (16).jpg', '78 (9).jpg', '78 (5).jpg', '79 (12).jpg', '79 (10).jpg', '79 (13).jpg', '78 (7).jpg', '79 (11).jpg', '78 (8).jpg', '79 (1).jpg', '79 (14).jpg', '78 (6).jpg', '79 (22).jpg', '79 (2).jpg', '79 (25).jpg', '79 (23).jpg', '79 (27).jpg', '79 (19).jpg', '79 (18).jpg', '79 (21).jpg', '79 (24).jpg', '79 (26).jpg', '79 (20).jpg', '79 (4).jpg', '79 (3).jpg', '80 (18).jpg', '79 (5).jpg', '79 (6).jpg', '79 (9).jpg', '80 (15).jpg', '80 (14).jpg', '80 (10).jpg', '80 (2).jpg', '80 (1).jpg', '80 (20).jpg', '79 (7).jpg', '80 (12).jpg', '80 (16).jpg', '79 (8).jpg', '80 (28).jpg', '80 (37).jpg', '80 (30).jpg', '80 (32).jpg', '80 (22).jpg', '80 (33).jpg', '80 (26).jpg', '80 (35).jpg', '80 (38).jpg', '80 (34).jpg', '80 (24).jpg', '80 (3).jpg', '80 (36).jpg', '81 (11).jpg', '80 (5).jpg', '80 (40).jpg', '80 (39).jpg', '80 (4).jpg', '81 (10).jpg', '80 (6).jpg', '81 (12).jpg', '81 (13).jpg', '81 (1).jpg', '80 (7).jpg', '81 (15).jpg', '80 (8).jpg', '81 (29).jpg', '81 (27).jpg', '81 (21).jpg', '81 (17).jpg', '81 (37).jpg', '81 (31).jpg', '81 (35).jpg', '81 (25).jpg', '81 (19).jpg', '81 (23).jpg', '81 (33).jpg', '81 (3).jpg', '81 (2).jpg', '81 (39).jpg', '81 (4).jpg', '81 (9).jpg', '81 (41).jpg', '82 (10).jpg', '81 (43).jpg', '81 (7).jpg', '81 (44).jpg', '82 (12).jpg', '82 (1).jpg', '81 (6).jpg', '81 (5).jpg', '81 (8).jpg', '82 (20).jpg', '82 (17).jpg', '82 (2).jpg', '82 (16).jpg', '82 (23).jpg', '82 (19).jpg', '82 (18).jpg', '82 (15).jpg', '82 (22).jpg', '82 (14).jpg', '82 (21).jpg', '82 (24).jpg', '82 (31).jpg', '82 (30).jpg', '82 (7).jpg', '82 (4).jpg', '82 (25).jpg', '82 (9).jpg', '82 (8).jpg', '82 (27).jpg', '82 (26).jpg', '82 (6).jpg', '82 (29).jpg', '82 (3).jpg', '82 (5).jpg', '82 (28).jpg', '83 (17).jpg', '83 (14).jpg', '83 (11).jpg', '83 (19).jpg', '83 (13).jpg', '83 (1).jpg', '83 (2).jpg', '83 (18).jpg', '83 (12).jpg', '83 (10).jpg', '83 (16).jpg', '83 (15).jpg', '83 (36).jpg', '83 (31).jpg', '83 (35).jpg', '83 (23).jpg', '83 (20).jpg', '83 (25).jpg', '83 (33).jpg', '83 (29).jpg', '83 (22).jpg', '83 (3).jpg', '83 (27).jpg', '83 (21).jpg', '83 (38).jpg', '83 (8).jpg', '84 (1).jpg', '83 (6).jpg', '83 (5).jpg', '83 (7).jpg', '83 (37).jpg', '84 (10).jpg', '84 (11).jpg', '83 (9).jpg', '83 (4).jpg', '84 (17).jpg', '84 (20).jpg', '84 (13).jpg', '84 (24).jpg', '84 (2).jpg', '84 (15).jpg', '84 (14).jpg', '84 (22).jpg', '84 (18).jpg', '84 (26).jpg', '84 (16).jpg', '84 (12).jpg', '84 (27).jpg', '84 (28).jpg', '84 (3).jpg', '84 (29).jpg', '84 (30).jpg', '84 (31).jpg', '84 (33).jpg', '84 (36).jpg', '84 (35).jpg', '84 (38).jpg', '84 (34).jpg', '84 (37).jpg', '84 (32).jpg', '84 (39).jpg', '84 (8).jpg', '85 (21).jpg', '85 (16).jpg', '85 (15).jpg', '84 (4).jpg', '85 (10).jpg', '85 (20).jpg', '85 (2).jpg', '85 (13).jpg', '84 (5).jpg', '85 (11).jpg', '85 (19).jpg', '84 (40).jpg', '85 (1).jpg', '85 (17).jpg', '84 (6).jpg', '84 (7).jpg', '84 (9).jpg', '85 (18).jpg', '86 (18).jpg', '86 (19).jpg', '85 (5).jpg', '86 (10).jpg', '85 (9).jpg', '86 (23).jpg', '85 (3).jpg', '86 (21).jpg', '86 (1).jpg', '86 (22).jpg', '85 (6).jpg', '86 (16).jpg', '86 (14).jpg', '86 (20).jpg', '86 (2).jpg', '85 (4).jpg', '85 (8).jpg', '86 (12).jpg', '85 (7).jpg', '86 (8).jpg', '87 (11).jpg', '86 (24).jpg', '87 (10).jpg', '86 (29).jpg', '86 (4).jpg', '87 (1).jpg', '86 (35).jpg', '86 (32).jpg', '86 (34).jpg', '86 (36).jpg', '86 (6).jpg', '86 (27).jpg', '86 (33).jpg', '86 (30).jpg', '86 (26).jpg', '86 (31).jpg', '86 (28).jpg', '86 (25).jpg', '86 (3).jpg', '87 (35).jpg', '87 (39).jpg', '87 (37).jpg', '87 (14).jpg', '87 (33).jpg', '87 (23).jpg', '87 (17).jpg', '87 (15).jpg', '87 (4).jpg', '87 (29).jpg', '87 (2).jpg', '87 (3).jpg', '87 (27).jpg', '87 (31).jpg', '87 (12).jpg', '87 (25).jpg', '87 (13).jpg', '87 (21).jpg', '87 (19).jpg', '87 (42).jpg', '87 (44).jpg', '87 (9).jpg', '88 (17).jpg', '87 (40).jpg', '87 (8).jpg', '88 (19).jpg', '88 (15).jpg', '88 (13).jpg', '88 (16).jpg', '87 (7).jpg', '88 (2).jpg', '87 (41).jpg', '87 (6).jpg', '88 (11).jpg', '87 (43).jpg', '88 (18).jpg', '87 (5).jpg', '88 (12).jpg', '88 (10).jpg', '88 (14).jpg', '88 (1).jpg', '88 (3).jpg', '88 (30).jpg', '88 (24).jpg', '88 (8).jpg', '89 (10).jpg', '88 (28).jpg', '88 (4).jpg', '88 (20).jpg', '88 (26).jpg', '88 (6).jpg', '88 (21).jpg', '88 (7).jpg', '88 (34).jpg', '88 (22).jpg', '88 (5).jpg', '88 (37).jpg', '88 (35).jpg', '89 (1).jpg', '88 (32).jpg', '88 (9).jpg', '88 (36).jpg', '89 (29).jpg', '89 (23).jpg', '89 (25).jpg', '89 (39).jpg', '89 (13).jpg', '89 (33).jpg', '89 (19).jpg', '89 (38).jpg', '89 (21).jpg', '89 (16).jpg', '89 (2).jpg', '89 (27).jpg', '89 (35).jpg', '89 (34).jpg', '89 (4).jpg', '89 (14).jpg', '89 (12).jpg', '89 (36).jpg', '89 (31).jpg', '89 (15).jpg', '89 (17).jpg', '89 (37).jpg', '89 (11).jpg', '89 (3).jpg', '90 (2).jpg', '89 (8).jpg', '90 (13).jpg', '89 (7).jpg', '90 (23).jpg', '90 (21).jpg', '90 (17).jpg', '89 (5).jpg', '89 (41).jpg', '90 (15).jpg', '90 (11).jpg', '90 (1).jpg', '89 (9).jpg', '90 (19).jpg', '90 (10).jpg', '89 (42).jpg', '90 (24).jpg', '89 (6).jpg', '89 (40).jpg', '90 (12).jpg', '90 (22).jpg', '89 (43).jpg', '90 (25).jpg', '90 (7).jpg', '91 (15).jpg', '91 (10).jpg', '90 (3).jpg', '90 (26).jpg', '91 (1).jpg', '90 (9).jpg', '90 (27).jpg', '91 (2).jpg', '90 (28).jpg', '90 (31).jpg', '91 (13).jpg', '91 (11).jpg', '90 (30).jpg', '90 (5).jpg', '90 (6).jpg', '90 (29).jpg', '90 (4).jpg', '91 (12).jpg', '90 (32).jpg', '91 (19).jpg', '91 (17).jpg', '91 (14).jpg', '90 (8).jpg', '91 (8).jpg', '91 (33).jpg', '91 (9).jpg', '91 (32).jpg', '91 (29).jpg', '91 (21).jpg', '91 (3).jpg', '91 (31).jpg', '91 (30).jpg', '91 (36).jpg', '91 (34).jpg', '91 (6).jpg', '91 (5).jpg', '91 (25).jpg', '91 (7).jpg', '91 (39).jpg', '91 (27).jpg', '91 (38).jpg', '91 (23).jpg', '91 (37).jpg', '91 (35).jpg', '91 (40).jpg', '91 (4).jpg', '92 (3).jpg', '92 (19).jpg', '92 (13).jpg', '92 (27).jpg', '92 (34).jpg', '92 (31).jpg', '92 (21).jpg', '92 (38).jpg', '92 (2).jpg', '92 (1).jpg', '92 (10).jpg', '92 (17).jpg', '92 (11).jpg', '92 (32).jpg', '92 (4).jpg', '92 (15).jpg', '92 (14).jpg', '92 (36).jpg', '92 (12).jpg', '92 (33).jpg', '92 (29).jpg', '92 (25).jpg', '92 (23).jpg', '92 (20).jpg', '93 (14).jpg', '92 (6).jpg', '92 (7).jpg', '93 (12).jpg', '92 (40).jpg', '92 (5).jpg', '93 (20).jpg', '93 (26).jpg', '93 (22).jpg', '93 (2).jpg', '93 (18).jpg', '93 (1).jpg', '93 (10).jpg', '92 (8).jpg', '92 (9).jpg', '92 (42).jpg', '93 (17).jpg', '93 (16).jpg', '93 (15).jpg', '93 (27).jpg', '93 (28).jpg', '93 (24).jpg', '93 (11).jpg', '93 (13).jpg', '93 (7).jpg', '93 (8).jpg', '93 (34).jpg', '94 (1).jpg', '94 (15).jpg', '94 (10).jpg', '94 (14).jpg', '93 (31).jpg', '93 (5).jpg', '93 (32).jpg', '94 (11).jpg', '94 (16).jpg', '93 (6).jpg', '93 (35).jpg', '93 (4).jpg', '93 (3).jpg', '94 (12).jpg', '93 (9).jpg', '93 (30).jpg', '93 (29).jpg', '94 (13).jpg', '93 (33).jpg', '93 (36).jpg', '94 (44).jpg', '94 (4).jpg', '94 (6).jpg', '94 (31).jpg', '94 (3).jpg', '94 (27).jpg', '94 (23).jpg', '94 (7).jpg', '94 (18).jpg', '94 (35).jpg', '94 (33).jpg', '94 (46).jpg', '94 (19).jpg', '94 (5).jpg', '94 (37).jpg', '94 (41).jpg', '94 (29).jpg', '94 (45).jpg', '94 (17).jpg', '94 (39).jpg', '94 (21).jpg', '94 (43).jpg', '94 (25).jpg', '94 (2).jpg', '97 (16).jpg', '97 (10).jpg', '97 (12).jpg', '97 (36).jpg', '97 (3).jpg', '97 (11).jpg', '97 (13).jpg', '97 (24).jpg', '97 (28).jpg', '97 (34).jpg', '97 (14).jpg', '97 (2).jpg', '97 (1).jpg', '97 (20).jpg', '97 (15).jpg', '94 (9).jpg', '97 (32).jpg', '97 (18).jpg', '97 (26).jpg', '97 (35).jpg', '97 (22).jpg', '97 (30).jpg', '94 (8).jpg', '97 (37).jpg', '97 (40).jpg', '97 (4).jpg', '97 (5).jpg', '97 (9).jpg', '97 (39).jpg', '97 (38).jpg', '97 (7).jpg', '97 (8).jpg', '97 (6).jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    print(\"✅ Folder found! Contents:\")\n",
        "    print(os.listdir(folder_path))\n",
        "else:\n",
        "    print(\"❌ Folder not found! Check path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "9mf3wIucpODk",
        "outputId": "84cdea61-d79a-4049-cdb1-9860d5b8dc85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Select a random test image\n",
        "index = np.random.randint(0, len(X_test))\n",
        "test_img = X_test[index]\n",
        "true_mask = Y_test[index]\n",
        "\n",
        "# Predict mask\n",
        "predicted_mask = model.predict(np.expand_dims(test_img, axis=0))[0]\n",
        "\n",
        "# Convert predicted mask to binary\n",
        "threshold = 0.5\n",
        "binary_mask = (predicted_mask > threshold).astype(np.uint8)\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "ax[0].imshow(test_img.squeeze(), cmap='gray')\n",
        "ax[0].set_title(\"Original Image\")\n",
        "\n",
        "ax[1].imshow(true_mask.squeeze(), cmap='gray')\n",
        "ax[1].set_title(\"Ground Truth Mask\")\n",
        "\n",
        "ax[2].imshow(binary_mask.squeeze(), cmap='gray')\n",
        "ax[2].set_title(\"Predicted Mask\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i7qZx6epn1B"
      },
      "outputs": [],
      "source": [
        "model.save(\"unet_brain_stroke.keras\")  # Saves in the new Keras format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0xMLnX3pvq3",
        "outputId": "d3b6dfaa-e6f4-4820-cd32-76168b938200"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 24 variables whereas the saved optimizer has 46 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"unet_brain_stroke.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AMLkX4kqMLL",
        "outputId": "953c83b2-2183-4620-b252-5cca62961fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: File 'new_ct_scan.jpg' not found!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = \"new_ct_scan.jpg\"\n",
        "\n",
        "if not os.path.exists(image_path):\n",
        "    print(f\"Error: File '{image_path}' not found!\")\n",
        "else:\n",
        "    # Load and preprocess the image\n",
        "    new_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    new_img = cv2.resize(new_img, (256, 256))  # Resize to match model input shape\n",
        "    new_img = new_img / 255.0  # Normalize\n",
        "    new_img = np.expand_dims(new_img, axis=(0, -1))  # Add batch and channel dimensions\n",
        "\n",
        "    # Predict the segmentation mask\n",
        "    predicted_mask = model.predict(new_img)[0]\n",
        "\n",
        "    # Convert to binary mask\n",
        "    binary_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Show results\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(new_img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(\"Input CT Scan\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(binary_mask.squeeze(), cmap=\"gray\")\n",
        "    plt.title(\"Predicted Stroke Region\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjoh44B-qUKK",
        "outputId": "6cb150ec-0603-4f28-8332-831d026bf0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: File not found. Check the path!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "image_path = \"new_ct_scan.jpg\"  # Update with the correct path\n",
        "\n",
        "if os.path.exists(image_path):\n",
        "    print(\"File exists:\", image_path)\n",
        "else:\n",
        "    print(\"Error: File not found. Check the path!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv7TZGC_qaB5",
        "outputId": "806ae1de-f196-4994-e4ee-6c091bec922f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: /content\n",
            "Files in this directory: ['.config', 'unet_brain_stroke.keras', 'unet_brain_stroke.h5', 'drive', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "print(\"Files in this directory:\", os.listdir(\".\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssPlRidNqj7L",
        "outputId": "02633e0a-8b26-4b5f-a286-a0c6c375fe1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Found Drive Folder! Files inside: ['Brain_Data_Organised']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "drive_path = \"/content/drive/MyDrive/brain_stroke/\"\n",
        "if os.path.exists(drive_path):\n",
        "    print(\"✅ Found Drive Folder! Files inside:\", os.listdir(drive_path))\n",
        "else:\n",
        "    print(\"❌ Drive folder not found. Check your Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrT6YukLqsKo",
        "outputId": "ee368162-d827-4ddd-948c-97006d60f45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 Files inside 'Brain_Data_Organised': ['Stroke', 'Normal', 'Masks']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "brain_data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"\n",
        "if os.path.exists(brain_data_path):\n",
        "    print(\"📂 Files inside 'Brain_Data_Organised':\", os.listdir(brain_data_path))\n",
        "else:\n",
        "    print(\"❌ 'Brain_Data_Organised' folder not found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSvzgrV4qxDy",
        "outputId": "f3f90260-649a-43ea-ca85-df9c7d52bced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Image not found! Check the filename and path.\n"
          ]
        }
      ],
      "source": [
        "image_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/new_ct_scan.jpg\"\n",
        "\n",
        "if os.path.exists(image_path):\n",
        "    new_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    print(\"✅ Image loaded successfully!\")\n",
        "else:\n",
        "    print(\"❌ Image not found! Check the filename and path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH3_NXpNrecu",
        "outputId": "caba81f4-646c-4af0-81d5-2b70ca57108e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in Brain_Data_Organised: ['Stroke', 'Normal', 'Masks']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"\n",
        "print(\"Files in Brain_Data_Organised:\", os.listdir(image_folder))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m5BryimrkSA",
        "outputId": "d013f1f9-aee5-4930-dbe9-0ff072e704b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stroke Images: ['58 (10).jpg', '58 (2).jpg', '58 (19).jpg', '58 (17).jpg', '58 (13).jpg', '58 (12).jpg', '58 (21).jpg', '58 (15).jpg', '58 (1).jpg', '58 (20).jpg', '58 (11).jpg', '58 (18).jpg', '58 (25).jpg', '58 (23).jpg', '58 (30).jpg', '58 (24).jpg', '58 (29).jpg', '58 (3).jpg', '58 (32).jpg', '58 (31).jpg', '58 (22).jpg', '58 (28).jpg', '58 (33).jpg', '58 (27).jpg', '58 (26).jpg', '66 (1).jpg', '58 (6).jpg', '58 (34).jpg', '58 (4).jpg', '58 (8).jpg', '58 (9).jpg', '58 (35).jpg', '66 (12).jpg', '58 (5).jpg', '58 (36).jpg', '58 (7).jpg', '66 (10).jpg', '66 (11).jpg', '66 (27).jpg', '66 (13).jpg', '66 (19).jpg', '66 (2).jpg', '66 (29).jpg', '66 (17).jpg', '66 (25).jpg', '66 (3).jpg', '66 (33).jpg', '66 (15).jpg', '66 (21).jpg', '66 (23).jpg', '66 (31).jpg', '66 (7).jpg', '66 (38).jpg', '66 (5).jpg', '66 (39).jpg', '66 (41).jpg', '66 (40).jpg', '66 (6).jpg', '66 (35).jpg', '66 (8).jpg', '66 (37).jpg', '66 (4).jpg', '66 (9).jpg', '67 (11).jpg', '67 (17).jpg', '67 (13).jpg', '67 (12).jpg', '67 (2).jpg', '67 (14).jpg', '67 (15).jpg', '67 (21).jpg', '67 (23).jpg', '67 (16).jpg', '67 (19).jpg', '67 (10).jpg', '67 (1).jpg', '67 (30).jpg', '67 (29).jpg', '67 (3).jpg', '67 (33).jpg', '67 (31).jpg', '67 (25).jpg', '67 (5).jpg', '67 (4).jpg', '67 (6).jpg', '67 (28).jpg', '67 (32).jpg', '67 (27).jpg', '67 (7).jpg', '68 (20).jpg', '68 (10).jpg', '67 (9).jpg', '68 (12).jpg', '67 (8).jpg', '68 (22).jpg', '68 (14).jpg', '68 (26).jpg', '68 (18).jpg', '68 (1).jpg', '68 (2).jpg', '68 (16).jpg', '68 (24).jpg', '68 (4).jpg', '68 (34).jpg', '68 (27).jpg', '68 (35).jpg', '68 (3).jpg', '68 (30).jpg', '68 (31).jpg', '68 (28).jpg', '68 (29).jpg', '68 (36).jpg', '68 (33).jpg', '68 (5).jpg', '68 (32).jpg', '69 (2).jpg', '69 (1).jpg', '68 (8).jpg', '69 (11).jpg', '69 (19).jpg', '69 (17).jpg', '69 (16).jpg', '69 (10).jpg', '68 (6).jpg', '69 (14).jpg', '69 (12).jpg', '69 (13).jpg', '69 (15).jpg', '69 (26).jpg', '69 (23).jpg', '69 (21).jpg', '69 (3).jpg', '69 (28).jpg', '69 (24).jpg', '69 (31).jpg', '69 (27).jpg', '69 (30).jpg', '69 (29).jpg', '69 (25).jpg', '69 (22).jpg', '70 (10).jpg', '69 (36).jpg', '69 (9).jpg', '70 (1).jpg', '69 (6).jpg', '69 (7).jpg', '69 (8).jpg', '69 (33).jpg', '69 (5).jpg', '69 (34).jpg', '69 (4).jpg', '69 (35).jpg', '69 (32).jpg', '70 (15).jpg', '70 (17).jpg', '70 (29).jpg', '70 (13).jpg', '70 (11).jpg', '70 (21).jpg', '70 (3).jpg', '70 (12).jpg', '70 (27).jpg', '70 (19).jpg', '70 (25).jpg', '70 (2).jpg', '70 (23).jpg', '70 (44).jpg', '70 (31).jpg', '70 (37).jpg', '70 (47).jpg', '70 (4).jpg', '70 (45).jpg', '70 (46).jpg', '70 (35).jpg', '70 (42).jpg', '70 (43).jpg', '70 (33).jpg', '70 (39).jpg', '70 (41).jpg', '71 (10).jpg', '71 (14).jpg', '71 (16).jpg', '71 (18).jpg', '70 (6).jpg', '70 (7).jpg', '70 (5).jpg', '70 (8).jpg', '71 (2).jpg', '71 (12).jpg', '70 (9).jpg', '70 (48).jpg', '71 (1).jpg', '71 (34).jpg', '71 (3).jpg', '71 (22).jpg', '71 (4).jpg', '71 (28).jpg', '71 (32).jpg', '71 (24).jpg', '71 (30).jpg', '71 (38).jpg', '71 (20).jpg', '71 (26).jpg', '71 (36).jpg', '71 (5).jpg', '71 (46).jpg', '71 (44).jpg', '71 (6).jpg', '72 (10).jpg', '71 (42).jpg', '72 (1).jpg', '71 (9).jpg', '71 (7).jpg', '71 (48).jpg', '72 (11).jpg', '71 (8).jpg', '71 (40).jpg', '72 (17).jpg', '72 (18).jpg', '72 (22).jpg', '72 (13).jpg', '72 (23).jpg', '72 (24).jpg', '72 (20).jpg', '72 (19).jpg', '72 (15).jpg', '72 (2).jpg', '72 (21).jpg', '72 (16).jpg', '72 (3).jpg', '72 (32).jpg', '72 (4).jpg', '72 (5).jpg', '72 (31).jpg', '72 (28).jpg', '72 (29).jpg', '72 (25).jpg', '72 (27).jpg', '72 (7).jpg', '72 (6).jpg', '72 (30).jpg', '72 (26).jpg', '73 (19).jpg', '73 (18).jpg', '73 (1).jpg', '73 (17).jpg', '73 (13).jpg', '73 (14).jpg', '73 (11).jpg', '73 (15).jpg', '73 (10).jpg', '72 (9).jpg', '73 (12).jpg', '72 (8).jpg', '73 (16).jpg', '73 (28).jpg', '73 (21).jpg', '73 (3).jpg', '73 (22).jpg', '73 (2).jpg', '73 (24).jpg', '73 (34).jpg', '73 (23).jpg', '73 (32).jpg', '73 (30).jpg', '73 (26).jpg', '73 (25).jpg', '73 (20).jpg', '73 (9).jpg', '73 (7).jpg', '73 (39).jpg', '73 (5).jpg', '74 (12).jpg', '73 (8).jpg', '74 (1).jpg', '73 (6).jpg', '73 (38).jpg', '74 (10).jpg', '73 (36).jpg', '74 (11).jpg', '73 (4).jpg', '74 (22).jpg', '74 (25).jpg', '74 (2).jpg', '74 (23).jpg', '74 (20).jpg', '74 (14).jpg', '74 (16).jpg', '74 (18).jpg', '74 (4).jpg', '74 (29).jpg', '74 (27).jpg', '74 (39).jpg', '74 (3).jpg', '74 (33).jpg', '74 (31).jpg', '74 (37).jpg', '74 (35).jpg', '74 (40).jpg', '74 (45).jpg', '74 (41).jpg', '74 (44).jpg', '74 (6).jpg', '74 (42).jpg', '74 (46).jpg', '74 (43).jpg', '74 (5).jpg', '75 (13).jpg', '74 (7).jpg', '75 (11).jpg', '75 (14).jpg', '75 (12).jpg', '75 (10).jpg', '75 (1).jpg', '74 (8).jpg', '74 (9).jpg', '75 (15).jpg', '75 (28).jpg', '75 (26).jpg', '75 (18).jpg', '75 (2).jpg', '75 (34).jpg', '75 (30).jpg', '75 (20).jpg', '75 (22).jpg', '75 (24).jpg', '75 (32).jpg', '75 (3).jpg', '75 (16).jpg', '75 (46).jpg', '75 (49).jpg', '75 (40).jpg', '75 (38).jpg', '75 (8).jpg', '75 (42).jpg', '75 (5).jpg', '75 (6).jpg', '75 (44).jpg', '75 (36).jpg', '75 (7).jpg', '75 (4).jpg', '75 (48).jpg', '76 (23).jpg', '76 (21).jpg', '76 (12).jpg', '76 (25).jpg', '76 (17).jpg', '76 (19).jpg', '75 (9).jpg', '76 (10).jpg', '76 (1).jpg', '76 (2).jpg', '76 (13).jpg', '76 (15).jpg', '76 (41).jpg', '76 (43).jpg', '76 (33).jpg', '76 (27).jpg', '76 (39).jpg', '76 (31).jpg', '76 (42).jpg', '76 (29).jpg', '76 (40).jpg', '76 (37).jpg', '76 (3).jpg', '76 (35).jpg', '76 (4).jpg', '76 (7).jpg', '77 (20).jpg', '77 (16).jpg', '76 (6).jpg', '77 (18).jpg', '77 (12).jpg', '76 (9).jpg', '77 (1).jpg', '77 (10).jpg', '76 (8).jpg', '76 (5).jpg', '77 (14).jpg', '77 (2).jpg', '77 (26).jpg', '77 (38).jpg', '77 (30).jpg', '77 (36).jpg', '77 (22).jpg', '77 (24).jpg', '77 (35).jpg', '77 (34).jpg', '77 (28).jpg', '77 (3).jpg', '77 (32).jpg', '77 (37).jpg', '78 (1).jpg', '77 (4).jpg', '77 (43).jpg', '77 (8).jpg', '77 (41).jpg', '77 (40).jpg', '77 (9).jpg', '77 (7).jpg', '77 (6).jpg', '77 (5).jpg', '77 (42).jpg', '77 (39).jpg', '78 (26).jpg', '78 (19).jpg', '78 (28).jpg', '78 (13).jpg', '78 (11).jpg', '78 (3).jpg', '78 (25).jpg', '78 (21).jpg', '78 (10).jpg', '78 (17).jpg', '78 (23).jpg', '78 (2).jpg', '78 (15).jpg', '78 (32).jpg', '78 (39).jpg', '78 (34).jpg', '78 (37).jpg', '78 (42).jpg', '78 (38).jpg', '78 (36).jpg', '78 (41).jpg', '78 (35).jpg', '78 (4).jpg', '78 (30).jpg', '78 (40).jpg', '79 (17).jpg', '79 (16).jpg', '78 (9).jpg', '78 (5).jpg', '79 (12).jpg', '79 (10).jpg', '79 (13).jpg', '78 (7).jpg', '79 (11).jpg', '78 (8).jpg', '79 (1).jpg', '79 (14).jpg', '78 (6).jpg', '79 (22).jpg', '79 (2).jpg', '79 (25).jpg', '79 (23).jpg', '79 (27).jpg', '79 (19).jpg', '79 (18).jpg', '79 (21).jpg', '79 (24).jpg', '79 (26).jpg', '79 (20).jpg', '79 (4).jpg', '79 (3).jpg', '80 (18).jpg', '79 (5).jpg', '79 (6).jpg', '79 (9).jpg', '80 (15).jpg', '80 (14).jpg', '80 (10).jpg', '80 (2).jpg', '80 (1).jpg', '80 (20).jpg', '79 (7).jpg', '80 (12).jpg', '80 (16).jpg', '79 (8).jpg', '80 (28).jpg', '80 (37).jpg', '80 (30).jpg', '80 (32).jpg', '80 (22).jpg', '80 (33).jpg', '80 (26).jpg', '80 (35).jpg', '80 (38).jpg', '80 (34).jpg', '80 (24).jpg', '80 (3).jpg', '80 (36).jpg', '81 (11).jpg', '80 (5).jpg', '80 (40).jpg', '80 (39).jpg', '80 (4).jpg', '81 (10).jpg', '80 (6).jpg', '81 (12).jpg', '81 (13).jpg', '81 (1).jpg', '80 (7).jpg', '81 (15).jpg', '80 (8).jpg', '81 (29).jpg', '81 (27).jpg', '81 (21).jpg', '81 (17).jpg', '81 (37).jpg', '81 (31).jpg', '81 (35).jpg', '81 (25).jpg', '81 (19).jpg', '81 (23).jpg', '81 (33).jpg', '81 (3).jpg', '81 (2).jpg', '81 (39).jpg', '81 (4).jpg', '81 (9).jpg', '81 (41).jpg', '82 (10).jpg', '81 (43).jpg', '81 (7).jpg', '81 (44).jpg', '82 (12).jpg', '82 (1).jpg', '81 (6).jpg', '81 (5).jpg', '81 (8).jpg', '82 (20).jpg', '82 (17).jpg', '82 (2).jpg', '82 (16).jpg', '82 (23).jpg', '82 (19).jpg', '82 (18).jpg', '82 (15).jpg', '82 (22).jpg', '82 (14).jpg', '82 (21).jpg', '82 (24).jpg', '82 (31).jpg', '82 (30).jpg', '82 (7).jpg', '82 (4).jpg', '82 (25).jpg', '82 (9).jpg', '82 (8).jpg', '82 (27).jpg', '82 (26).jpg', '82 (6).jpg', '82 (29).jpg', '82 (3).jpg', '82 (5).jpg', '82 (28).jpg', '83 (17).jpg', '83 (14).jpg', '83 (11).jpg', '83 (19).jpg', '83 (13).jpg', '83 (1).jpg', '83 (2).jpg', '83 (18).jpg', '83 (12).jpg', '83 (10).jpg', '83 (16).jpg', '83 (15).jpg', '83 (36).jpg', '83 (31).jpg', '83 (35).jpg', '83 (23).jpg', '83 (20).jpg', '83 (25).jpg', '83 (33).jpg', '83 (29).jpg', '83 (22).jpg', '83 (3).jpg', '83 (27).jpg', '83 (21).jpg', '83 (38).jpg', '83 (8).jpg', '84 (1).jpg', '83 (6).jpg', '83 (5).jpg', '83 (7).jpg', '83 (37).jpg', '84 (10).jpg', '84 (11).jpg', '83 (9).jpg', '83 (4).jpg', '84 (17).jpg', '84 (20).jpg', '84 (13).jpg', '84 (24).jpg', '84 (2).jpg', '84 (15).jpg', '84 (14).jpg', '84 (22).jpg', '84 (18).jpg', '84 (26).jpg', '84 (16).jpg', '84 (12).jpg', '84 (27).jpg', '84 (28).jpg', '84 (3).jpg', '84 (29).jpg', '84 (30).jpg', '84 (31).jpg', '84 (33).jpg', '84 (36).jpg', '84 (35).jpg', '84 (38).jpg', '84 (34).jpg', '84 (37).jpg', '84 (32).jpg', '84 (39).jpg', '84 (8).jpg', '85 (21).jpg', '85 (16).jpg', '85 (15).jpg', '84 (4).jpg', '85 (10).jpg', '85 (20).jpg', '85 (2).jpg', '85 (13).jpg', '84 (5).jpg', '85 (11).jpg', '85 (19).jpg', '84 (40).jpg', '85 (1).jpg', '85 (17).jpg', '84 (6).jpg', '84 (7).jpg', '84 (9).jpg', '85 (18).jpg', '86 (18).jpg', '86 (19).jpg', '85 (5).jpg', '86 (10).jpg', '85 (9).jpg', '86 (23).jpg', '85 (3).jpg', '86 (21).jpg', '86 (1).jpg', '86 (22).jpg', '85 (6).jpg', '86 (16).jpg', '86 (14).jpg', '86 (20).jpg', '86 (2).jpg', '85 (4).jpg', '85 (8).jpg', '86 (12).jpg', '85 (7).jpg', '86 (8).jpg', '87 (11).jpg', '86 (24).jpg', '87 (10).jpg', '86 (29).jpg', '86 (4).jpg', '87 (1).jpg', '86 (35).jpg', '86 (32).jpg', '86 (34).jpg', '86 (36).jpg', '86 (6).jpg', '86 (27).jpg', '86 (33).jpg', '86 (30).jpg', '86 (26).jpg', '86 (31).jpg', '86 (28).jpg', '86 (25).jpg', '86 (3).jpg', '87 (35).jpg', '87 (39).jpg', '87 (37).jpg', '87 (14).jpg', '87 (33).jpg', '87 (23).jpg', '87 (17).jpg', '87 (15).jpg', '87 (4).jpg', '87 (29).jpg', '87 (2).jpg', '87 (3).jpg', '87 (27).jpg', '87 (31).jpg', '87 (12).jpg', '87 (25).jpg', '87 (13).jpg', '87 (21).jpg', '87 (19).jpg', '87 (42).jpg', '87 (44).jpg', '87 (9).jpg', '88 (17).jpg', '87 (40).jpg', '87 (8).jpg', '88 (19).jpg', '88 (15).jpg', '88 (13).jpg', '88 (16).jpg', '87 (7).jpg', '88 (2).jpg', '87 (41).jpg', '87 (6).jpg', '88 (11).jpg', '87 (43).jpg', '88 (18).jpg', '87 (5).jpg', '88 (12).jpg', '88 (10).jpg', '88 (14).jpg', '88 (1).jpg', '88 (3).jpg', '88 (30).jpg', '88 (24).jpg', '88 (8).jpg', '89 (10).jpg', '88 (28).jpg', '88 (4).jpg', '88 (20).jpg', '88 (26).jpg', '88 (6).jpg', '88 (21).jpg', '88 (7).jpg', '88 (34).jpg', '88 (22).jpg', '88 (5).jpg', '88 (37).jpg', '88 (35).jpg', '89 (1).jpg', '88 (32).jpg', '88 (9).jpg', '88 (36).jpg', '89 (29).jpg', '89 (23).jpg', '89 (25).jpg', '89 (39).jpg', '89 (13).jpg', '89 (33).jpg', '89 (19).jpg', '89 (38).jpg', '89 (21).jpg', '89 (16).jpg', '89 (2).jpg', '89 (27).jpg', '89 (35).jpg', '89 (34).jpg', '89 (4).jpg', '89 (14).jpg', '89 (12).jpg', '89 (36).jpg', '89 (31).jpg', '89 (15).jpg', '89 (17).jpg', '89 (37).jpg', '89 (11).jpg', '89 (3).jpg', '90 (2).jpg', '89 (8).jpg', '90 (13).jpg', '89 (7).jpg', '90 (23).jpg', '90 (21).jpg', '90 (17).jpg', '89 (5).jpg', '89 (41).jpg', '90 (15).jpg', '90 (11).jpg', '90 (1).jpg', '89 (9).jpg', '90 (19).jpg', '90 (10).jpg', '89 (42).jpg', '90 (24).jpg', '89 (6).jpg', '89 (40).jpg', '90 (12).jpg', '90 (22).jpg', '89 (43).jpg', '90 (25).jpg', '90 (7).jpg', '91 (15).jpg', '91 (10).jpg', '90 (3).jpg', '90 (26).jpg', '91 (1).jpg', '90 (9).jpg', '90 (27).jpg', '91 (2).jpg', '90 (28).jpg', '90 (31).jpg', '91 (13).jpg', '91 (11).jpg', '90 (30).jpg', '90 (5).jpg', '90 (6).jpg', '90 (29).jpg', '90 (4).jpg', '91 (12).jpg', '90 (32).jpg', '91 (19).jpg', '91 (17).jpg', '91 (14).jpg', '90 (8).jpg', '91 (8).jpg', '91 (33).jpg', '91 (9).jpg', '91 (32).jpg', '91 (29).jpg', '91 (21).jpg', '91 (3).jpg', '91 (31).jpg', '91 (30).jpg', '91 (36).jpg', '91 (34).jpg', '91 (6).jpg', '91 (5).jpg', '91 (25).jpg', '91 (7).jpg', '91 (39).jpg', '91 (27).jpg', '91 (38).jpg', '91 (23).jpg', '91 (37).jpg', '91 (35).jpg', '91 (40).jpg', '91 (4).jpg', '92 (3).jpg', '92 (19).jpg', '92 (13).jpg', '92 (27).jpg', '92 (34).jpg', '92 (31).jpg', '92 (21).jpg', '92 (38).jpg', '92 (2).jpg', '92 (1).jpg', '92 (10).jpg', '92 (17).jpg', '92 (11).jpg', '92 (32).jpg', '92 (4).jpg', '92 (15).jpg', '92 (14).jpg', '92 (36).jpg', '92 (12).jpg', '92 (33).jpg', '92 (29).jpg', '92 (25).jpg', '92 (23).jpg', '92 (20).jpg', '93 (14).jpg', '92 (6).jpg', '92 (7).jpg', '93 (12).jpg', '92 (40).jpg', '92 (5).jpg', '93 (20).jpg', '93 (26).jpg', '93 (22).jpg', '93 (2).jpg', '93 (18).jpg', '93 (1).jpg', '93 (10).jpg', '92 (8).jpg', '92 (9).jpg', '92 (42).jpg', '93 (17).jpg', '93 (16).jpg', '93 (15).jpg', '93 (27).jpg', '93 (28).jpg', '93 (24).jpg', '93 (11).jpg', '93 (13).jpg', '93 (7).jpg', '93 (8).jpg', '93 (34).jpg', '94 (1).jpg', '94 (15).jpg', '94 (10).jpg', '94 (14).jpg', '93 (31).jpg', '93 (5).jpg', '93 (32).jpg', '94 (11).jpg', '94 (16).jpg', '93 (6).jpg', '93 (35).jpg', '93 (4).jpg', '93 (3).jpg', '94 (12).jpg', '93 (9).jpg', '93 (30).jpg', '93 (29).jpg', '94 (13).jpg', '93 (33).jpg', '93 (36).jpg', '94 (44).jpg', '94 (4).jpg', '94 (6).jpg', '94 (31).jpg', '94 (3).jpg', '94 (27).jpg', '94 (23).jpg', '94 (7).jpg', '94 (18).jpg', '94 (35).jpg', '94 (33).jpg', '94 (46).jpg', '94 (19).jpg', '94 (5).jpg', '94 (37).jpg', '94 (41).jpg', '94 (29).jpg', '94 (45).jpg', '94 (17).jpg', '94 (39).jpg', '94 (21).jpg', '94 (43).jpg', '94 (25).jpg', '94 (2).jpg', '97 (16).jpg', '97 (10).jpg', '97 (12).jpg', '97 (36).jpg', '97 (3).jpg', '97 (11).jpg', '97 (13).jpg', '97 (24).jpg', '97 (28).jpg', '97 (34).jpg', '97 (14).jpg', '97 (2).jpg', '97 (1).jpg', '97 (20).jpg', '97 (15).jpg', '94 (9).jpg', '97 (32).jpg', '97 (18).jpg', '97 (26).jpg', '97 (35).jpg', '97 (22).jpg', '97 (30).jpg', '94 (8).jpg', '97 (37).jpg', '97 (40).jpg', '97 (4).jpg', '97 (5).jpg', '97 (9).jpg', '97 (39).jpg', '97 (38).jpg', '97 (7).jpg', '97 (8).jpg', '97 (6).jpg']\n",
            "Normal Images: ['118 (23).jpg', '118 (25).jpg', '118 (24).jpg', '118 (13).jpg', '118 (17).jpg', '119 (10).jpg', '118 (3).jpg', '118 (7).jpg', '118 (9).jpg', '118 (29).jpg', '118 (4).jpg', '118 (27).jpg', '118 (8).jpg', '118 (30).jpg', '118 (26).jpg', '118 (5).jpg', '118 (28).jpg', '118 (6).jpg', '119 (1).jpg', '119 (18).jpg', '119 (11).jpg', '119 (16).jpg', '119 (12).jpg', '119 (15).jpg', '119 (21).jpg', '119 (19).jpg', '119 (14).jpg', '119 (13).jpg', '119 (20).jpg', '119 (17).jpg', '119 (2).jpg', '119 (22).jpg', '119 (3).jpg', '119 (28).jpg', '119 (27).jpg', '119 (5).jpg', '119 (6).jpg', '119 (30).jpg', '119 (29).jpg', '119 (23).jpg', '119 (7).jpg', '119 (4).jpg', '119 (25).jpg', '119 (26).jpg', '119 (24).jpg', '119 (31).jpg', '120 (2).jpg', '119 (8).jpg', '120 (12).jpg', '120 (17).jpg', '120 (14).jpg', '120 (10).jpg', '120 (15).jpg', '120 (16).jpg', '119 (9).jpg', '120 (18).jpg', '120 (1).jpg', '120 (19).jpg', '120 (11).jpg', '120 (13).jpg', '120 (4).jpg', '120 (25).jpg', '120 (20).jpg', '120 (29).jpg', '120 (27).jpg', '120 (23).jpg', '120 (21).jpg', '120 (26).jpg', '120 (6).jpg', '120 (24).jpg', '120 (5).jpg', '120 (22).jpg', '120 (3).jpg', '120 (30).jpg', '120 (28).jpg', '121 (14).jpg', '121 (17).jpg', '121 (19).jpg', '120 (7).jpg', '120 (9).jpg', '121 (12).jpg', '121 (10).jpg', '120 (8).jpg', '121 (11).jpg', '121 (1).jpg', '121 (13).jpg', '121 (15).jpg', '121 (18).jpg', '121 (16).jpg', '121 (24).jpg', '121 (23).jpg', '121 (22).jpg', '121 (2).jpg', '121 (20).jpg', '121 (3).jpg', '121 (26).jpg', '121 (27).jpg', '121 (25).jpg', '121 (30).jpg', '121 (28).jpg', '121 (29).jpg', '121 (4).jpg', '121 (21).jpg', '122 (14).jpg', '122 (11).jpg', '122 (1).jpg', '122 (16).jpg', '121 (6).jpg', '122 (12).jpg', '122 (13).jpg', '122 (15).jpg', '121 (8).jpg', '121 (9).jpg', '121 (7).jpg', '122 (17).jpg', '121 (5).jpg', '122 (10).jpg', '122 (20).jpg', '122 (26).jpg', '122 (2).jpg', '122 (23).jpg', '122 (3).jpg', '122 (21).jpg', '122 (27).jpg', '122 (4).jpg', '122 (18).jpg', '122 (24).jpg', '122 (19).jpg', '122 (22).jpg', '122 (25).jpg', '122 (28).jpg', '123 (12).jpg', '122 (6).jpg', '123 (13).jpg', '123 (18).jpg', '123 (15).jpg', '122 (9).jpg', '123 (16).jpg', '123 (14).jpg', '123 (17).jpg', '123 (10).jpg', '122 (8).jpg', '123 (11).jpg', '122 (7).jpg', '123 (1).jpg', '122 (5).jpg', '123 (30).jpg', '123 (25).jpg', '123 (23).jpg', '123 (27).jpg', '123 (26).jpg', '123 (24).jpg', '123 (28).jpg', '123 (29).jpg', '123 (3).jpg', '123 (20).jpg', '123 (21).jpg', '123 (2).jpg', '123 (22).jpg', '123 (19).jpg', '123 (38).jpg', '123 (37).jpg', '123 (39).jpg', '123 (8).jpg', '123 (7).jpg', '123 (5).jpg', '123 (6).jpg', '123 (4).jpg', '123 (36).jpg', '123 (31).jpg', '123 (33).jpg', '123 (34).jpg', '123 (35).jpg', '123 (32).jpg', '124 (15).jpg', '123 (9).jpg', '124 (1).jpg', '124 (14).jpg', '124 (12).jpg', '124 (11).jpg', '124 (16).jpg', '124 (2).jpg', '124 (18).jpg', '124 (10).jpg', '124 (13).jpg', '124 (20).jpg', '124 (17).jpg', '124 (19).jpg', '124 (25).jpg', '124 (23).jpg', '124 (30).jpg', '124 (21).jpg', '124 (4).jpg', '124 (3).jpg', '124 (27).jpg', '124 (29).jpg', '124 (5).jpg', '124 (6).jpg', '124 (7).jpg', '124 (24).jpg', '124 (22).jpg', '124 (26).jpg', '124 (28).jpg', '124 (8).jpg', '125 (15).jpg', '125 (19).jpg', '125 (10).jpg', '125 (12).jpg', '125 (20).jpg', '125 (13).jpg', '125 (17).jpg', '124 (9).jpg', '125 (16).jpg', '125 (11).jpg', '125 (2).jpg', '125 (1).jpg', '125 (14).jpg', '125 (18).jpg', '125 (26).jpg', '125 (24).jpg', '125 (23).jpg', '125 (25).jpg', '125 (29).jpg', '125 (30).jpg', '125 (32).jpg', '125 (27).jpg', '125 (28).jpg', '125 (21).jpg', '125 (31).jpg', '125 (33).jpg', '125 (3).jpg', '125 (22).jpg', '125 (34).jpg', '125 (5).jpg', '125 (37).jpg', '126 (10).jpg', '125 (9).jpg', '125 (36).jpg', '125 (4).jpg', '125 (35).jpg', '125 (38).jpg', '125 (40).jpg', '125 (8).jpg', '125 (7).jpg', '125 (39).jpg', '126 (1).jpg', '125 (6).jpg', '126 (18).jpg', '126 (19).jpg', '126 (2).jpg', '126 (11).jpg', '126 (16).jpg', '126 (14).jpg', '126 (12).jpg', '126 (15).jpg', '126 (21).jpg', '126 (20).jpg', '126 (17).jpg', '126 (22).jpg', '126 (13).jpg', '126 (23).jpg', '126 (24).jpg', '126 (27).jpg', '126 (30).jpg', '126 (28).jpg', '126 (4).jpg', '126 (25).jpg', '126 (3).jpg', '126 (26).jpg', '126 (29).jpg', '126 (6).jpg', '126 (9).jpg', '127 (12).jpg', '126 (5).jpg', '127 (13).jpg', '127 (1).jpg', '127 (11).jpg', '126 (8).jpg', '126 (7).jpg', '127 (10).jpg', '127 (18).jpg', '127 (14).jpg', '127 (21).jpg', '127 (23).jpg', '127 (15).jpg', '127 (2).jpg', '127 (17).jpg', '127 (20).jpg', '127 (22).jpg', '127 (19).jpg', '127 (16).jpg', '127 (26).jpg', '127 (32).jpg', '127 (28).jpg', '127 (24).jpg', '127 (31).jpg', '127 (4).jpg', '127 (6).jpg', '127 (25).jpg', '127 (3).jpg', '127 (5).jpg', '127 (29).jpg', '127 (30).jpg', '127 (27).jpg', '128 (10).jpg', '128 (12).jpg', '128 (11).jpg', '127 (9).jpg', '128 (1).jpg', '127 (8).jpg', '128 (17).jpg', '128 (14).jpg', '128 (18).jpg', '128 (16).jpg', '127 (7).jpg', '128 (19).jpg', '128 (15).jpg', '128 (13).jpg', '128 (20).jpg', '128 (25).jpg', '128 (26).jpg', '128 (28).jpg', '128 (2).jpg', '128 (24).jpg', '128 (3).jpg', '128 (4).jpg', '128 (23).jpg', '128 (5).jpg', '128 (22).jpg', '128 (21).jpg', '128 (27).jpg', '128 (9).jpg', '129 (1).jpg', '129 (12).jpg', '129 (10).jpg', '128 (8).jpg', '129 (14).jpg', '129 (11).jpg', '129 (16).jpg', '129 (15).jpg', '129 (13).jpg', '128 (6).jpg', '129 (17).jpg', '129 (18).jpg', '128 (7).jpg', '129 (19).jpg', '129 (3).jpg', '129 (26).jpg', '129 (29).jpg', '129 (23).jpg', '129 (22).jpg', '129 (20).jpg', '129 (27).jpg', '129 (2).jpg', '129 (24).jpg', '129 (28).jpg', '129 (25).jpg', '129 (21).jpg', '129 (5).jpg', '129 (6).jpg', '129 (7).jpg', '129 (30).jpg', '129 (8).jpg', '130 (10).jpg', '130 (13).jpg', '130 (11).jpg', '129 (9).jpg', '130 (14).jpg', '130 (12).jpg', '129 (4).jpg', '130 (1).jpg', '130 (18).jpg', '130 (15).jpg', '130 (2).jpg', '130 (19).jpg', '130 (24).jpg', '130 (23).jpg', '130 (16).jpg', '130 (22).jpg', '130 (17).jpg', '130 (26).jpg', '130 (21).jpg', '130 (25).jpg', '130 (20).jpg', '130 (8).jpg', '130 (29).jpg', '130 (7).jpg', '130 (6).jpg', '130 (5).jpg', '130 (28).jpg', '49 (10).jpg', '130 (31).jpg', '49 (1).jpg', '130 (27).jpg', '130 (9).jpg', '130 (4).jpg', '130 (3).jpg', '130 (30).jpg', '49 (14).jpg', '49 (19).jpg', '49 (17).jpg', '49 (23).jpg', '49 (12).jpg', '49 (18).jpg', '49 (2).jpg', '49 (21).jpg', '49 (16).jpg', '49 (22).jpg', '49 (15).jpg', '49 (13).jpg', '49 (11).jpg', '49 (20).jpg', '49 (31).jpg', '49 (26).jpg', '49 (25).jpg', '49 (29).jpg', '49 (3).jpg', '49 (6).jpg', '49 (28).jpg', '49 (30).jpg', '49 (4).jpg', '49 (5).jpg', '49 (32).jpg', '49 (33).jpg', '49 (27).jpg', '49 (24).jpg', '50 (24).jpg', '49 (7).jpg', '50 (10).jpg', '49 (8).jpg', '50 (18).jpg', '50 (12).jpg', '50 (16).jpg', '49 (9).jpg', '50 (2).jpg', '50 (11).jpg', '50 (20).jpg', '50 (14).jpg', '50 (1).jpg', '50 (22).jpg', '50 (5).jpg', '50 (34).jpg', '50 (26).jpg', '50 (36).jpg', '50 (7).jpg', '50 (32).jpg', '50 (28).jpg', '50 (30).jpg', '50 (37).jpg', '50 (38).jpg', '50 (3).jpg', '50 (8).jpg', '50 (6).jpg', '50 (4).jpg', '51 (13).jpg', '51 (1).jpg', '51 (10).jpg', '51 (12).jpg', '51 (14).jpg', '51 (2).jpg', '51 (24).jpg', '51 (11).jpg', '51 (16).jpg', '51 (22).jpg', '51 (18).jpg', '50 (9).jpg', '51 (20).jpg', '51 (42).jpg', '51 (28).jpg', '51 (30).jpg', '51 (4).jpg', '51 (32).jpg', '51 (44).jpg', '51 (34).jpg', '51 (26).jpg', '51 (3).jpg', '51 (38).jpg', '51 (36).jpg', '51 (40).jpg', '51 (48).jpg', '51 (46).jpg', '52 (1).jpg', '52 (10).jpg', '51 (9).jpg', '51 (6).jpg', '52 (19).jpg', '52 (17).jpg', '52 (13).jpg', '51 (5).jpg', '51 (50).jpg', '52 (2).jpg', '51 (8).jpg', '52 (15).jpg', '51 (7).jpg', '52 (11).jpg', '52 (25).jpg', '52 (30).jpg', '52 (21).jpg', '52 (34).jpg', '52 (32).jpg', '52 (33).jpg', '52 (29).jpg', '52 (35).jpg', '52 (3).jpg', '52 (31).jpg', '52 (27).jpg', '52 (23).jpg', '53 (1).jpg', '52 (8).jpg', '52 (38).jpg', '52 (36).jpg', '52 (4).jpg', '53 (10).jpg', '52 (39).jpg', '52 (5).jpg', '52 (6).jpg', '52 (9).jpg', '52 (37).jpg', '53 (11).jpg', '52 (7).jpg', '53 (17).jpg', '53 (19).jpg', '53 (15).jpg', '53 (22).jpg', '53 (12).jpg', '53 (24).jpg', '53 (2).jpg', '53 (21).jpg', '53 (13).jpg', '53 (18).jpg', '53 (20).jpg', '53 (14).jpg', '53 (16).jpg', '53 (28).jpg', '53 (39).jpg', '53 (35).jpg', '53 (37).jpg', '53 (3).jpg', '53 (29).jpg', '53 (33).jpg', '53 (26).jpg', '53 (41).jpg', '53 (4).jpg', '53 (43).jpg', '53 (31).jpg', '54 (16).jpg', '54 (14).jpg', '53 (9).jpg', '53 (6).jpg', '54 (15).jpg', '54 (13).jpg', '53 (7).jpg', '54 (1).jpg', '53 (5).jpg', '54 (12).jpg', '54 (10).jpg', '54 (11).jpg', '53 (8).jpg', '54 (28).jpg', '54 (19).jpg', '54 (27).jpg', '54 (21).jpg', '54 (20).jpg', '54 (22).jpg', '54 (18).jpg', '54 (3).jpg', '54 (26).jpg', '54 (2).jpg', '54 (23).jpg', '54 (25).jpg', '54 (17).jpg', '54 (24).jpg', '55 (1).jpg', '54 (8).jpg', '55 (14).jpg', '54 (5).jpg', '55 (12).jpg', '54 (6).jpg', '55 (10).jpg', '55 (17).jpg', '55 (16).jpg', '55 (13).jpg', '55 (15).jpg', '54 (9).jpg', '55 (11).jpg', '54 (4).jpg', '54 (7).jpg', '55 (19).jpg', '55 (29).jpg', '55 (24).jpg', '55 (2).jpg', '55 (20).jpg', '55 (21).jpg', '55 (18).jpg', '55 (25).jpg', '55 (28).jpg', '55 (23).jpg', '55 (27).jpg', '55 (26).jpg', '55 (22).jpg', '55 (3).jpg', '55 (5).jpg', '55 (4).jpg', '56 (10).jpg', '55 (8).jpg', '56 (11).jpg', '55 (32).jpg', '55 (7).jpg', '55 (9).jpg', '55 (31).jpg', '55 (6).jpg', '56 (1).jpg', '55 (30).jpg', '56 (23).jpg', '56 (17).jpg', '56 (14).jpg', '56 (2).jpg', '56 (15).jpg', '56 (13).jpg', '56 (16).jpg', '56 (18).jpg', '56 (19).jpg', '56 (22).jpg', '56 (12).jpg', '56 (21).jpg', '56 (20).jpg', '56 (29).jpg', '56 (30).jpg', '56 (5).jpg', '56 (3).jpg', '56 (24).jpg', '56 (32).jpg', '56 (27).jpg', '56 (33).jpg', '56 (28).jpg', '56 (31).jpg', '56 (4).jpg', '56 (25).jpg', '56 (6).jpg', '56 (26).jpg', '57 (18).jpg', '57 (10).jpg', '57 (17).jpg', '56 (7).jpg', '57 (13).jpg', '56 (9).jpg', '57 (16).jpg', '57 (11).jpg', '57 (15).jpg', '57 (14).jpg', '57 (1).jpg', '57 (12).jpg', '56 (8).jpg', '57 (24).jpg', '57 (26).jpg', '57 (25).jpg', '57 (27).jpg', '57 (29).jpg', '57 (19).jpg', '57 (2).jpg', '57 (22).jpg', '57 (23).jpg', '57 (28).jpg', '57 (21).jpg', '57 (20).jpg', '57 (7).jpg', '59 (1).jpg', '57 (4).jpg', '57 (6).jpg', '57 (30).jpg', '57 (31).jpg', '57 (34).jpg', '57 (8).jpg', '57 (32).jpg', '57 (33).jpg', '57 (35).jpg', '57 (3).jpg', '57 (5).jpg', '57 (9).jpg', '59 (17).jpg', '59 (13).jpg', '59 (10).jpg', '59 (20).jpg', '59 (16).jpg', '59 (11).jpg', '59 (2).jpg', '59 (12).jpg', '59 (15).jpg', '59 (21).jpg', '59 (19).jpg', '59 (18).jpg', '59 (14).jpg', '59 (24).jpg', '59 (3).jpg', '59 (7).jpg', '59 (27).jpg', '59 (25).jpg', '59 (26).jpg', '59 (22).jpg', '59 (9).jpg', '59 (8).jpg', '59 (4).jpg', '59 (6).jpg', '60 (1).jpg', '59 (5).jpg', '59 (23).jpg', '60 (12).jpg', '60 (16).jpg', '60 (15).jpg', '60 (14).jpg', '60 (19).jpg', '60 (17).jpg', '60 (18).jpg', '60 (20).jpg', '60 (2).jpg', '60 (10).jpg', '60 (13).jpg', '60 (11).jpg', '60 (27).jpg', '60 (3).jpg', '60 (5).jpg', '60 (29).jpg', '60 (26).jpg', '60 (23).jpg', '60 (28).jpg', '60 (8).jpg', '60 (21).jpg', '60 (4).jpg', '60 (7).jpg', '60 (25).jpg', '60 (24).jpg', '60 (6).jpg', '60 (22).jpg', '61 (16).jpg', '61 (11).jpg', '61 (19).jpg', '61 (18).jpg', '61 (13).jpg', '61 (1).jpg', '60 (9).jpg', '61 (10).jpg', '61 (14).jpg', '61 (15).jpg', '61 (17).jpg', '61 (12).jpg', '61 (30).jpg', '61 (26).jpg', '61 (29).jpg', '61 (28).jpg', '61 (23).jpg', '61 (22).jpg', '61 (25).jpg', '61 (20).jpg', '61 (2).jpg', '61 (27).jpg', '61 (21).jpg', '61 (3).jpg', '61 (24).jpg', '62 (13).jpg', '61 (5).jpg', '62 (10).jpg', '61 (6).jpg', '61 (31).jpg', '62 (1).jpg', '62 (14).jpg', '61 (7).jpg', '61 (8).jpg', '61 (4).jpg', '61 (9).jpg', '62 (12).jpg', '62 (11).jpg', '62 (23).jpg', '62 (21).jpg', '62 (3).jpg', '62 (15).jpg', '62 (20).jpg', '62 (2).jpg', '62 (18).jpg', '62 (22).jpg', '62 (16).jpg', '62 (17).jpg', '62 (19).jpg', '63 (15).jpg', '63 (1).jpg', '63 (11).jpg', '63 (10).jpg', '62 (6).jpg', '63 (14).jpg', '62 (4).jpg', '62 (7).jpg', '63 (13).jpg', '63 (12).jpg', '62 (9).jpg', '62 (8).jpg', '62 (5).jpg', '63 (18).jpg', '63 (22).jpg', '63 (25).jpg', '63 (19).jpg', '63 (2).jpg', '63 (17).jpg', '63 (21).jpg', '63 (23).jpg', '63 (26).jpg', '63 (20).jpg', '63 (16).jpg', '63 (27).jpg', '63 (24).jpg', '63 (29).jpg', '63 (34).jpg', '63 (35).jpg', '63 (33).jpg', '63 (6).jpg', '63 (3).jpg', '63 (31).jpg', '63 (30).jpg', '63 (32).jpg', '63 (36).jpg', '63 (5).jpg', '63 (4).jpg', '63 (28).jpg', '64 (19).jpg', '64 (1).jpg', '64 (18).jpg', '64 (13).jpg', '64 (14).jpg', '63 (8).jpg', '64 (17).jpg', '63 (7).jpg', '64 (10).jpg', '63 (9).jpg', '64 (11).jpg', '64 (12).jpg', '64 (16).jpg', '64 (15).jpg', '64 (23).jpg', '64 (2).jpg', '64 (3).jpg', '64 (5).jpg', '64 (25).jpg', '64 (24).jpg', '64 (20).jpg', '64 (7).jpg', '64 (6).jpg', '64 (4).jpg', '64 (21).jpg', '64 (22).jpg', '64 (26).jpg', '65 (1).jpg', '65 (11).jpg', '65 (13).jpg', '65 (15).jpg', '65 (18).jpg', '64 (8).jpg', '65 (12).jpg', '65 (19).jpg', '65 (10).jpg', '65 (16).jpg', '65 (14).jpg', '64 (9).jpg', '65 (17).jpg', '65 (24).jpg', '65 (3).jpg', '65 (29).jpg', '65 (20).jpg', '65 (2).jpg', '65 (30).jpg', '65 (21).jpg', '65 (28).jpg', '65 (25).jpg', '65 (26).jpg', '65 (27).jpg', '65 (22).jpg', '65 (23).jpg', '95 (12).jpg', '95 (1).jpg', '95 (14).jpg', '95 (10).jpg', '65 (8).jpg', '65 (7).jpg', '95 (15).jpg', '95 (11).jpg', '95 (13).jpg', '65 (6).jpg', '65 (5).jpg', '65 (4).jpg', '65 (9).jpg', '95 (18).jpg', '95 (16).jpg', '95 (25).jpg', '95 (2).jpg', '95 (26).jpg', '95 (24).jpg', '95 (20).jpg', '95 (22).jpg', '95 (23).jpg', '95 (17).jpg', '95 (21).jpg', '95 (19).jpg', '95 (9).jpg', '96 (1).jpg', '95 (27).jpg', '95 (8).jpg', '95 (29).jpg', '95 (7).jpg', '95 (4).jpg', '95 (5).jpg', '96 (10).jpg', '95 (6).jpg', '95 (3).jpg', '95 (28).jpg', '96 (20).jpg', '96 (17).jpg', '96 (16).jpg', '96 (15).jpg', '96 (13).jpg', '96 (18).jpg', '96 (14).jpg', '96 (21).jpg', '96 (12).jpg', '96 (2).jpg', '96 (19).jpg', '96 (22).jpg', '96 (11).jpg', '96 (24).jpg', '96 (32).jpg', '96 (33).jpg', '96 (27).jpg', '96 (23).jpg', '96 (25).jpg', '96 (29).jpg', '96 (3).jpg', '96 (4).jpg', '96 (31).jpg', '96 (28).jpg', '96 (30).jpg', '96 (26).jpg', '98 (11).jpg', '96 (6).jpg', '98 (14).jpg', '98 (10).jpg', '98 (12).jpg', '98 (13).jpg', '96 (9).jpg', '98 (15).jpg', '96 (7).jpg', '96 (8).jpg', '96 (5).jpg', '98 (1).jpg', '98 (17).jpg', '98 (23).jpg', '98 (24).jpg', '98 (16).jpg', '98 (21).jpg', '98 (19).jpg', '98 (26).jpg', '98 (2).jpg', '98 (25).jpg', '98 (20).jpg', '98 (27).jpg', '98 (18).jpg', '98 (22).jpg', '98 (7).jpg', '98 (8).jpg', '98 (29).jpg', '99 (11).jpg', '98 (5).jpg', '98 (9).jpg', '98 (3).jpg', '98 (28).jpg', '99 (1).jpg', '98 (6).jpg', '99 (10).jpg', '98 (4).jpg', '99 (17).jpg', '99 (23).jpg', '99 (15).jpg', '99 (21).jpg', '99 (2).jpg', '99 (20).jpg', '99 (19).jpg', '99 (22).jpg', '99 (16).jpg', '99 (12).jpg', '99 (13).jpg', '99 (18).jpg', '99 (14).jpg', '99 (24).jpg', '99 (5).jpg', '99 (29).jpg', '99 (28).jpg', '99 (27).jpg', '99 (25).jpg', '99 (7).jpg', '99 (6).jpg', '99 (3).jpg', '99 (4).jpg', '99 (8).jpg', '99 (26).jpg', '99 (9).jpg', '100 (16).jpg', '100 (15).jpg', '100 (13).jpg', '100 (12).jpg', '100 (19).jpg', '100 (11).jpg', '100 (1).jpg', '100 (17).jpg', '100 (10).jpg', '100 (18).jpg', '100 (14).jpg', '100 (23).jpg', '100 (4).jpg', '100 (21).jpg', '100 (30).jpg', '100 (5).jpg', '100 (3).jpg', '100 (22).jpg', '100 (28).jpg', '100 (24).jpg', '100 (29).jpg', '100 (26).jpg', '100 (2).jpg', '100 (27).jpg', '100 (25).jpg', '100 (20).jpg', '100 (8).jpg', '101 (19).jpg', '101 (11).jpg', '100 (6).jpg', '101 (12).jpg', '100 (9).jpg', '101 (14).jpg', '101 (16).jpg', '101 (18).jpg', '100 (7).jpg', '101 (17).jpg', '101 (1).jpg', '101 (15).jpg', '101 (13).jpg', '101 (10).jpg', '101 (24).jpg', '101 (31).jpg', '101 (26).jpg', '101 (28).jpg', '101 (23).jpg', '101 (3).jpg', '101 (4).jpg', '101 (30).jpg', '101 (29).jpg', '101 (25).jpg', '101 (27).jpg', '101 (5).jpg', '101 (21).jpg', '101 (6).jpg', '101 (2).jpg', '101 (20).jpg', '101 (22).jpg', '101 (7).jpg', '102 (17).jpg', '102 (13).jpg', '102 (11).jpg', '101 (9).jpg', '102 (15).jpg', '102 (16).jpg', '102 (10).jpg', '102 (18).jpg', '101 (8).jpg', '102 (19).jpg', '102 (1).jpg', '102 (2).jpg', '102 (20).jpg', '102 (12).jpg', '102 (14).jpg', '102 (3).jpg', '102 (23).jpg', '102 (4).jpg', '102 (6).jpg', '102 (22).jpg', '102 (30).jpg', '102 (31).jpg', '102 (21).jpg', '102 (25).jpg', '102 (5).jpg', '102 (29).jpg', '102 (24).jpg', '102 (28).jpg', '102 (27).jpg', '102 (26).jpg', '103 (2).jpg', '103 (20).jpg', '103 (19).jpg', '103 (1).jpg', '103 (10).jpg', '103 (14).jpg', '103 (15).jpg', '103 (12).jpg', '103 (13).jpg', '102 (7).jpg', '103 (11).jpg', '103 (16).jpg', '103 (18).jpg', '103 (17).jpg', '102 (9).jpg', '102 (8).jpg', '103 (28).jpg', '103 (31).jpg', '103 (24).jpg', '103 (26).jpg', '103 (27).jpg', '103 (29).jpg', '103 (32).jpg', '103 (34).jpg', '103 (30).jpg', '103 (33).jpg', '103 (3).jpg', '103 (4).jpg', '103 (25).jpg', '103 (22).jpg', '103 (35).jpg', '103 (21).jpg', '103 (23).jpg', '104 (17).jpg', '104 (11).jpg', '104 (14).jpg', '104 (19).jpg', '104 (10).jpg', '104 (1).jpg', '104 (16).jpg', '103 (9).jpg', '104 (12).jpg', '103 (5).jpg', '103 (8).jpg', '104 (2).jpg', '103 (6).jpg', '104 (15).jpg', '104 (13).jpg', '104 (18).jpg', '103 (7).jpg', '104 (29).jpg', '104 (22).jpg', '104 (4).jpg', '104 (23).jpg', '104 (20).jpg', '104 (5).jpg', '104 (8).jpg', '104 (6).jpg', '104 (28).jpg', '104 (7).jpg', '104 (3).jpg', '104 (26).jpg', '104 (24).jpg', '104 (27).jpg', '104 (25).jpg', '104 (21).jpg', '105 (17).jpg', '105 (12).jpg', '105 (10).jpg', '105 (20).jpg', '105 (15).jpg', '105 (13).jpg', '105 (18).jpg', '105 (2).jpg', '105 (19).jpg', '105 (14).jpg', '105 (1).jpg', '105 (16).jpg', '105 (11).jpg', '104 (9).jpg', '105 (7).jpg', '105 (25).jpg', '105 (22).jpg', '105 (5).jpg', '105 (24).jpg', '105 (26).jpg', '105 (21).jpg', '105 (4).jpg', '105 (30).jpg', '105 (29).jpg', '105 (28).jpg', '105 (6).jpg', '105 (23).jpg', '105 (27).jpg', '105 (3).jpg', '105 (8).jpg', '106 (17).jpg', '106 (2).jpg', '105 (9).jpg', '106 (14).jpg', '106 (12).jpg', '106 (16).jpg', '106 (10).jpg', '106 (18).jpg', '106 (15).jpg', '106 (19).jpg', '106 (1).jpg', '106 (13).jpg', '106 (11).jpg', '106 (20).jpg', '106 (5).jpg', '106 (26).jpg', '106 (21).jpg', '106 (28).jpg', '106 (3).jpg', '106 (22).jpg', '106 (25).jpg', '106 (7).jpg', '106 (29).jpg', '106 (24).jpg', '106 (6).jpg', '106 (27).jpg', '106 (4).jpg', '106 (23).jpg', '106 (8).jpg', '107 (12).jpg', '107 (15).jpg', '107 (16).jpg', '107 (14).jpg', '107 (19).jpg', '107 (1).jpg', '107 (10).jpg', '107 (11).jpg', '107 (13).jpg', '106 (9).jpg', '107 (2).jpg', '107 (17).jpg', '107 (18).jpg', '107 (25).jpg', '107 (29).jpg', '107 (30).jpg', '107 (6).jpg', '107 (4).jpg', '107 (28).jpg', '107 (23).jpg', '107 (26).jpg', '107 (5).jpg', '107 (3).jpg', '107 (21).jpg', '107 (24).jpg', '107 (22).jpg', '107 (20).jpg', '107 (27).jpg', '108 (15).jpg', '108 (19).jpg', '108 (16).jpg', '108 (17).jpg', '107 (8).jpg', '108 (18).jpg', '108 (1).jpg', '107 (7).jpg', '108 (10).jpg', '108 (11).jpg', '108 (12).jpg', '108 (13).jpg', '107 (9).jpg', '108 (14).jpg', '108 (27).jpg', '108 (23).jpg', '108 (22).jpg', '108 (24).jpg', '108 (25).jpg', '108 (4).jpg', '108 (28).jpg', '108 (29).jpg', '108 (5).jpg', '108 (3).jpg', '108 (21).jpg', '108 (26).jpg', '108 (20).jpg', '108 (2).jpg', '109 (14).jpg', '108 (8).jpg', '108 (7).jpg', '109 (10).jpg', '109 (17).jpg', '109 (1).jpg', '109 (11).jpg', '109 (15).jpg', '108 (9).jpg', '109 (16).jpg', '109 (12).jpg', '109 (13).jpg', '108 (6).jpg', '109 (25).jpg', '109 (28).jpg', '109 (24).jpg', '109 (23).jpg', '109 (27).jpg', '109 (19).jpg', '109 (18).jpg', '109 (20).jpg', '109 (3).jpg', '109 (26).jpg', '109 (22).jpg', '109 (2).jpg', '109 (4).jpg', '109 (21).jpg', '110 (12).jpg', '109 (9).jpg', '109 (5).jpg', '109 (7).jpg', '110 (15).jpg', '110 (13).jpg', '110 (1).jpg', '110 (11).jpg', '110 (14).jpg', '109 (6).jpg', '109 (8).jpg', '110 (10).jpg', '110 (25).jpg', '110 (27).jpg', '110 (18).jpg', '110 (26).jpg', '110 (23).jpg', '110 (22).jpg', '110 (19).jpg', '110 (17).jpg', '110 (28).jpg', '110 (3).jpg', '110 (21).jpg', '110 (2).jpg', '110 (16).jpg', '110 (20).jpg', '110 (24).jpg', '111 (11).jpg', '111 (14).jpg', '111 (12).jpg', '111 (1).jpg', '110 (5).jpg', '110 (4).jpg', '111 (10).jpg', '110 (7).jpg', '111 (13).jpg', '110 (9).jpg', '110 (6).jpg', '110 (8).jpg', '111 (15).jpg', '111 (17).jpg', '111 (19).jpg', '111 (21).jpg', '111 (24).jpg', '111 (20).jpg', '111 (29).jpg', '111 (16).jpg', '111 (27).jpg', '111 (22).jpg', '111 (18).jpg', '111 (23).jpg', '111 (25).jpg', '111 (2).jpg', '111 (26).jpg', '111 (28).jpg', '111 (4).jpg', '112 (11).jpg', '112 (10).jpg', '111 (7).jpg', '111 (30).jpg', '111 (5).jpg', '111 (9).jpg', '111 (31).jpg', '111 (32).jpg', '112 (1).jpg', '111 (6).jpg', '111 (8).jpg', '111 (33).jpg', '111 (3).jpg', '112 (18).jpg', '112 (20).jpg', '112 (19).jpg', '112 (21).jpg', '112 (22).jpg', '112 (13).jpg', '112 (16).jpg', '112 (24).jpg', '112 (14).jpg', '112 (15).jpg', '112 (2).jpg', '112 (17).jpg', '112 (12).jpg', '112 (23).jpg', '112 (25).jpg', '112 (26).jpg', '113 (11).jpg', '112 (4).jpg', '113 (12).jpg', '112 (3).jpg', '113 (1).jpg', '112 (6).jpg', '112 (9).jpg', '112 (7).jpg', '113 (10).jpg', '113 (13).jpg', '112 (5).jpg', '112 (8).jpg', '113 (24).jpg', '113 (22).jpg', '113 (15).jpg', '113 (21).jpg', '113 (18).jpg', '113 (23).jpg', '113 (19).jpg', '113 (20).jpg', '113 (14).jpg', '113 (17).jpg', '113 (2).jpg', '113 (25).jpg', '113 (16).jpg', '113 (26).jpg', '113 (6).jpg', '114 (12).jpg', '114 (11).jpg', '114 (10).jpg', '113 (9).jpg', '113 (27).jpg', '113 (5).jpg', '113 (8).jpg', '114 (1).jpg', '113 (4).jpg', '113 (28).jpg', '113 (3).jpg', '113 (7).jpg', '114 (19).jpg', '114 (25).jpg', '114 (18).jpg', '114 (16).jpg', '114 (21).jpg', '114 (13).jpg', '114 (14).jpg', '114 (24).jpg', '114 (15).jpg', '114 (22).jpg', '114 (23).jpg', '114 (20).jpg', '114 (2).jpg', '114 (17).jpg', '114 (29).jpg', '114 (8).jpg', '114 (5).jpg', '115 (10).jpg', '115 (11).jpg', '114 (9).jpg', '114 (3).jpg', '114 (27).jpg', '114 (6).jpg', '114 (26).jpg', '114 (4).jpg', '115 (1).jpg', '114 (28).jpg', '114 (7).jpg', '115 (17).jpg', '115 (18).jpg', '115 (20).jpg', '115 (21).jpg', '115 (19).jpg', '115 (12).jpg', '115 (14).jpg', '115 (22).jpg', '115 (2).jpg', '115 (13).jpg', '115 (15).jpg', '115 (16).jpg', '115 (31).jpg', '115 (4).jpg', '115 (32).jpg', '115 (27).jpg', '115 (24).jpg', '115 (30).jpg', '115 (23).jpg', '115 (3).jpg', '115 (26).jpg', '115 (25).jpg', '115 (29).jpg', '115 (28).jpg', '116 (14).jpg', '116 (12).jpg', '115 (5).jpg', '115 (7).jpg', '116 (17).jpg', '116 (15).jpg', '115 (8).jpg', '115 (9).jpg', '116 (13).jpg', '116 (1).jpg', '115 (6).jpg', '116 (10).jpg', '116 (11).jpg', '116 (16).jpg', '116 (25).jpg', '116 (28).jpg', '116 (3).jpg', '116 (19).jpg', '116 (29).jpg', '116 (2).jpg', '116 (27).jpg', '116 (22).jpg', '116 (18).jpg', '116 (20).jpg', '116 (24).jpg', '116 (21).jpg', '116 (26).jpg', '116 (23).jpg', '117 (12).jpg', '117 (1).jpg', '116 (31).jpg', '116 (7).jpg', '116 (30).jpg', '116 (4).jpg', '116 (9).jpg', '117 (11).jpg', '116 (5).jpg', '116 (8).jpg', '117 (10).jpg', '117 (13).jpg', '116 (6).jpg', '117 (18).jpg', '117 (22).jpg', '117 (19).jpg', '117 (15).jpg', '117 (2).jpg', '117 (26).jpg', '117 (23).jpg', '117 (14).jpg', '117 (21).jpg', '117 (16).jpg', '117 (17).jpg', '117 (25).jpg', '117 (20).jpg', '117 (24).jpg', '118 (1).jpg', '118 (12).jpg', '117 (28).jpg', '117 (5).jpg', '117 (8).jpg', '117 (3).jpg', '117 (7).jpg', '118 (10).jpg', '117 (29).jpg', '117 (27).jpg', '118 (11).jpg', '117 (6).jpg', '117 (4).jpg', '117 (9).jpg', '118 (22).jpg', '118 (15).jpg', '118 (19).jpg', '118 (18).jpg', '118 (2).jpg', '118 (14).jpg', '118 (20).jpg', '118 (21).jpg', '118 (16).jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "stroke_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "normal_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Normal\"\n",
        "\n",
        "print(\"Stroke Images:\", os.listdir(stroke_folder))\n",
        "print(\"Normal Images:\", os.listdir(normal_folder))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHpXTPSTr6xg",
        "outputId": "c156cf9c-2c3e-4490-846b-655568ad6edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Error: Image '/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke/sample_image.jpg' not found! Check the path and filename.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# ✅ Load the trained U-Net model\n",
        "model = tf.keras.models.load_model(\"/content/unet_brain_stroke.keras\", compile=False)\n",
        "\n",
        "# ✅ Update the correct path to an image from your dataset\n",
        "image_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke/sample_image.jpg\"  # Change this!\n",
        "\n",
        "# ✅ Check if the image exists\n",
        "if not os.path.exists(image_path):\n",
        "    print(f\"❌ Error: Image '{image_path}' not found! Check the path and filename.\")\n",
        "else:\n",
        "    # 📌 Step 1: Load and Preprocess the Image\n",
        "    new_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    new_img = cv2.resize(new_img, (256, 256))  # Resize to match model input shape\n",
        "    new_img = new_img / 255.0  # Normalize (convert pixel values to 0-1)\n",
        "    new_img = np.expand_dims(new_img, axis=(0, -1))  # Add batch and channel dimensions\n",
        "\n",
        "    # 📌 Step 2: Predict the Segmentation Mask\n",
        "    predicted_mask = model.predict(new_img)[0]\n",
        "\n",
        "    # 📌 Step 3: Convert to Binary Mask (Threshold = 0.5)\n",
        "    binary_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    # 📌 Step 4: Display the Results\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(new_img.squeeze(), cmap='gray')\n",
        "    plt.title(\"Input CT Scan\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(binary_mask.squeeze(), cmap='gray')\n",
        "    plt.title(\"Predicted Stroke Region\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNHarIsksG_k",
        "outputId": "27fbda29-3d4e-47c4-dcd2-b37d07b28564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Stroke Folder Found!\n",
            "📂 Available Images: ['58 (10).jpg', '58 (2).jpg', '58 (19).jpg', '58 (17).jpg', '58 (13).jpg', '58 (12).jpg', '58 (21).jpg', '58 (15).jpg', '58 (1).jpg', '58 (20).jpg', '58 (11).jpg', '58 (18).jpg', '58 (25).jpg', '58 (23).jpg', '58 (30).jpg', '58 (24).jpg', '58 (29).jpg', '58 (3).jpg', '58 (32).jpg', '58 (31).jpg', '58 (22).jpg', '58 (28).jpg', '58 (33).jpg', '58 (27).jpg', '58 (26).jpg', '66 (1).jpg', '58 (6).jpg', '58 (34).jpg', '58 (4).jpg', '58 (8).jpg', '58 (9).jpg', '58 (35).jpg', '66 (12).jpg', '58 (5).jpg', '58 (36).jpg', '58 (7).jpg', '66 (10).jpg', '66 (11).jpg', '66 (27).jpg', '66 (13).jpg', '66 (19).jpg', '66 (2).jpg', '66 (29).jpg', '66 (17).jpg', '66 (25).jpg', '66 (3).jpg', '66 (33).jpg', '66 (15).jpg', '66 (21).jpg', '66 (23).jpg', '66 (31).jpg', '66 (7).jpg', '66 (38).jpg', '66 (5).jpg', '66 (39).jpg', '66 (41).jpg', '66 (40).jpg', '66 (6).jpg', '66 (35).jpg', '66 (8).jpg', '66 (37).jpg', '66 (4).jpg', '66 (9).jpg', '67 (11).jpg', '67 (17).jpg', '67 (13).jpg', '67 (12).jpg', '67 (2).jpg', '67 (14).jpg', '67 (15).jpg', '67 (21).jpg', '67 (23).jpg', '67 (16).jpg', '67 (19).jpg', '67 (10).jpg', '67 (1).jpg', '67 (30).jpg', '67 (29).jpg', '67 (3).jpg', '67 (33).jpg', '67 (31).jpg', '67 (25).jpg', '67 (5).jpg', '67 (4).jpg', '67 (6).jpg', '67 (28).jpg', '67 (32).jpg', '67 (27).jpg', '67 (7).jpg', '68 (20).jpg', '68 (10).jpg', '67 (9).jpg', '68 (12).jpg', '67 (8).jpg', '68 (22).jpg', '68 (14).jpg', '68 (26).jpg', '68 (18).jpg', '68 (1).jpg', '68 (2).jpg', '68 (16).jpg', '68 (24).jpg', '68 (4).jpg', '68 (34).jpg', '68 (27).jpg', '68 (35).jpg', '68 (3).jpg', '68 (30).jpg', '68 (31).jpg', '68 (28).jpg', '68 (29).jpg', '68 (36).jpg', '68 (33).jpg', '68 (5).jpg', '68 (32).jpg', '69 (2).jpg', '69 (1).jpg', '68 (8).jpg', '69 (11).jpg', '69 (19).jpg', '69 (17).jpg', '69 (16).jpg', '69 (10).jpg', '68 (6).jpg', '69 (14).jpg', '69 (12).jpg', '69 (13).jpg', '69 (15).jpg', '69 (26).jpg', '69 (23).jpg', '69 (21).jpg', '69 (3).jpg', '69 (28).jpg', '69 (24).jpg', '69 (31).jpg', '69 (27).jpg', '69 (30).jpg', '69 (29).jpg', '69 (25).jpg', '69 (22).jpg', '70 (10).jpg', '69 (36).jpg', '69 (9).jpg', '70 (1).jpg', '69 (6).jpg', '69 (7).jpg', '69 (8).jpg', '69 (33).jpg', '69 (5).jpg', '69 (34).jpg', '69 (4).jpg', '69 (35).jpg', '69 (32).jpg', '70 (15).jpg', '70 (17).jpg', '70 (29).jpg', '70 (13).jpg', '70 (11).jpg', '70 (21).jpg', '70 (3).jpg', '70 (12).jpg', '70 (27).jpg', '70 (19).jpg', '70 (25).jpg', '70 (2).jpg', '70 (23).jpg', '70 (44).jpg', '70 (31).jpg', '70 (37).jpg', '70 (47).jpg', '70 (4).jpg', '70 (45).jpg', '70 (46).jpg', '70 (35).jpg', '70 (42).jpg', '70 (43).jpg', '70 (33).jpg', '70 (39).jpg', '70 (41).jpg', '71 (10).jpg', '71 (14).jpg', '71 (16).jpg', '71 (18).jpg', '70 (6).jpg', '70 (7).jpg', '70 (5).jpg', '70 (8).jpg', '71 (2).jpg', '71 (12).jpg', '70 (9).jpg', '70 (48).jpg', '71 (1).jpg', '71 (34).jpg', '71 (3).jpg', '71 (22).jpg', '71 (4).jpg', '71 (28).jpg', '71 (32).jpg', '71 (24).jpg', '71 (30).jpg', '71 (38).jpg', '71 (20).jpg', '71 (26).jpg', '71 (36).jpg', '71 (5).jpg', '71 (46).jpg', '71 (44).jpg', '71 (6).jpg', '72 (10).jpg', '71 (42).jpg', '72 (1).jpg', '71 (9).jpg', '71 (7).jpg', '71 (48).jpg', '72 (11).jpg', '71 (8).jpg', '71 (40).jpg', '72 (17).jpg', '72 (18).jpg', '72 (22).jpg', '72 (13).jpg', '72 (23).jpg', '72 (24).jpg', '72 (20).jpg', '72 (19).jpg', '72 (15).jpg', '72 (2).jpg', '72 (21).jpg', '72 (16).jpg', '72 (3).jpg', '72 (32).jpg', '72 (4).jpg', '72 (5).jpg', '72 (31).jpg', '72 (28).jpg', '72 (29).jpg', '72 (25).jpg', '72 (27).jpg', '72 (7).jpg', '72 (6).jpg', '72 (30).jpg', '72 (26).jpg', '73 (19).jpg', '73 (18).jpg', '73 (1).jpg', '73 (17).jpg', '73 (13).jpg', '73 (14).jpg', '73 (11).jpg', '73 (15).jpg', '73 (10).jpg', '72 (9).jpg', '73 (12).jpg', '72 (8).jpg', '73 (16).jpg', '73 (28).jpg', '73 (21).jpg', '73 (3).jpg', '73 (22).jpg', '73 (2).jpg', '73 (24).jpg', '73 (34).jpg', '73 (23).jpg', '73 (32).jpg', '73 (30).jpg', '73 (26).jpg', '73 (25).jpg', '73 (20).jpg', '73 (9).jpg', '73 (7).jpg', '73 (39).jpg', '73 (5).jpg', '74 (12).jpg', '73 (8).jpg', '74 (1).jpg', '73 (6).jpg', '73 (38).jpg', '74 (10).jpg', '73 (36).jpg', '74 (11).jpg', '73 (4).jpg', '74 (22).jpg', '74 (25).jpg', '74 (2).jpg', '74 (23).jpg', '74 (20).jpg', '74 (14).jpg', '74 (16).jpg', '74 (18).jpg', '74 (4).jpg', '74 (29).jpg', '74 (27).jpg', '74 (39).jpg', '74 (3).jpg', '74 (33).jpg', '74 (31).jpg', '74 (37).jpg', '74 (35).jpg', '74 (40).jpg', '74 (45).jpg', '74 (41).jpg', '74 (44).jpg', '74 (6).jpg', '74 (42).jpg', '74 (46).jpg', '74 (43).jpg', '74 (5).jpg', '75 (13).jpg', '74 (7).jpg', '75 (11).jpg', '75 (14).jpg', '75 (12).jpg', '75 (10).jpg', '75 (1).jpg', '74 (8).jpg', '74 (9).jpg', '75 (15).jpg', '75 (28).jpg', '75 (26).jpg', '75 (18).jpg', '75 (2).jpg', '75 (34).jpg', '75 (30).jpg', '75 (20).jpg', '75 (22).jpg', '75 (24).jpg', '75 (32).jpg', '75 (3).jpg', '75 (16).jpg', '75 (46).jpg', '75 (49).jpg', '75 (40).jpg', '75 (38).jpg', '75 (8).jpg', '75 (42).jpg', '75 (5).jpg', '75 (6).jpg', '75 (44).jpg', '75 (36).jpg', '75 (7).jpg', '75 (4).jpg', '75 (48).jpg', '76 (23).jpg', '76 (21).jpg', '76 (12).jpg', '76 (25).jpg', '76 (17).jpg', '76 (19).jpg', '75 (9).jpg', '76 (10).jpg', '76 (1).jpg', '76 (2).jpg', '76 (13).jpg', '76 (15).jpg', '76 (41).jpg', '76 (43).jpg', '76 (33).jpg', '76 (27).jpg', '76 (39).jpg', '76 (31).jpg', '76 (42).jpg', '76 (29).jpg', '76 (40).jpg', '76 (37).jpg', '76 (3).jpg', '76 (35).jpg', '76 (4).jpg', '76 (7).jpg', '77 (20).jpg', '77 (16).jpg', '76 (6).jpg', '77 (18).jpg', '77 (12).jpg', '76 (9).jpg', '77 (1).jpg', '77 (10).jpg', '76 (8).jpg', '76 (5).jpg', '77 (14).jpg', '77 (2).jpg', '77 (26).jpg', '77 (38).jpg', '77 (30).jpg', '77 (36).jpg', '77 (22).jpg', '77 (24).jpg', '77 (35).jpg', '77 (34).jpg', '77 (28).jpg', '77 (3).jpg', '77 (32).jpg', '77 (37).jpg', '78 (1).jpg', '77 (4).jpg', '77 (43).jpg', '77 (8).jpg', '77 (41).jpg', '77 (40).jpg', '77 (9).jpg', '77 (7).jpg', '77 (6).jpg', '77 (5).jpg', '77 (42).jpg', '77 (39).jpg', '78 (26).jpg', '78 (19).jpg', '78 (28).jpg', '78 (13).jpg', '78 (11).jpg', '78 (3).jpg', '78 (25).jpg', '78 (21).jpg', '78 (10).jpg', '78 (17).jpg', '78 (23).jpg', '78 (2).jpg', '78 (15).jpg', '78 (32).jpg', '78 (39).jpg', '78 (34).jpg', '78 (37).jpg', '78 (42).jpg', '78 (38).jpg', '78 (36).jpg', '78 (41).jpg', '78 (35).jpg', '78 (4).jpg', '78 (30).jpg', '78 (40).jpg', '79 (17).jpg', '79 (16).jpg', '78 (9).jpg', '78 (5).jpg', '79 (12).jpg', '79 (10).jpg', '79 (13).jpg', '78 (7).jpg', '79 (11).jpg', '78 (8).jpg', '79 (1).jpg', '79 (14).jpg', '78 (6).jpg', '79 (22).jpg', '79 (2).jpg', '79 (25).jpg', '79 (23).jpg', '79 (27).jpg', '79 (19).jpg', '79 (18).jpg', '79 (21).jpg', '79 (24).jpg', '79 (26).jpg', '79 (20).jpg', '79 (4).jpg', '79 (3).jpg', '80 (18).jpg', '79 (5).jpg', '79 (6).jpg', '79 (9).jpg', '80 (15).jpg', '80 (14).jpg', '80 (10).jpg', '80 (2).jpg', '80 (1).jpg', '80 (20).jpg', '79 (7).jpg', '80 (12).jpg', '80 (16).jpg', '79 (8).jpg', '80 (28).jpg', '80 (37).jpg', '80 (30).jpg', '80 (32).jpg', '80 (22).jpg', '80 (33).jpg', '80 (26).jpg', '80 (35).jpg', '80 (38).jpg', '80 (34).jpg', '80 (24).jpg', '80 (3).jpg', '80 (36).jpg', '81 (11).jpg', '80 (5).jpg', '80 (40).jpg', '80 (39).jpg', '80 (4).jpg', '81 (10).jpg', '80 (6).jpg', '81 (12).jpg', '81 (13).jpg', '81 (1).jpg', '80 (7).jpg', '81 (15).jpg', '80 (8).jpg', '81 (29).jpg', '81 (27).jpg', '81 (21).jpg', '81 (17).jpg', '81 (37).jpg', '81 (31).jpg', '81 (35).jpg', '81 (25).jpg', '81 (19).jpg', '81 (23).jpg', '81 (33).jpg', '81 (3).jpg', '81 (2).jpg', '81 (39).jpg', '81 (4).jpg', '81 (9).jpg', '81 (41).jpg', '82 (10).jpg', '81 (43).jpg', '81 (7).jpg', '81 (44).jpg', '82 (12).jpg', '82 (1).jpg', '81 (6).jpg', '81 (5).jpg', '81 (8).jpg', '82 (20).jpg', '82 (17).jpg', '82 (2).jpg', '82 (16).jpg', '82 (23).jpg', '82 (19).jpg', '82 (18).jpg', '82 (15).jpg', '82 (22).jpg', '82 (14).jpg', '82 (21).jpg', '82 (24).jpg', '82 (31).jpg', '82 (30).jpg', '82 (7).jpg', '82 (4).jpg', '82 (25).jpg', '82 (9).jpg', '82 (8).jpg', '82 (27).jpg', '82 (26).jpg', '82 (6).jpg', '82 (29).jpg', '82 (3).jpg', '82 (5).jpg', '82 (28).jpg', '83 (17).jpg', '83 (14).jpg', '83 (11).jpg', '83 (19).jpg', '83 (13).jpg', '83 (1).jpg', '83 (2).jpg', '83 (18).jpg', '83 (12).jpg', '83 (10).jpg', '83 (16).jpg', '83 (15).jpg', '83 (36).jpg', '83 (31).jpg', '83 (35).jpg', '83 (23).jpg', '83 (20).jpg', '83 (25).jpg', '83 (33).jpg', '83 (29).jpg', '83 (22).jpg', '83 (3).jpg', '83 (27).jpg', '83 (21).jpg', '83 (38).jpg', '83 (8).jpg', '84 (1).jpg', '83 (6).jpg', '83 (5).jpg', '83 (7).jpg', '83 (37).jpg', '84 (10).jpg', '84 (11).jpg', '83 (9).jpg', '83 (4).jpg', '84 (17).jpg', '84 (20).jpg', '84 (13).jpg', '84 (24).jpg', '84 (2).jpg', '84 (15).jpg', '84 (14).jpg', '84 (22).jpg', '84 (18).jpg', '84 (26).jpg', '84 (16).jpg', '84 (12).jpg', '84 (27).jpg', '84 (28).jpg', '84 (3).jpg', '84 (29).jpg', '84 (30).jpg', '84 (31).jpg', '84 (33).jpg', '84 (36).jpg', '84 (35).jpg', '84 (38).jpg', '84 (34).jpg', '84 (37).jpg', '84 (32).jpg', '84 (39).jpg', '84 (8).jpg', '85 (21).jpg', '85 (16).jpg', '85 (15).jpg', '84 (4).jpg', '85 (10).jpg', '85 (20).jpg', '85 (2).jpg', '85 (13).jpg', '84 (5).jpg', '85 (11).jpg', '85 (19).jpg', '84 (40).jpg', '85 (1).jpg', '85 (17).jpg', '84 (6).jpg', '84 (7).jpg', '84 (9).jpg', '85 (18).jpg', '86 (18).jpg', '86 (19).jpg', '85 (5).jpg', '86 (10).jpg', '85 (9).jpg', '86 (23).jpg', '85 (3).jpg', '86 (21).jpg', '86 (1).jpg', '86 (22).jpg', '85 (6).jpg', '86 (16).jpg', '86 (14).jpg', '86 (20).jpg', '86 (2).jpg', '85 (4).jpg', '85 (8).jpg', '86 (12).jpg', '85 (7).jpg', '86 (8).jpg', '87 (11).jpg', '86 (24).jpg', '87 (10).jpg', '86 (29).jpg', '86 (4).jpg', '87 (1).jpg', '86 (35).jpg', '86 (32).jpg', '86 (34).jpg', '86 (36).jpg', '86 (6).jpg', '86 (27).jpg', '86 (33).jpg', '86 (30).jpg', '86 (26).jpg', '86 (31).jpg', '86 (28).jpg', '86 (25).jpg', '86 (3).jpg', '87 (35).jpg', '87 (39).jpg', '87 (37).jpg', '87 (14).jpg', '87 (33).jpg', '87 (23).jpg', '87 (17).jpg', '87 (15).jpg', '87 (4).jpg', '87 (29).jpg', '87 (2).jpg', '87 (3).jpg', '87 (27).jpg', '87 (31).jpg', '87 (12).jpg', '87 (25).jpg', '87 (13).jpg', '87 (21).jpg', '87 (19).jpg', '87 (42).jpg', '87 (44).jpg', '87 (9).jpg', '88 (17).jpg', '87 (40).jpg', '87 (8).jpg', '88 (19).jpg', '88 (15).jpg', '88 (13).jpg', '88 (16).jpg', '87 (7).jpg', '88 (2).jpg', '87 (41).jpg', '87 (6).jpg', '88 (11).jpg', '87 (43).jpg', '88 (18).jpg', '87 (5).jpg', '88 (12).jpg', '88 (10).jpg', '88 (14).jpg', '88 (1).jpg', '88 (3).jpg', '88 (30).jpg', '88 (24).jpg', '88 (8).jpg', '89 (10).jpg', '88 (28).jpg', '88 (4).jpg', '88 (20).jpg', '88 (26).jpg', '88 (6).jpg', '88 (21).jpg', '88 (7).jpg', '88 (34).jpg', '88 (22).jpg', '88 (5).jpg', '88 (37).jpg', '88 (35).jpg', '89 (1).jpg', '88 (32).jpg', '88 (9).jpg', '88 (36).jpg', '89 (29).jpg', '89 (23).jpg', '89 (25).jpg', '89 (39).jpg', '89 (13).jpg', '89 (33).jpg', '89 (19).jpg', '89 (38).jpg', '89 (21).jpg', '89 (16).jpg', '89 (2).jpg', '89 (27).jpg', '89 (35).jpg', '89 (34).jpg', '89 (4).jpg', '89 (14).jpg', '89 (12).jpg', '89 (36).jpg', '89 (31).jpg', '89 (15).jpg', '89 (17).jpg', '89 (37).jpg', '89 (11).jpg', '89 (3).jpg', '90 (2).jpg', '89 (8).jpg', '90 (13).jpg', '89 (7).jpg', '90 (23).jpg', '90 (21).jpg', '90 (17).jpg', '89 (5).jpg', '89 (41).jpg', '90 (15).jpg', '90 (11).jpg', '90 (1).jpg', '89 (9).jpg', '90 (19).jpg', '90 (10).jpg', '89 (42).jpg', '90 (24).jpg', '89 (6).jpg', '89 (40).jpg', '90 (12).jpg', '90 (22).jpg', '89 (43).jpg', '90 (25).jpg', '90 (7).jpg', '91 (15).jpg', '91 (10).jpg', '90 (3).jpg', '90 (26).jpg', '91 (1).jpg', '90 (9).jpg', '90 (27).jpg', '91 (2).jpg', '90 (28).jpg', '90 (31).jpg', '91 (13).jpg', '91 (11).jpg', '90 (30).jpg', '90 (5).jpg', '90 (6).jpg', '90 (29).jpg', '90 (4).jpg', '91 (12).jpg', '90 (32).jpg', '91 (19).jpg', '91 (17).jpg', '91 (14).jpg', '90 (8).jpg', '91 (8).jpg', '91 (33).jpg', '91 (9).jpg', '91 (32).jpg', '91 (29).jpg', '91 (21).jpg', '91 (3).jpg', '91 (31).jpg', '91 (30).jpg', '91 (36).jpg', '91 (34).jpg', '91 (6).jpg', '91 (5).jpg', '91 (25).jpg', '91 (7).jpg', '91 (39).jpg', '91 (27).jpg', '91 (38).jpg', '91 (23).jpg', '91 (37).jpg', '91 (35).jpg', '91 (40).jpg', '91 (4).jpg', '92 (3).jpg', '92 (19).jpg', '92 (13).jpg', '92 (27).jpg', '92 (34).jpg', '92 (31).jpg', '92 (21).jpg', '92 (38).jpg', '92 (2).jpg', '92 (1).jpg', '92 (10).jpg', '92 (17).jpg', '92 (11).jpg', '92 (32).jpg', '92 (4).jpg', '92 (15).jpg', '92 (14).jpg', '92 (36).jpg', '92 (12).jpg', '92 (33).jpg', '92 (29).jpg', '92 (25).jpg', '92 (23).jpg', '92 (20).jpg', '93 (14).jpg', '92 (6).jpg', '92 (7).jpg', '93 (12).jpg', '92 (40).jpg', '92 (5).jpg', '93 (20).jpg', '93 (26).jpg', '93 (22).jpg', '93 (2).jpg', '93 (18).jpg', '93 (1).jpg', '93 (10).jpg', '92 (8).jpg', '92 (9).jpg', '92 (42).jpg', '93 (17).jpg', '93 (16).jpg', '93 (15).jpg', '93 (27).jpg', '93 (28).jpg', '93 (24).jpg', '93 (11).jpg', '93 (13).jpg', '93 (7).jpg', '93 (8).jpg', '93 (34).jpg', '94 (1).jpg', '94 (15).jpg', '94 (10).jpg', '94 (14).jpg', '93 (31).jpg', '93 (5).jpg', '93 (32).jpg', '94 (11).jpg', '94 (16).jpg', '93 (6).jpg', '93 (35).jpg', '93 (4).jpg', '93 (3).jpg', '94 (12).jpg', '93 (9).jpg', '93 (30).jpg', '93 (29).jpg', '94 (13).jpg', '93 (33).jpg', '93 (36).jpg', '94 (44).jpg', '94 (4).jpg', '94 (6).jpg', '94 (31).jpg', '94 (3).jpg', '94 (27).jpg', '94 (23).jpg', '94 (7).jpg', '94 (18).jpg', '94 (35).jpg', '94 (33).jpg', '94 (46).jpg', '94 (19).jpg', '94 (5).jpg', '94 (37).jpg', '94 (41).jpg', '94 (29).jpg', '94 (45).jpg', '94 (17).jpg', '94 (39).jpg', '94 (21).jpg', '94 (43).jpg', '94 (25).jpg', '94 (2).jpg', '97 (16).jpg', '97 (10).jpg', '97 (12).jpg', '97 (36).jpg', '97 (3).jpg', '97 (11).jpg', '97 (13).jpg', '97 (24).jpg', '97 (28).jpg', '97 (34).jpg', '97 (14).jpg', '97 (2).jpg', '97 (1).jpg', '97 (20).jpg', '97 (15).jpg', '94 (9).jpg', '97 (32).jpg', '97 (18).jpg', '97 (26).jpg', '97 (35).jpg', '97 (22).jpg', '97 (30).jpg', '94 (8).jpg', '97 (37).jpg', '97 (40).jpg', '97 (4).jpg', '97 (5).jpg', '97 (9).jpg', '97 (39).jpg', '97 (38).jpg', '97 (7).jpg', '97 (8).jpg', '97 (6).jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "stroke_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "if os.path.exists(stroke_folder):\n",
        "    print(\"✅ Stroke Folder Found!\")\n",
        "    print(\"📂 Available Images:\", os.listdir(stroke_folder))\n",
        "else:\n",
        "    print(\"❌ Error: Stroke folder not found! Check your Google Drive path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckPaGrS3fnI1",
        "outputId": "f953ce3a-edf2-41fa-8b63-e49d684b6b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IoU Score: 0.3366\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "\n",
        "# ✅ Simulated Example: Replace these with your actual predicted and ground truth masks\n",
        "# Assume binary_mask is already generated from U-Net prediction\n",
        "binary_mask = np.random.randint(0, 2, (256, 256), dtype=np.uint8)  # Dummy prediction\n",
        "ground_truth_mask = np.random.randint(0, 2, (256, 256), dtype=np.uint8)  # Dummy ground truth\n",
        "\n",
        "# ✅ Ensure both masks have the same shape\n",
        "if binary_mask.shape != ground_truth_mask.shape:\n",
        "    print(\"❌ Error: The shape of binary_mask and ground_truth_mask must match!\")\n",
        "else:\n",
        "    # Compute IoU\n",
        "    iou = MeanIoU(num_classes=2)\n",
        "    iou.update_state(binary_mask, ground_truth_mask)\n",
        "    print(f\"IoU Score: {iou.result().numpy():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_vGCqoQjwLGl",
        "outputId": "21318b0b-c371-4fd5-9f40-6a78874bf712"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling3d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │          \u001b[38;5;34m27,680\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │          \u001b[38;5;34m27,680\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_3 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │          \u001b[38;5;34m27,680\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_4 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m55,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_5 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m110,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_6 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m110,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_7 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m221,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_8 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m442,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_9 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m442,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling3d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m514\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,503,138</span> (5.73 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,503,138\u001b[0m (5.73 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,501,794</span> (5.73 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,501,794\u001b[0m (5.73 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define 3D DenseNet model\n",
        "def densenet_3d(input_shape=(128, 128, 128, 1), num_classes=2):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = layers.Conv3D(32, (3,3,3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.MaxPooling3D(pool_size=(2,2,2))(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    for _ in range(3):\n",
        "        x = layers.Conv3D(32, (3,3,3), padding='same', activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.MaxPooling3D(pool_size=(2,2,2))(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    for _ in range(3):\n",
        "        x = layers.Conv3D(64, (3,3,3), padding='same', activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.MaxPooling3D(pool_size=(2,2,2))(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    for _ in range(3):\n",
        "        x = layers.Conv3D(128, (3,3,3), padding='same', activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = densenet_3d()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-C-VdJyKcC",
        "outputId": "166d1304-e14c-4440-eafe-e04490748fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd3KbzAkyWNw",
        "outputId": "acfe7681-1638-422c-87fd-a00af0aad75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Folders: ['Copy of UNIT-I.docx', 'Photo album.gslides', 'Untitled presentation (2).gslides', \"I am sharing 'Seminar ppt\", 'SANTHIYA.....19PPT', 'abstract (2).pptx', 'micro (1).pptx', 'micro.pptx', 'abstract (1).pptx', 'abstract.pptx', 'seminar (1).pptx', 'E-learning ppt.pptx', 'SCREENLESS DISPLAY TECHNOLOGY (1).pptx', 'SCREENLESS DISPLAY TECHNOLOGY.pptx', 'seminar.pptx', 'data to the spreadsheet.png', 'template sheet.png', 'currency to US Dollars.png', 'country column.png', 'difference between discount and sale price.png', 'average.png', 'sum of prices.png', 'freeze 1st row.png', 'cell format.png', 'Untitled document (18).gdoc', 'CS3362 - DATA SCIENCE.docx', 'Excel 1 completed...xlsx', 'Li-Fi.docx', 'Untitled presentation (1).gslides', 'Copy of Eleanor · SlidesCarnival (4).gslides', 'Copy of Eleanor · SlidesCarnival (3).gslides', 'Copy of Eleanor · SlidesCarnival (2).gslides', 'Copy of Eleanor · SlidesCarnival (1).gslides', 'Copy of Eleanor · SlidesCarnival.gslides', 'Untitled presentation.gslides', 'Untitled document (17).gdoc', 'Untitled document (16).gdoc', 'Untitled document (15).gdoc', 'Untitled document (14).gdoc', 'Untitled document (13).gdoc', 'Untitled document (12).gdoc', 'Untitled document (11).gdoc', 'Untitled document (10).gdoc', 'Colab Notebooks', 'State Bank Collect sandy (1).jpg', 'State Bank Collect sandy.jpg', 'code galata certificate.pdf', 'Untitled document (9).gdoc', '<html>.gdoc', 'Untitled document (8).gdoc', 'Untitled document (7).gdoc', 'Presentation (1).pptx', 'Presentation (1).gslides', 'ADS_Phase_1.pdf', 'payment screenshot ', 'ADS_Phase_1 (2).gdoc', 'ADS_Phase_1 (1).gdoc', 'ADS_Phase_1.gdoc', 'ADS_Phase_3 (1).docx.pdf', 'ADS_Phase_3.docx.gdoc', 'ADS_Phase_3.docx.pdf', 'ADS_Phase_4 (1).docx.gdoc', 'ADS_Phase_4.docx.pdf', 'DAC_Phase 5.pdf', 'project video.mp4', 'DAC_Phase 5.gdoc', 'final project.mp4', 'Copy of final project.mp4', 'ADS_Phase_4.docx.gdoc', 'Untitled document (6).gdoc', 'Mini Project Evaluation Sheet 2.docx', 'Untitled document (5).gdoc', 'Untitled document (4).gdoc', 'Untitled document (3).gdoc', 'Untitled document (2).gdoc', 'Kaniska M P Resume final (1).pdf', 'Kaniska M P Resume final (2).gdoc', 'Kaniska M P Resume final.pdf', 'Kaniska M P Resume final (1).gdoc', 'Kaniska M P Resume final.gdoc', 'santhiya final resume (1).docx', 'sarumathi final resume.gdoc', 'santhiya final resume.docx.pdf', 'santhiya final resume.docx', 'santhiya final resume (1).docx.gdoc', 'Aysha (1).pdf', 'Aysha (2).gdoc', 'santhiya final resume.docx.gdoc', 'Aysha.pdf', 'PROBLEM STATEMENT KARUR & NAMAKKAL -ECE.xlsx', 'geetha resume.docx.pdf', 'SANTHIYA 1.docx.pdf', 'amd.pdf', 'Aysha - Bar chart 1.gsheet', 'Aysha (1).gdoc', 'Resume (2).gdoc', 'Resume.gdoc', 'SANTHIYA 1 (1).docx', 'SANTHIYA 1 (2).docx.gdoc', 'students namelist 6th sem cse.xlsx.pdf', 'Copy of SArumathi 1.docx.gdoc', 'Untitled document (1).gdoc', 'SANTHIYA 1.docx', 'SANTHIYA 1 (1).docx.gdoc', 'geetha resume.docx.gdoc', 'geetha.docx', 'SARUMATHI A.docx', 'SARUMATHI A (1).gdoc', 'geetha.gdoc', 'M. NAGALAKSHMI .docx', 'K.HARSHAVARTHINI .docx', 'K.HARSHAVARTHINI .gdoc', 'Project Confirmation.pdf', 'Project Confirmation (1).gdoc', 'Project Confirmation.gdoc', 'Project Confirmation.docx', 'Project Confirmation .............docx', 'null-2 (1).docx', 'null-2.docx', 'HOMOMORPHISM - Copy (1).docx', 'HOMOMORPHISM - Copy.docx', 'HOMOMORPHISM - Copy.docx (1).pdf', 'Chettinad college.pdf', 'Chettinad college.gdoc', 'BATCH-7 ppt (1).pptx', 'BATCH-14 ppt (1).pptx', 'EDII IDEA SUBMISSION.pdf', 'EDII IDEA SUBMISSION.gdoc', 'EDII IDEA SUBMISSION FINAL.docx', 'Mini Project Evaluation With EDII REGI.docx', 'SANTHIYA 1.gdoc', 'BATCH-14 ppt.pptx', 'devops (1).docx', 'devops.docx', 'Question bank all 5 units.pdf', 'Question bank all 5 units.gdoc', 'Untitled document.gdoc', 'library.xlsx', 'library (1).xlsx.pdf', 'library.xlsx.pdf', 'original resume.gdoc', 'SANTHIYA 1.docx.gdoc', 'Aysha.gdoc', 'SARUMATHI A.pdf', 'SARUMATHI A.gdoc', 'Event Inventory - Smart Import.xlsx', 'original resume.pdf', 'Photo.pdf', 'Photo (1).jpg', 'Untitled Jam.gjam', 'Untitled Jam.pdf', 'Charu.docx', 'Resume.docx', 'Resume (1).pdf', 'SIH2024_MY_Presentation and Sample PPT.pptx', 'SIH2024_IDEA_Presentation_Format.pptx', 'Resume (1).gdoc', 'My drive', 'Screenshot 2024-09-22 115938.pdf', 'Int CN Answer Key.pdf', 'Int CN Answer Key.gdoc', 'WhatsApp Image 2024-09-24 at 9.18.17 PM.jpeg', 'Photo', 'cse.xlsx', 'yolo_training', 'model2.zip', 'p15.c - nm program - Visual Studio Code 2024-10-23 20-26-49.mp4', '920221104043_Santhiya K_CN.mp4', 'SANTHIYA (1).pdf', 'MyScraoingProject', 'SANTHIYA K (1).pdf', 'SANTHIYA K.pdf', 'சொல்Spot-Team.pdf', 'Team-சொல்Spot.pdf', 'Add a heading (3).pdf', 'Screenshot_2025-02-20-11-22-34-26_4336b74596784d9a2aa81f87c2016f50.jpg', 'dcm file.zip', 'WhatsApp Audio 2025-03-25 at 11.56.10_a8d1dc53.dat.unknown', 'Copy of WhatsApp Audio 2025-03-25 at 11.56.10_a8d1dc53.dat.unknown', 'final_project', 'brain_stroke', 'unet_model.keras', 'Photo.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "base_path = \"/content/drive/MyDrive/\"\n",
        "print(\"Available Folders:\", os.listdir(base_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYpwH_LQya2T",
        "outputId": "63446327-8b7c-434e-c3c6-d0ff60b17c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inside brain_stroke: ['Brain_Data_Organised']\n"
          ]
        }
      ],
      "source": [
        "brain_stroke_path = os.path.join(base_path, \"brain_stroke\")\n",
        "print(\"Inside brain_stroke:\", os.listdir(brain_stroke_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p6R_aYcysMj",
        "outputId": "d127423b-61b9-4b01-d96c-a37f54c5ead3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 Files in Brain_Data_Organised: ['Stroke', 'Normal', 'Masks', '58 (10).jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"\n",
        "print(\"📂 Files in Brain_Data_Organised:\", os.listdir(image_folder))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwiBe7Yvy7Yf"
      },
      "outputs": [],
      "source": [
        "image_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx9_PLUBzXAc",
        "outputId": "170a646f-7f5e-48e8-de05-7e8e5d2ab27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(950, 650, 650)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Path to the \"Stroke\" folder\n",
        "image_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "\n",
        "# Get all image filenames in the folder\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "\n",
        "# Initialize a list to store the image data\n",
        "images = []\n",
        "\n",
        "# Loop through each image file\n",
        "for image_file in image_files:\n",
        "    # Construct the full path of the image\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "    # Open the image\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Append the image array to the list\n",
        "    images.append(img_array)\n",
        "\n",
        "# Convert the list of images into a single NumPy array\n",
        "images_np = np.array(images)\n",
        "\n",
        "# Check the shape of the NumPy array (optional)\n",
        "print(images_np.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPBGO2uaz0UU",
        "outputId": "1950154a-f700-4ffe-939f-8e088861421c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "# Normalize images to the range [0, 1]\n",
        "images_np = images_np.astype('float32') / 255.0\n",
        "\n",
        "# Check the new min and max values (optional)\n",
        "print(images_np.min(), images_np.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfn6SYmG0MvR",
        "outputId": "2f1cd1a8-ffe4-49fb-b87e-2367f28da98d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(950, 650, 650)\n"
          ]
        }
      ],
      "source": [
        "# Path to the \"Masks\" folder\n",
        "mask_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Masks\"\n",
        "\n",
        "# Get all mask filenames in the folder\n",
        "mask_files = [f for f in os.listdir(mask_folder) if f.endswith('.jpg')]\n",
        "\n",
        "# Initialize a list to store the mask data\n",
        "masks = []\n",
        "\n",
        "# Loop through each mask file\n",
        "for mask_file in mask_files:\n",
        "    # Construct the full path of the mask\n",
        "    mask_path = os.path.join(mask_folder, mask_file)\n",
        "\n",
        "    # Open the mask\n",
        "    mask = Image.open(mask_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "    # Convert the mask to a NumPy array\n",
        "    mask_array = np.array(mask)\n",
        "\n",
        "    # Normalize mask to be 0 or 1 (if necessary)\n",
        "    mask_array = mask_array / 255.0\n",
        "\n",
        "    # Append the mask array to the list\n",
        "    masks.append(mask_array)\n",
        "\n",
        "# Convert the list of masks into a single NumPy array\n",
        "masks_np = np.array(masks)\n",
        "\n",
        "# Check the shape of the mask array (optional)\n",
        "print(masks_np.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDdlWnhFpuoy",
        "outputId": "8c604a9b-8f62-4204-bb47-96e1bb47ec52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy pandas scikit-learn nibabel matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdeMA0DJtc8d",
        "outputId": "b783bcd4-0335-4c02-ee07-62e1cf433570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4WcclsFuHDB",
        "outputId": "dde7fb83-3c84-4c23-e5e1-3a04b8aa7e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Folder exists. Listing contents:\n",
            "['58 (10).jpg', '58 (2).jpg', '58 (19).jpg', '58 (17).jpg', '58 (13).jpg', '58 (12).jpg', '58 (21).jpg', '58 (15).jpg', '58 (1).jpg', '58 (20).jpg', '58 (11).jpg', '58 (18).jpg', '58 (25).jpg', '58 (23).jpg', '58 (30).jpg', '58 (24).jpg', '58 (29).jpg', '58 (3).jpg', '58 (32).jpg', '58 (31).jpg', '58 (22).jpg', '58 (28).jpg', '58 (33).jpg', '58 (27).jpg', '58 (26).jpg', '66 (1).jpg', '58 (6).jpg', '58 (34).jpg', '58 (4).jpg', '58 (8).jpg', '58 (9).jpg', '58 (35).jpg', '66 (12).jpg', '58 (5).jpg', '58 (36).jpg', '58 (7).jpg', '66 (10).jpg', '66 (11).jpg', '66 (27).jpg', '66 (13).jpg', '66 (19).jpg', '66 (2).jpg', '66 (29).jpg', '66 (17).jpg', '66 (25).jpg', '66 (3).jpg', '66 (33).jpg', '66 (15).jpg', '66 (21).jpg', '66 (23).jpg', '66 (31).jpg', '66 (7).jpg', '66 (38).jpg', '66 (5).jpg', '66 (39).jpg', '66 (41).jpg', '66 (40).jpg', '66 (6).jpg', '66 (35).jpg', '66 (8).jpg', '66 (37).jpg', '66 (4).jpg', '66 (9).jpg', '67 (11).jpg', '67 (17).jpg', '67 (13).jpg', '67 (12).jpg', '67 (2).jpg', '67 (14).jpg', '67 (15).jpg', '67 (21).jpg', '67 (23).jpg', '67 (16).jpg', '67 (19).jpg', '67 (10).jpg', '67 (1).jpg', '67 (30).jpg', '67 (29).jpg', '67 (3).jpg', '67 (33).jpg', '67 (31).jpg', '67 (25).jpg', '67 (5).jpg', '67 (4).jpg', '67 (6).jpg', '67 (28).jpg', '67 (32).jpg', '67 (27).jpg', '67 (7).jpg', '68 (20).jpg', '68 (10).jpg', '67 (9).jpg', '68 (12).jpg', '67 (8).jpg', '68 (22).jpg', '68 (14).jpg', '68 (26).jpg', '68 (18).jpg', '68 (1).jpg', '68 (2).jpg', '68 (16).jpg', '68 (24).jpg', '68 (4).jpg', '68 (34).jpg', '68 (27).jpg', '68 (35).jpg', '68 (3).jpg', '68 (30).jpg', '68 (31).jpg', '68 (28).jpg', '68 (29).jpg', '68 (36).jpg', '68 (33).jpg', '68 (5).jpg', '68 (32).jpg', '69 (2).jpg', '69 (1).jpg', '68 (8).jpg', '69 (11).jpg', '69 (19).jpg', '69 (17).jpg', '69 (16).jpg', '69 (10).jpg', '68 (6).jpg', '69 (14).jpg', '69 (12).jpg', '69 (13).jpg', '69 (15).jpg', '69 (26).jpg', '69 (23).jpg', '69 (21).jpg', '69 (3).jpg', '69 (28).jpg', '69 (24).jpg', '69 (31).jpg', '69 (27).jpg', '69 (30).jpg', '69 (29).jpg', '69 (25).jpg', '69 (22).jpg', '70 (10).jpg', '69 (36).jpg', '69 (9).jpg', '70 (1).jpg', '69 (6).jpg', '69 (7).jpg', '69 (8).jpg', '69 (33).jpg', '69 (5).jpg', '69 (34).jpg', '69 (4).jpg', '69 (35).jpg', '69 (32).jpg', '70 (15).jpg', '70 (17).jpg', '70 (29).jpg', '70 (13).jpg', '70 (11).jpg', '70 (21).jpg', '70 (3).jpg', '70 (12).jpg', '70 (27).jpg', '70 (19).jpg', '70 (25).jpg', '70 (2).jpg', '70 (23).jpg', '70 (44).jpg', '70 (31).jpg', '70 (37).jpg', '70 (47).jpg', '70 (4).jpg', '70 (45).jpg', '70 (46).jpg', '70 (35).jpg', '70 (42).jpg', '70 (43).jpg', '70 (33).jpg', '70 (39).jpg', '70 (41).jpg', '71 (10).jpg', '71 (14).jpg', '71 (16).jpg', '71 (18).jpg', '70 (6).jpg', '70 (7).jpg', '70 (5).jpg', '70 (8).jpg', '71 (2).jpg', '71 (12).jpg', '70 (9).jpg', '70 (48).jpg', '71 (1).jpg', '71 (34).jpg', '71 (3).jpg', '71 (22).jpg', '71 (4).jpg', '71 (28).jpg', '71 (32).jpg', '71 (24).jpg', '71 (30).jpg', '71 (38).jpg', '71 (20).jpg', '71 (26).jpg', '71 (36).jpg', '71 (5).jpg', '71 (46).jpg', '71 (44).jpg', '71 (6).jpg', '72 (10).jpg', '71 (42).jpg', '72 (1).jpg', '71 (9).jpg', '71 (7).jpg', '71 (48).jpg', '72 (11).jpg', '71 (8).jpg', '71 (40).jpg', '72 (17).jpg', '72 (18).jpg', '72 (22).jpg', '72 (13).jpg', '72 (23).jpg', '72 (24).jpg', '72 (20).jpg', '72 (19).jpg', '72 (15).jpg', '72 (2).jpg', '72 (21).jpg', '72 (16).jpg', '72 (3).jpg', '72 (32).jpg', '72 (4).jpg', '72 (5).jpg', '72 (31).jpg', '72 (28).jpg', '72 (29).jpg', '72 (25).jpg', '72 (27).jpg', '72 (7).jpg', '72 (6).jpg', '72 (30).jpg', '72 (26).jpg', '73 (19).jpg', '73 (18).jpg', '73 (1).jpg', '73 (17).jpg', '73 (13).jpg', '73 (14).jpg', '73 (11).jpg', '73 (15).jpg', '73 (10).jpg', '72 (9).jpg', '73 (12).jpg', '72 (8).jpg', '73 (16).jpg', '73 (28).jpg', '73 (21).jpg', '73 (3).jpg', '73 (22).jpg', '73 (2).jpg', '73 (24).jpg', '73 (34).jpg', '73 (23).jpg', '73 (32).jpg', '73 (30).jpg', '73 (26).jpg', '73 (25).jpg', '73 (20).jpg', '73 (9).jpg', '73 (7).jpg', '73 (39).jpg', '73 (5).jpg', '74 (12).jpg', '73 (8).jpg', '74 (1).jpg', '73 (6).jpg', '73 (38).jpg', '74 (10).jpg', '73 (36).jpg', '74 (11).jpg', '73 (4).jpg', '74 (22).jpg', '74 (25).jpg', '74 (2).jpg', '74 (23).jpg', '74 (20).jpg', '74 (14).jpg', '74 (16).jpg', '74 (18).jpg', '74 (4).jpg', '74 (29).jpg', '74 (27).jpg', '74 (39).jpg', '74 (3).jpg', '74 (33).jpg', '74 (31).jpg', '74 (37).jpg', '74 (35).jpg', '74 (40).jpg', '74 (45).jpg', '74 (41).jpg', '74 (44).jpg', '74 (6).jpg', '74 (42).jpg', '74 (46).jpg', '74 (43).jpg', '74 (5).jpg', '75 (13).jpg', '74 (7).jpg', '75 (11).jpg', '75 (14).jpg', '75 (12).jpg', '75 (10).jpg', '75 (1).jpg', '74 (8).jpg', '74 (9).jpg', '75 (15).jpg', '75 (28).jpg', '75 (26).jpg', '75 (18).jpg', '75 (2).jpg', '75 (34).jpg', '75 (30).jpg', '75 (20).jpg', '75 (22).jpg', '75 (24).jpg', '75 (32).jpg', '75 (3).jpg', '75 (16).jpg', '75 (46).jpg', '75 (49).jpg', '75 (40).jpg', '75 (38).jpg', '75 (8).jpg', '75 (42).jpg', '75 (5).jpg', '75 (6).jpg', '75 (44).jpg', '75 (36).jpg', '75 (7).jpg', '75 (4).jpg', '75 (48).jpg', '76 (23).jpg', '76 (21).jpg', '76 (12).jpg', '76 (25).jpg', '76 (17).jpg', '76 (19).jpg', '75 (9).jpg', '76 (10).jpg', '76 (1).jpg', '76 (2).jpg', '76 (13).jpg', '76 (15).jpg', '76 (41).jpg', '76 (43).jpg', '76 (33).jpg', '76 (27).jpg', '76 (39).jpg', '76 (31).jpg', '76 (42).jpg', '76 (29).jpg', '76 (40).jpg', '76 (37).jpg', '76 (3).jpg', '76 (35).jpg', '76 (4).jpg', '76 (7).jpg', '77 (20).jpg', '77 (16).jpg', '76 (6).jpg', '77 (18).jpg', '77 (12).jpg', '76 (9).jpg', '77 (1).jpg', '77 (10).jpg', '76 (8).jpg', '76 (5).jpg', '77 (14).jpg', '77 (2).jpg', '77 (26).jpg', '77 (38).jpg', '77 (30).jpg', '77 (36).jpg', '77 (22).jpg', '77 (24).jpg', '77 (35).jpg', '77 (34).jpg', '77 (28).jpg', '77 (3).jpg', '77 (32).jpg', '77 (37).jpg', '78 (1).jpg', '77 (4).jpg', '77 (43).jpg', '77 (8).jpg', '77 (41).jpg', '77 (40).jpg', '77 (9).jpg', '77 (7).jpg', '77 (6).jpg', '77 (5).jpg', '77 (42).jpg', '77 (39).jpg', '78 (26).jpg', '78 (19).jpg', '78 (28).jpg', '78 (13).jpg', '78 (11).jpg', '78 (3).jpg', '78 (25).jpg', '78 (21).jpg', '78 (10).jpg', '78 (17).jpg', '78 (23).jpg', '78 (2).jpg', '78 (15).jpg', '78 (32).jpg', '78 (39).jpg', '78 (34).jpg', '78 (37).jpg', '78 (42).jpg', '78 (38).jpg', '78 (36).jpg', '78 (41).jpg', '78 (35).jpg', '78 (4).jpg', '78 (30).jpg', '78 (40).jpg', '79 (17).jpg', '79 (16).jpg', '78 (9).jpg', '78 (5).jpg', '79 (12).jpg', '79 (10).jpg', '79 (13).jpg', '78 (7).jpg', '79 (11).jpg', '78 (8).jpg', '79 (1).jpg', '79 (14).jpg', '78 (6).jpg', '79 (22).jpg', '79 (2).jpg', '79 (25).jpg', '79 (23).jpg', '79 (27).jpg', '79 (19).jpg', '79 (18).jpg', '79 (21).jpg', '79 (24).jpg', '79 (26).jpg', '79 (20).jpg', '79 (4).jpg', '79 (3).jpg', '80 (18).jpg', '79 (5).jpg', '79 (6).jpg', '79 (9).jpg', '80 (15).jpg', '80 (14).jpg', '80 (10).jpg', '80 (2).jpg', '80 (1).jpg', '80 (20).jpg', '79 (7).jpg', '80 (12).jpg', '80 (16).jpg', '79 (8).jpg', '80 (28).jpg', '80 (37).jpg', '80 (30).jpg', '80 (32).jpg', '80 (22).jpg', '80 (33).jpg', '80 (26).jpg', '80 (35).jpg', '80 (38).jpg', '80 (34).jpg', '80 (24).jpg', '80 (3).jpg', '80 (36).jpg', '81 (11).jpg', '80 (5).jpg', '80 (40).jpg', '80 (39).jpg', '80 (4).jpg', '81 (10).jpg', '80 (6).jpg', '81 (12).jpg', '81 (13).jpg', '81 (1).jpg', '80 (7).jpg', '81 (15).jpg', '80 (8).jpg', '81 (29).jpg', '81 (27).jpg', '81 (21).jpg', '81 (17).jpg', '81 (37).jpg', '81 (31).jpg', '81 (35).jpg', '81 (25).jpg', '81 (19).jpg', '81 (23).jpg', '81 (33).jpg', '81 (3).jpg', '81 (2).jpg', '81 (39).jpg', '81 (4).jpg', '81 (9).jpg', '81 (41).jpg', '82 (10).jpg', '81 (43).jpg', '81 (7).jpg', '81 (44).jpg', '82 (12).jpg', '82 (1).jpg', '81 (6).jpg', '81 (5).jpg', '81 (8).jpg', '82 (20).jpg', '82 (17).jpg', '82 (2).jpg', '82 (16).jpg', '82 (23).jpg', '82 (19).jpg', '82 (18).jpg', '82 (15).jpg', '82 (22).jpg', '82 (14).jpg', '82 (21).jpg', '82 (24).jpg', '82 (31).jpg', '82 (30).jpg', '82 (7).jpg', '82 (4).jpg', '82 (25).jpg', '82 (9).jpg', '82 (8).jpg', '82 (27).jpg', '82 (26).jpg', '82 (6).jpg', '82 (29).jpg', '82 (3).jpg', '82 (5).jpg', '82 (28).jpg', '83 (17).jpg', '83 (14).jpg', '83 (11).jpg', '83 (19).jpg', '83 (13).jpg', '83 (1).jpg', '83 (2).jpg', '83 (18).jpg', '83 (12).jpg', '83 (10).jpg', '83 (16).jpg', '83 (15).jpg', '83 (36).jpg', '83 (31).jpg', '83 (35).jpg', '83 (23).jpg', '83 (20).jpg', '83 (25).jpg', '83 (33).jpg', '83 (29).jpg', '83 (22).jpg', '83 (3).jpg', '83 (27).jpg', '83 (21).jpg', '83 (38).jpg', '83 (8).jpg', '84 (1).jpg', '83 (6).jpg', '83 (5).jpg', '83 (7).jpg', '83 (37).jpg', '84 (10).jpg', '84 (11).jpg', '83 (9).jpg', '83 (4).jpg', '84 (17).jpg', '84 (20).jpg', '84 (13).jpg', '84 (24).jpg', '84 (2).jpg', '84 (15).jpg', '84 (14).jpg', '84 (22).jpg', '84 (18).jpg', '84 (26).jpg', '84 (16).jpg', '84 (12).jpg', '84 (27).jpg', '84 (28).jpg', '84 (3).jpg', '84 (29).jpg', '84 (30).jpg', '84 (31).jpg', '84 (33).jpg', '84 (36).jpg', '84 (35).jpg', '84 (38).jpg', '84 (34).jpg', '84 (37).jpg', '84 (32).jpg', '84 (39).jpg', '84 (8).jpg', '85 (21).jpg', '85 (16).jpg', '85 (15).jpg', '84 (4).jpg', '85 (10).jpg', '85 (20).jpg', '85 (2).jpg', '85 (13).jpg', '84 (5).jpg', '85 (11).jpg', '85 (19).jpg', '84 (40).jpg', '85 (1).jpg', '85 (17).jpg', '84 (6).jpg', '84 (7).jpg', '84 (9).jpg', '85 (18).jpg', '86 (18).jpg', '86 (19).jpg', '85 (5).jpg', '86 (10).jpg', '85 (9).jpg', '86 (23).jpg', '85 (3).jpg', '86 (21).jpg', '86 (1).jpg', '86 (22).jpg', '85 (6).jpg', '86 (16).jpg', '86 (14).jpg', '86 (20).jpg', '86 (2).jpg', '85 (4).jpg', '85 (8).jpg', '86 (12).jpg', '85 (7).jpg', '86 (8).jpg', '87 (11).jpg', '86 (24).jpg', '87 (10).jpg', '86 (29).jpg', '86 (4).jpg', '87 (1).jpg', '86 (35).jpg', '86 (32).jpg', '86 (34).jpg', '86 (36).jpg', '86 (6).jpg', '86 (27).jpg', '86 (33).jpg', '86 (30).jpg', '86 (26).jpg', '86 (31).jpg', '86 (28).jpg', '86 (25).jpg', '86 (3).jpg', '87 (35).jpg', '87 (39).jpg', '87 (37).jpg', '87 (14).jpg', '87 (33).jpg', '87 (23).jpg', '87 (17).jpg', '87 (15).jpg', '87 (4).jpg', '87 (29).jpg', '87 (2).jpg', '87 (3).jpg', '87 (27).jpg', '87 (31).jpg', '87 (12).jpg', '87 (25).jpg', '87 (13).jpg', '87 (21).jpg', '87 (19).jpg', '87 (42).jpg', '87 (44).jpg', '87 (9).jpg', '88 (17).jpg', '87 (40).jpg', '87 (8).jpg', '88 (19).jpg', '88 (15).jpg', '88 (13).jpg', '88 (16).jpg', '87 (7).jpg', '88 (2).jpg', '87 (41).jpg', '87 (6).jpg', '88 (11).jpg', '87 (43).jpg', '88 (18).jpg', '87 (5).jpg', '88 (12).jpg', '88 (10).jpg', '88 (14).jpg', '88 (1).jpg', '88 (3).jpg', '88 (30).jpg', '88 (24).jpg', '88 (8).jpg', '89 (10).jpg', '88 (28).jpg', '88 (4).jpg', '88 (20).jpg', '88 (26).jpg', '88 (6).jpg', '88 (21).jpg', '88 (7).jpg', '88 (34).jpg', '88 (22).jpg', '88 (5).jpg', '88 (37).jpg', '88 (35).jpg', '89 (1).jpg', '88 (32).jpg', '88 (9).jpg', '88 (36).jpg', '89 (29).jpg', '89 (23).jpg', '89 (25).jpg', '89 (39).jpg', '89 (13).jpg', '89 (33).jpg', '89 (19).jpg', '89 (38).jpg', '89 (21).jpg', '89 (16).jpg', '89 (2).jpg', '89 (27).jpg', '89 (35).jpg', '89 (34).jpg', '89 (4).jpg', '89 (14).jpg', '89 (12).jpg', '89 (36).jpg', '89 (31).jpg', '89 (15).jpg', '89 (17).jpg', '89 (37).jpg', '89 (11).jpg', '89 (3).jpg', '90 (2).jpg', '89 (8).jpg', '90 (13).jpg', '89 (7).jpg', '90 (23).jpg', '90 (21).jpg', '90 (17).jpg', '89 (5).jpg', '89 (41).jpg', '90 (15).jpg', '90 (11).jpg', '90 (1).jpg', '89 (9).jpg', '90 (19).jpg', '90 (10).jpg', '89 (42).jpg', '90 (24).jpg', '89 (6).jpg', '89 (40).jpg', '90 (12).jpg', '90 (22).jpg', '89 (43).jpg', '90 (25).jpg', '90 (7).jpg', '91 (15).jpg', '91 (10).jpg', '90 (3).jpg', '90 (26).jpg', '91 (1).jpg', '90 (9).jpg', '90 (27).jpg', '91 (2).jpg', '90 (28).jpg', '90 (31).jpg', '91 (13).jpg', '91 (11).jpg', '90 (30).jpg', '90 (5).jpg', '90 (6).jpg', '90 (29).jpg', '90 (4).jpg', '91 (12).jpg', '90 (32).jpg', '91 (19).jpg', '91 (17).jpg', '91 (14).jpg', '90 (8).jpg', '91 (8).jpg', '91 (33).jpg', '91 (9).jpg', '91 (32).jpg', '91 (29).jpg', '91 (21).jpg', '91 (3).jpg', '91 (31).jpg', '91 (30).jpg', '91 (36).jpg', '91 (34).jpg', '91 (6).jpg', '91 (5).jpg', '91 (25).jpg', '91 (7).jpg', '91 (39).jpg', '91 (27).jpg', '91 (38).jpg', '91 (23).jpg', '91 (37).jpg', '91 (35).jpg', '91 (40).jpg', '91 (4).jpg', '92 (3).jpg', '92 (19).jpg', '92 (13).jpg', '92 (27).jpg', '92 (34).jpg', '92 (31).jpg', '92 (21).jpg', '92 (38).jpg', '92 (2).jpg', '92 (1).jpg', '92 (10).jpg', '92 (17).jpg', '92 (11).jpg', '92 (32).jpg', '92 (4).jpg', '92 (15).jpg', '92 (14).jpg', '92 (36).jpg', '92 (12).jpg', '92 (33).jpg', '92 (29).jpg', '92 (25).jpg', '92 (23).jpg', '92 (20).jpg', '93 (14).jpg', '92 (6).jpg', '92 (7).jpg', '93 (12).jpg', '92 (40).jpg', '92 (5).jpg', '93 (20).jpg', '93 (26).jpg', '93 (22).jpg', '93 (2).jpg', '93 (18).jpg', '93 (1).jpg', '93 (10).jpg', '92 (8).jpg', '92 (9).jpg', '92 (42).jpg', '93 (17).jpg', '93 (16).jpg', '93 (15).jpg', '93 (27).jpg', '93 (28).jpg', '93 (24).jpg', '93 (11).jpg', '93 (13).jpg', '93 (7).jpg', '93 (8).jpg', '93 (34).jpg', '94 (1).jpg', '94 (15).jpg', '94 (10).jpg', '94 (14).jpg', '93 (31).jpg', '93 (5).jpg', '93 (32).jpg', '94 (11).jpg', '94 (16).jpg', '93 (6).jpg', '93 (35).jpg', '93 (4).jpg', '93 (3).jpg', '94 (12).jpg', '93 (9).jpg', '93 (30).jpg', '93 (29).jpg', '94 (13).jpg', '93 (33).jpg', '93 (36).jpg', '94 (44).jpg', '94 (4).jpg', '94 (6).jpg', '94 (31).jpg', '94 (3).jpg', '94 (27).jpg', '94 (23).jpg', '94 (7).jpg', '94 (18).jpg', '94 (35).jpg', '94 (33).jpg', '94 (46).jpg', '94 (19).jpg', '94 (5).jpg', '94 (37).jpg', '94 (41).jpg', '94 (29).jpg', '94 (45).jpg', '94 (17).jpg', '94 (39).jpg', '94 (21).jpg', '94 (43).jpg', '94 (25).jpg', '94 (2).jpg', '97 (16).jpg', '97 (10).jpg', '97 (12).jpg', '97 (36).jpg', '97 (3).jpg', '97 (11).jpg', '97 (13).jpg', '97 (24).jpg', '97 (28).jpg', '97 (34).jpg', '97 (14).jpg', '97 (2).jpg', '97 (1).jpg', '97 (20).jpg', '97 (15).jpg', '94 (9).jpg', '97 (32).jpg', '97 (18).jpg', '97 (26).jpg', '97 (35).jpg', '97 (22).jpg', '97 (30).jpg', '94 (8).jpg', '97 (37).jpg', '97 (40).jpg', '97 (4).jpg', '97 (5).jpg', '97 (9).jpg', '97 (39).jpg', '97 (38).jpg', '97 (7).jpg', '97 (8).jpg', '97 (6).jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "stroke_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(stroke_folder):\n",
        "    print(\"✅ Folder exists. Listing contents:\")\n",
        "    print(os.listdir(stroke_folder))\n",
        "else:\n",
        "    print(\"❌ Path does not exist. Check your directory structure.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ueZoGv8uUim",
        "outputId": "449b9ba5-060b-4153-eee8-f7e925489878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample files: ['58 (10).jpg', '58 (2).jpg', '58 (19).jpg', '58 (17).jpg', '58 (13).jpg', '58 (12).jpg', '58 (21).jpg', '58 (15).jpg', '58 (1).jpg', '58 (20).jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "files = os.listdir(stroke_folder)\n",
        "print(\"Sample files:\", files[:10])  # Show first 10 files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uDdNX5jugOl",
        "outputId": "284c1d5e-4c30-451d-eb38-75d1eb0faf47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully! Shape of X: (316, 3, 128, 128), Shape of y: (316, 2)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "stroke_folder = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/Stroke\"\n",
        "img_size = 128  # Resize all images to 128x128\n",
        "depth = 3       # Number of slices per sample (Choose appropriately based on your dataset)\n",
        "\n",
        "def load_images(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    img_files = sorted(os.listdir(folder))  # Get all image files\n",
        "\n",
        "    # Make sure we have enough images to form depth-based groups\n",
        "    if len(img_files) < depth:\n",
        "        print(\"Not enough images to form proper depth-based inputs.\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    for i in range(0, len(img_files) - depth + 1, depth):  # Create groups of `depth` slices\n",
        "        slices = []\n",
        "\n",
        "        for j in range(depth):\n",
        "            img_path = os.path.join(folder, img_files[i + j])\n",
        "            try:\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load in grayscale\n",
        "                img = cv2.resize(img, (img_size, img_size))\n",
        "                slices.append(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "\n",
        "        if len(slices) == depth:\n",
        "            images.append(np.array(slices))\n",
        "            labels.append(1)  # Assuming all are stroke cases\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X, y = load_images(stroke_folder)\n",
        "\n",
        "# Normalize data\n",
        "X = X / 255.0\n",
        "y = to_categorical(y, 2)  # Convert labels to categorical format\n",
        "\n",
        "print(f\"Dataset loaded successfully! Shape of X: {X.shape}, Shape of y: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc7vzwJpu7Rj",
        "outputId": "969d7e48-4daa-467c-d276-7b00c7b04afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: (226, 3, 128, 128), Validation samples: (26, 3, 128, 128), Testing samples: (64, 3, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset (80% train, 10% validation, 10% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape}, Validation samples: {X_val.shape}, Testing samples: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6CnxvNYvRVU",
        "outputId": "f1f9721b-5bf7-40a2-c908-9086afcf80b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated Shapes - X_train: (226, 3, 128, 128, 1), X_val: (26, 3, 128, 128, 1), X_test: (64, 3, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "# Expand dimensions to match Conv3D input requirements (Adding channel dimension)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "print(f\"Updated Shapes - X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdklKTcqvZMM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling3D\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "DvtG4NU3wD-w",
        "outputId": "b7a287ed-42f4-4b5a-d0b8-2f7d28553ec5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2097152</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │     <span style=\"color: #00af00; text-decoration-color: #00af00\">268,435,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_13 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_3 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_14 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m55,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_4 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2097152\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │     \u001b[38;5;34m268,435,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,491,969</span> (1.00 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m268,491,969\u001b[0m (1.00 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,491,969</span> (1.00 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,491,969\u001b[0m (1.00 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv3D, MaxPooling3D, Flatten, GlobalAveragePooling3D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_3d_densenet(input_shape):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # DenseNet-like structure (you can replace this with your actual DenseNet layers)\n",
        "    x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling3D((2, 2, 2))(x)\n",
        "\n",
        "    # Add more convolutional layers to build the network\n",
        "    x = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling3D((2, 2, 2))(x)\n",
        "\n",
        "    # Flatten before the dense layers\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Fully connected layer\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    # Output layer (modify depending on the number of classes)\n",
        "    output = Dense(1, activation='sigmoid')(x)  # For binary classification, adjust if multiclass\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs, output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape and create the model\n",
        "input_shape = (128, 128, 128, 1)  # Example: Adjust if necessary\n",
        "model = build_3d_densenet(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT76SsaA9A5j",
        "outputId": "460ec813-6881-4194-b6f9-9ea17288ee86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MLL2Cbr-auI",
        "outputId": "f72d41a7-2eff-48c0-f8fd-0b9a6af47219"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Conversion complete!\n",
            "X shape: (0,)\n",
            "y shape: (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to load 3D volume from a patient folder\n",
        "def load_patient_volume(folder_path, image_size=(128, 128), depth=128):\n",
        "    slices = sorted(os.listdir(folder_path))\n",
        "    volume = []\n",
        "    for slice_name in slices:\n",
        "        if not slice_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "        img_path = os.path.join(folder_path, slice_name)\n",
        "        img = Image.open(img_path).convert('L')\n",
        "        img = img.resize(image_size)\n",
        "        volume.append(np.array(img))\n",
        "\n",
        "    # Pad if less than 128 slices\n",
        "    while len(volume) < depth:\n",
        "        volume.append(np.zeros(image_size))\n",
        "\n",
        "    volume = volume[:depth]  # Ensure fixed depth\n",
        "    volume = np.stack(volume, axis=0)\n",
        "    volume = np.expand_dims(volume, axis=-1)  # Shape: (128,128,128,1)\n",
        "    return volume\n",
        "\n",
        "# ✅ Set correct path\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/3d_densenet\"\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Process each patient folder\n",
        "for folder in tqdm(os.listdir(data_path)):\n",
        "    folder_path = os.path.join(data_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        volume = load_patient_volume(folder_path)\n",
        "        X.append(volume)\n",
        "\n",
        "        # Label based on folder name\n",
        "        label = 1 if \"stroke\" in folder.lower() else 0\n",
        "        y.append(label)\n",
        "\n",
        "# Convert and save as .npy\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "np.save(os.path.join(data_path, \"X_data.npy\"), X)\n",
        "np.save(os.path.join(data_path, \"y_labels.npy\"), y)\n",
        "\n",
        "print(\"✅ Conversion complete!\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpFdnwtG_jm0",
        "outputId": "bbc1b1d9-f3e5-4337-a5c7-dda422082ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded!\n",
            "X shape: (0,)\n",
            "y shape: (0,)\n",
            "Labels: []\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load saved data\n",
        "X = np.load('/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/3d_densenet/X_data.npy')\n",
        "y = np.load('/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/3d_densenet/y_labels.npy')\n",
        "\n",
        "print(\"✅ Loaded!\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Labels:\", y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpZ7LccqAHAY",
        "outputId": "b0f65cdd-b328-4e25-faac-caca9936f980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Folders inside 3d_densenet:\n",
            "📁 X_data.npy -> file\n",
            "📁 y_labels.npy -> file\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised/3d_densenet\"\n",
        "\n",
        "# Show top-level folders (patient cases)\n",
        "print(\"🔍 Folders inside 3d_densenet:\")\n",
        "for folder in os.listdir(data_path):\n",
        "    folder_path = os.path.join(data_path, folder)\n",
        "    print(f\"📁 {folder} ->\", \"folder\" if os.path.isdir(folder_path) else \"file\")\n",
        "\n",
        "    # Show what’s inside ONE folder (first one)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(\"   └── Contents:\")\n",
        "        print(\"   \", os.listdir(folder_path)[:5])  # Only show first 5 files/folders\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gV9Q-neAWtk",
        "outputId": "786d8fd8-47b5-4b56-d56d-219529e66289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🖼 Found image: 58 (10).jpg\n",
            "📂 In folder: /content/drive/MyDrive/brain_stroke/Brain_Data_Organised\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"\n",
        "\n",
        "# Explore all folders to find where the .jpg images are\n",
        "for root, dirs, files in os.walk(base_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):\n",
        "            print(\"🖼 Found image:\", file)\n",
        "            print(\"📂 In folder:\", root)\n",
        "            break  # Stop after finding the first one\n",
        "    else:\n",
        "        continue\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU7THuOWBIAg",
        "outputId": "de43207b-d60f-4286-b7b9-6f6c56281ae7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 242.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Conversion done\n",
            "X shape: (1, 1, 128, 128, 1)\n",
            "y shape: (1,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        " import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/brain_stroke/Brain_Data_Organised\"\n",
        "target_size = (128, 128)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for filename in tqdm(sorted(os.listdir(data_path))):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(data_path, filename)\n",
        "        img = Image.open(img_path).convert('L')\n",
        "        img = img.resize(target_size)\n",
        "\n",
        "        img_array = np.array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=(0, -1))  # (1, 128, 128, 1)\n",
        "\n",
        "        X.append(img_array)\n",
        "\n",
        "        if \"stroke\" in filename.lower():\n",
        "            y.append(1)\n",
        "        else:\n",
        "            y.append(0)\n",
        "\n",
        "X = np.array(X)  # Now shape is (num_samples, 1, 128, 128, 1)\n",
        "X = X.astype('float32')\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ Conversion done\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "np.save(os.path.join(data_path, \"X_data.npy\"), X)\n",
        "np.save(os.path.join(data_path, \"y_labels.npy\"), y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hdiYtX0Mgn0",
        "outputId": "3af1f322-e747-44b4-dce5-0b01655f5c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk1wseFFM5zV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6D1KN-cNml9"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised\"  # Correct path\n",
        "\n",
        "categories = [\"stroke\", \"normal\"]  # Assuming two folders inside Brain_Data_Organised\n",
        "output_path = \"/content/drive/MyDrive/final_project/numpy_arrays\"\n",
        "os.makedirs(output_path, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLf1xdpYQmq7",
        "outputId": "575bfcbc-2c86-4a23-b5cf-9d8cf30a09ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: stroke_1.npy with shape (273, 128, 128)\n",
            "Saved: normal_0.npy with shape (1551, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Correct capitalized folder names\n",
        "base_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised\"\n",
        "categories = [\"Stroke\", \"Normal\"]\n",
        "output_path = \"/content/drive/MyDrive/final_project/numpy_arrays\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 128\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(base_path, category)\n",
        "    case_id = category.lower()  # Just \"stroke\" or \"normal\"\n",
        "    slices = []\n",
        "\n",
        "    for file in sorted(os.listdir(category_path)):\n",
        "        if file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(category_path, file)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            slices.append(img)\n",
        "\n",
        "    if len(slices) > 0:\n",
        "        volume = np.stack(slices, axis=0)\n",
        "        label = 1 if case_id == \"stroke\" else 0\n",
        "        np.save(os.path.join(output_path, f\"{case_id}_{label}.npy\"), volume)\n",
        "        print(f\"Saved: {case_id}_{label}.npy with shape {volume.shape}\")\n",
        "    else:\n",
        "        print(f\"No images found in {category_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T02KPjxPTcyx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D,\n",
        "                                     Dense, BatchNormalization, Activation, concatenate)\n",
        "\n",
        "def dense_block(x, filters, name_prefix):\n",
        "    \"\"\"Simple Dense Block with 2 Conv3D layers\"\"\"\n",
        "    x1 = Conv3D(filters, kernel_size=3, padding='same', activation='relu', name=f\"{name_prefix}_conv1\")(x)\n",
        "    x1 = BatchNormalization(name=f\"{name_prefix}_bn1\")(x1)\n",
        "\n",
        "    x2 = Conv3D(filters, kernel_size=3, padding='same', activation='relu', name=f\"{name_prefix}_conv2\")(x1)\n",
        "    x2 = BatchNormalization(name=f\"{name_prefix}_bn2\")(x2)\n",
        "\n",
        "    out = concatenate([x, x1, x2], axis=-1, name=f\"{name_prefix}_concat\")\n",
        "    return out\n",
        "\n",
        "def build_3d_densenet(input_shape=(128, 128, 128, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv3D(16, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = dense_block(x, filters=16, name_prefix=\"dense1\")\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = dense_block(x, filters=32, name_prefix=\"dense2\")\n",
        "    x = GlobalAveragePooling3D()(x)\n",
        "\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "k2zE2GIhTi7I",
        "outputId": "8abba4e0-4560-4525-e6dd-8757f93061e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,928</span> │ max_pooling3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_bn1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ dense1_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,928</span> │ dense1_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_bn2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ dense1_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_concat             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>) │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dense1_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ dense1_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>) │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense1_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ max_pooling3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_bn1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense2_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ dense2_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_bn2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense2_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_concat             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)                   │                │ dense2_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ dense2_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling3d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense2_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,232</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│                           │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │            \u001b[38;5;34m448\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                           │ \u001b[38;5;34m16\u001b[0m)                    │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │              \u001b[38;5;34m0\u001b[0m │ conv3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling3D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_conv1 (\u001b[38;5;33mConv3D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │          \u001b[38;5;34m6,928\u001b[0m │ max_pooling3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_bn1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │             \u001b[38;5;34m64\u001b[0m │ dense1_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_conv2 (\u001b[38;5;33mConv3D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │          \u001b[38;5;34m6,928\u001b[0m │ dense1_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_bn2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │             \u001b[38;5;34m64\u001b[0m │ dense1_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense1_concat             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m) │              \u001b[38;5;34m0\u001b[0m │ max_pooling3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dense1_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ dense1_bn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m) │              \u001b[38;5;34m0\u001b[0m │ dense1_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling3D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_conv1 (\u001b[38;5;33mConv3D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │         \u001b[38;5;34m41,504\u001b[0m │ max_pooling3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_bn1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │            \u001b[38;5;34m128\u001b[0m │ dense2_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_conv2 (\u001b[38;5;33mConv3D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │         \u001b[38;5;34m27,680\u001b[0m │ dense2_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_bn2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │            \u001b[38;5;34m128\u001b[0m │ dense2_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense2_concat             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,     │              \u001b[38;5;34m0\u001b[0m │ max_pooling3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │ \u001b[38;5;34m112\u001b[0m)                   │                │ dense2_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ dense2_bn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling3d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense2_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m7,232\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,169</span> (356.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,169\u001b[0m (356.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,977</span> (355.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m90,977\u001b[0m (355.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_3d_densenet()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zMK5z5uVU7j",
        "outputId": "2501b06e-0941-44a9-bbe3-a0d618fc2776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Stroke: 100%|██████████| 273/273 [00:02<00:00, 118.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Volume shape: (273, 128, 128)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Normal: 100%|██████████| 1551/1551 [00:19<00:00, 79.51it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Volume shape: (1551, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "stroke_path = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'\n",
        "normal_path = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'\n",
        "save_path = '/content/drive/MyDrive/final_project/numpy_arrays'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "def load_and_stack_images(folder_path):\n",
        "    image_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.jpg')])\n",
        "    volume = []\n",
        "\n",
        "    for file in tqdm(image_files, desc=f\"Processing {os.path.basename(folder_path)}\"):\n",
        "        img = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (128, 128))  # Resize to 128x128\n",
        "        volume.append(img)\n",
        "\n",
        "    volume = np.array(volume)\n",
        "    print(f\"Volume shape: {volume.shape}\")\n",
        "    return volume\n",
        "\n",
        "# Process Stroke\n",
        "stroke_volume = load_and_stack_images(stroke_path)\n",
        "np.save(os.path.join(save_path, 'stroke.npy'), stroke_volume)\n",
        "\n",
        "# Process Normal\n",
        "normal_volume = load_and_stack_images(normal_path)\n",
        "np.save(os.path.join(save_path, 'normal.npy'), normal_volume)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "E2PGduMhZaSk",
        "outputId": "a0ee5f51-6529-465a-b3f3-b409221d670a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,928</span> │ max_pooling3d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv3d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,928</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv3d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling3d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ max_pooling3d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv3d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv3d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>) │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling3d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ batch_normalization_2… │\n",
              "│                           │                        │                │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling3d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,232</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │            \u001b[38;5;34m448\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                           │ \u001b[38;5;34m16\u001b[0m)                    │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling3D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m6,928\u001b[0m │ max_pooling3d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │             \u001b[38;5;34m64\u001b[0m │ conv3d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_3 (\u001b[38;5;33mConv3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m6,928\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │             \u001b[38;5;34m64\u001b[0m │ conv3d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ max_pooling3d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling3d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mMaxPooling3D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_4 (\u001b[38;5;33mConv3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │         \u001b[38;5;34m41,504\u001b[0m │ max_pooling3d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │            \u001b[38;5;34m128\u001b[0m │ conv3d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3d_5 (\u001b[38;5;33mConv3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │         \u001b[38;5;34m27,680\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │            \u001b[38;5;34m128\u001b[0m │ conv3d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m112\u001b[0m) │              \u001b[38;5;34m0\u001b[0m │ max_pooling3d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ batch_normalization_2… │\n",
              "│                           │                        │                │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling3d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m7,232\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,169</span> (356.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,169\u001b[0m (356.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,977</span> (355.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m90,977\u001b[0m (355.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, BatchNormalization, MaxPooling3D, GlobalAveragePooling3D, Dense, Concatenate\n",
        "\n",
        "# ✅ Updated input shape: (16, 128, 128, 1)\n",
        "input_layer = Input(shape=(16, 128, 128, 1))\n",
        "\n",
        "# Initial Conv Layer\n",
        "x = Conv3D(16, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "# Dense Block 1\n",
        "conv1 = Conv3D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
        "bn1 = BatchNormalization()(conv1)\n",
        "\n",
        "conv2 = Conv3D(16, kernel_size=3, activation='relu', padding='same')(bn1)\n",
        "bn2 = BatchNormalization()(conv2)\n",
        "\n",
        "concat1 = Concatenate()([x, bn1, bn2])\n",
        "x = MaxPooling3D(pool_size=2)(concat1)\n",
        "\n",
        "# Dense Block 2\n",
        "conv3 = Conv3D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "bn3 = BatchNormalization()(conv3)\n",
        "\n",
        "conv4 = Conv3D(32, kernel_size=3, activation='relu', padding='same')(bn3)\n",
        "bn4 = BatchNormalization()(conv4)\n",
        "\n",
        "concat2 = Concatenate()([x, bn3, bn4])\n",
        "x = GlobalAveragePooling3D()(concat2)\n",
        "\n",
        "# Classification layer\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoaNQhkI4MNe"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, Dense, Flatten, Dropout, GlobalAveragePooling3D\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "\n",
        "# Define 3D DenseNet model\n",
        "def build_3d_densenet(input_shape=(16, 128, 128, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv3D(64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "    x = Conv3D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "    x = Conv3D(256, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = GlobalAveragePooling3D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Instantiate model\n",
        "model = build_3d_densenet()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YUrkFwk7O12",
        "outputId": "62ab2ea8-66f2-4d73-de91-75797a3efc56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYom36ml7zEo",
        "outputId": "eee69ac6-a5e8-44b7-f32e-4ef21dad6a75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Stroke: 100%|██████████| 273/273 [00:00<00:00, 5406.23it/s]\n",
            "Processing Normal: 100%|██████████| 1551/1551 [00:00<00:00, 7476.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (0, 1)\n",
            "y shape: (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "stroke_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke\"\n",
        "normal_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal\"\n",
        "\n",
        "def load_volume(path, max_slices=16, size=(128, 128)):\n",
        "    images = sorted(os.listdir(path))\n",
        "    volume = []\n",
        "    for img_name in images[:max_slices]:\n",
        "        img_path = os.path.join(path, img_name)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, size)\n",
        "            volume.append(img)\n",
        "    # If fewer than max_slices, pad with zeros\n",
        "    while len(volume) < max_slices:\n",
        "        volume.append(np.zeros(size))\n",
        "    return np.array(volume)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Stroke = 1\n",
        "for folder in tqdm(os.listdir(stroke_path), desc=\"Processing Stroke\"):\n",
        "    folder_path = os.path.join(stroke_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        vol = load_volume(folder_path)\n",
        "        X.append(vol)\n",
        "        y.append(1)\n",
        "\n",
        "# Normal = 0\n",
        "for folder in tqdm(os.listdir(normal_path), desc=\"Processing Normal\"):\n",
        "    folder_path = os.path.join(normal_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        vol = load_volume(folder_path)\n",
        "        X.append(vol)\n",
        "        y.append(0)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Add channel dimension\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "# Save to disk\n",
        "np.save(\"/content/drive/MyDrive/final_project/X_3d.npy\", X)\n",
        "np.save(\"/content/drive/MyDrive/final_project/y_3d.npy\", y)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU-5br708FC9",
        "outputId": "72664eeb-386e-407b-b6e6-4261639492ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Stroke: 100%|██████████| 273/273 [00:00<00:00, 5691.05it/s]\n",
            "Processing Normal: 100%|██████████| 1551/1551 [00:00<00:00, 5789.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ X shape: (0, 128, 128, 1)\n",
            "✅ y shape: (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "stroke_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke\"\n",
        "normal_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal\"\n",
        "\n",
        "def load_images_from_folder(folder_path, label):\n",
        "    for folder in tqdm(os.listdir(folder_path), desc=f\"Processing {'Stroke' if label == 1 else 'Normal'}\"):\n",
        "        folder_dir = os.path.join(folder_path, folder)\n",
        "        if os.path.isdir(folder_dir):\n",
        "            for file in os.listdir(folder_dir):\n",
        "                file_path = os.path.join(folder_dir, file)\n",
        "                # Accept common image types\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    try:\n",
        "                        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                        if img is not None:\n",
        "                            img_resized = cv2.resize(img, (128, 128))  # resize to fixed shape\n",
        "                            X.append(img_resized)\n",
        "                            y.append(label)\n",
        "                        else:\n",
        "                            print(f\"⚠️ Could not read image: {file_path}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"❌ Error processing {file_path}: {e}\")\n",
        "                else:\n",
        "                    print(f\"⏩ Skipping non-image file: {file_path}\")\n",
        "\n",
        "load_images_from_folder(stroke_path, 1)\n",
        "load_images_from_folder(normal_path, 0)\n",
        "\n",
        "X = np.array(X).reshape(-1, 128, 128, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ X shape:\", X.shape)\n",
        "print(\"✅ y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_srHd438a78"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder_path, label):\n",
        "    for folder in tqdm(os.listdir(folder_path), desc=f\"Processing {'Stroke' if label == 1 else 'Normal'}\"):\n",
        "        folder_dir = os.path.join(folder_path, folder)\n",
        "        if os.path.isdir(folder_dir):\n",
        "            for file in os.listdir(folder_dir):\n",
        "                file_path = os.path.join(folder_dir, file)\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    print(f\"📂 Trying: {file_path}\")\n",
        "                    try:\n",
        "                        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                        if img is not None:\n",
        "                            img_resized = cv2.resize(img, (128, 128))\n",
        "                            X.append(img_resized)\n",
        "                            y.append(label)\n",
        "                        else:\n",
        "                            print(f\"⚠️ Image is None: {file_path}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"❌ Error: {file_path} — {e}\")\n",
        "                else:\n",
        "                    print(f\"⏩ Skipping non-image: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDQhymYJ8p6S",
        "outputId": "2daf5103-d695-4581-ccc7-23ebe32bef0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Stroke: 100%|██████████| 273/273 [00:05<00:00, 46.34it/s] \n",
            "Processing Normal: 100%|██████████| 1551/1551 [00:38<00:00, 40.44it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ X shape: (1824, 128, 128, 1)\n",
            "✅ y shape: (1824,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "def load_images_directly_from_folder(folder_path, label):\n",
        "    for file in tqdm(os.listdir(folder_path), desc=f\"Processing {'Stroke' if label == 1 else 'Normal'}\"):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is not None:\n",
        "                img_resized = cv2.resize(img, (128, 128))\n",
        "                X.append(img_resized)\n",
        "                y.append(label)\n",
        "            else:\n",
        "                print(f\"⚠️ Could not read image: {file_path}\")\n",
        "\n",
        "# Set the correct paths\n",
        "stroke_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke\"\n",
        "normal_path = \"/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal\"\n",
        "\n",
        "# Load images\n",
        "load_images_directly_from_folder(stroke_path, label=1)\n",
        "load_images_directly_from_folder(normal_path, label=0)\n",
        "\n",
        "# Convert to numpy\n",
        "X = np.array(X).reshape(-1, 128, 128, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ X shape:\", X.shape)\n",
        "print(\"✅ y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFaY232j9GFC",
        "outputId": "75b333f6-7cd1-4b8b-9ccf-f05b8a84f8cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved X and y as .npy files!\n"
          ]
        }
      ],
      "source": [
        "np.save(\"/content/drive/MyDrive/final_project/X_3d.npy\", X)\n",
        "np.save(\"/content/drive/MyDrive/final_project/y_3d.npy\", y)\n",
        "print(\"✅ Saved X and y as .npy files!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxMlv_Y9C42W",
        "outputId": "d3bc286e-0110-42d0-b932-9afd97093591"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/final_project/model_A_3D_DenseNet.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jDuaGcWDEol"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.save('/content/drive/MyDrive/final_project/model_A_3D_DenseNet.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpwqKyyVDfmS"
      },
      "outputs": [],
      "source": [
        "X = np.load(\"/content/drive/MyDrive/final_project/X_3d.npy\")\n",
        "y = np.load(\"/content/drive/MyDrive/final_project/y_3d.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ66bvwCDiIr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXN0wsAMDlCf",
        "outputId": "8bfdc767-6cc4-408b-c645-92feeb325389"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/final_project/model_A_3D_DenseNet.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SFhw3ysGUMI",
        "outputId": "35fc3e80-7b69-4de7-bf8d-e215b0e86163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(365, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example: Your current data\n",
        "print(X_test.shape)  # Should be (N, 128, 128, 1)\n",
        "\n",
        "# Flatten to get rid of channel for easy slicing\n",
        "X_test_flat = X_test.reshape(-1, 128, 128)\n",
        "\n",
        "# Number of slices\n",
        "total_slices = X_test_flat.shape[0]\n",
        "\n",
        "# Number of full 3D volumes (each with 16 slices)\n",
        "volume_depth = 16\n",
        "num_volumes = total_slices // volume_depth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oPnxjyGGXCD",
        "outputId": "e39e950e-e2e5-498b-995d-27034da20761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ X_test_3d shape: (22, 16, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "X_test_3d = []\n",
        "\n",
        "for i in range(num_volumes):\n",
        "    volume = X_test_flat[i*volume_depth:(i+1)*volume_depth]\n",
        "    X_test_3d.append(volume)\n",
        "\n",
        "# Convert to numpy array and add channel dimension\n",
        "X_test_3d = np.array(X_test_3d)\n",
        "X_test_3d = X_test_3d[..., np.newaxis]  # Final shape: (num_volumes, 16, 128, 128, 1)\n",
        "\n",
        "print(f\"✅ X_test_3d shape: {X_test_3d.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_SdWpI5GZ9T"
      },
      "outputs": [],
      "source": [
        "y_test_trimmed = y_test[:num_volumes]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwWbCpajGft7",
        "outputId": "80a1f8e6-5693-4b40-9554-c7f630fd1363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_3d)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hFkOGtkHTeI",
        "outputId": "d6d340e0-4087-4eff-eb2e-25e00014a87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "# View all predictions\n",
        "print(\"Predicted Labels:\", y_pred_labels.flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfGiD_d5HXP7",
        "outputId": "bd41582b-bfe0-4f65-a4b4-0922979b1d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stroke predictions (1): 22\n",
            "Normal predictions (0): 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "stroke_count = np.sum(y_pred_labels)  # Count of predicted stroke (1)\n",
        "normal_count = len(y_pred_labels) - stroke_count  # Count of predicted normal (0)\n",
        "\n",
        "print(f\"Stroke predictions (1): {stroke_count}\")\n",
        "print(f\"Normal predictions (0): {normal_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "5WKdA4XPlC0A",
        "outputId": "e2326fb5-fe97-4adc-ffe5-53fc9216f9d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling3d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m2,624\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m55,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m221,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_3 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m884,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling3d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,265,799</span> (4.83 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,265,799\u001b[0m (4.83 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,839</span> (4.82 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,264,839\u001b[0m (4.82 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, BatchNormalization, Activation, GlobalAveragePooling3D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_shape = (128, 128, 128, 3)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Initial Convolution\n",
        "x = Conv3D(32, kernel_size=3, padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "# Block 1\n",
        "x = Conv3D(64, kernel_size=3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "# Block 2\n",
        "x = Conv3D(128, kernel_size=3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "# Block 3\n",
        "x = Conv3D(256, kernel_size=3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = GlobalAveragePooling3D()(x)\n",
        "\n",
        "# Dense Layers\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Output: 7 classes for mRS score\n",
        "outputs = Dense(7, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPUTLAK3AqUa",
        "outputId": "5e43ea28-d892-4402-8958-ba694a65b1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE5EpOEoCAYB",
        "outputId": "6c21317b-d730-4b79-f5b9-6b0b18217d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.path.exists('/content/drive/MyDrive/final_project/X_data.npy'))\n",
        "print(os.path.exists('/content/drive/MyDrive/final_project/y_labels.npy'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS-EnIUJCO1q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpsY87QRCSF8"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised'\n",
        "categories = ['stroke', 'normal']\n",
        "image_size = (128, 128)  # We'll resize to 128x128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs_FX6K8CmTM",
        "outputId": "98f9ad1b-50d7-4d88-ebc1-1a3ea804dffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 /content/drive/MyDrive/final_project/Brain_Data_Organised\n",
            " ┣━ 📁 Normal\n",
            " ┣━ 📁 Stroke\n",
            "\n",
            "📂 /content/drive/MyDrive/final_project/Brain_Data_Organised/Normal\n",
            " ┣━ 🖼️ 118 (19).jpg\n",
            " ┣━ 🖼️ 118 (21).jpg\n",
            " ┣━ 🖼️ 118 (25).jpg\n",
            " ┣━ 🖼️ 118 (16).jpg\n",
            " ┣━ 🖼️ 118 (13).jpg\n",
            "\n",
            "📂 /content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke\n",
            " ┣━ 🖼️ 58 (20).jpg\n",
            " ┣━ 🖼️ 58 (12).jpg\n",
            " ┣━ 🖼️ 58 (21).jpg\n",
            " ┣━ 🖼️ 58 (13).jpg\n",
            " ┣━ 🖼️ 58 (19).jpg\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "root_path = '/content/drive/MyDrive/final_project/Brain_Data_Organised'\n",
        "\n",
        "for root, dirs, files in os.walk(root_path):\n",
        "    print(\"📂\", root)\n",
        "    for d in dirs:\n",
        "        print(\" ┣━ 📁\", d)\n",
        "    for f in files[:5]:  # Show only first 5 files to avoid long output\n",
        "        print(\" ┣━ 🖼️\", f)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoyjHZYgCxjp",
        "outputId": "d5f42c06-d5c0-43a1-9eeb-3ca1621ab5a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Stroke: 100%|██████████| 273/273 [00:06<00:00, 41.27it/s] \n",
            "Processing Normal: 100%|██████████| 1551/1551 [00:35<00:00, 43.24it/s] \n"
          ]
        }
      ],
      "source": [
        "X_data = []\n",
        "y_labels = []\n",
        "\n",
        "# Corrected category names to match actual folder names\n",
        "categories = ['Stroke', 'Normal']\n",
        "\n",
        "for label, category in enumerate(categories):  # Stroke=0, Normal=1\n",
        "    folder_path = os.path.join(data_dir, category)\n",
        "    for filename in tqdm(os.listdir(folder_path), desc=f\"Processing {category}\"):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                image = load_img(img_path, color_mode='grayscale', target_size=image_size)\n",
        "                image = img_to_array(image)\n",
        "                X_data.append(image)\n",
        "                y_labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Skipped {img_path} due to error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quiapVINDQU-",
        "outputId": "db6c9cdb-0138-4049-a3d1-f9a418477227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved as .npy! Shapes:\n",
            "X_data: (1824, 128, 128, 1)\n",
            "y_labels: (1824,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_data = np.array(X_data, dtype='float32') / 255.0  # Normalize to [0, 1]\n",
        "y_labels = np.array(y_labels)\n",
        "\n",
        "# Reshape to (N, 128, 128, 1)\n",
        "X_data = X_data.reshape(-1, 128, 128, 1)\n",
        "\n",
        "# Save the arrays\n",
        "np.save('/content/drive/MyDrive/final_project/X_data.npy', X_data)\n",
        "np.save('/content/drive/MyDrive/final_project/y_labels.npy', y_labels)\n",
        "\n",
        "print(\"✅ Saved as .npy! Shapes:\")\n",
        "print(\"X_data:\", X_data.shape)\n",
        "print(\"y_labels:\", y_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtzQW1mFDwJO",
        "outputId": "2ad14e6c-4a7e-4b01-dd4e-bfc483c7dd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 3D volumes ready!\n",
            "X_3d shape: (14, 128, 128, 128, 1)\n",
            "y_3d shape: (14,)\n"
          ]
        }
      ],
      "source": [
        "# Trim to only full volumes\n",
        "trim_size = (X_data.shape[0] // 128) * 128\n",
        "X_trimmed = X_data[:trim_size]\n",
        "y_trimmed = y_labels[:trim_size]\n",
        "\n",
        "# Reshape to 3D volumes\n",
        "X_3d = X_trimmed.reshape(-1, 128, 128, 128, 1)\n",
        "\n",
        "# Majority vote or max label in 128-slice block for classification label\n",
        "y_3d = []\n",
        "for i in range(0, len(y_trimmed), 128):\n",
        "    volume_labels = y_trimmed[i:i+128]\n",
        "    final_label = np.bincount(volume_labels).argmax()\n",
        "    y_3d.append(final_label)\n",
        "\n",
        "y_3d = np.array(y_3d)\n",
        "\n",
        "print(\"✅ 3D volumes ready!\")\n",
        "print(\"X_3d shape:\", X_3d.shape)\n",
        "print(\"y_3d shape:\", y_3d.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GbOi7WED6K9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, Dropout, BatchNormalization, Activation\n",
        "\n",
        "input_shape = (128, 128, 128, 1)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "x = Conv3D(32, kernel_size=3, padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "x = Conv3D(64, kernel_size=3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "x = Conv3D(128, kernel_size=3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "x = GlobalAveragePooling3D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(7, activation='softmax')(x)  # 7 m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3wlO-8mEibZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_3d, y_3d, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PpgIX_JFGiU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, Dropout, BatchNormalization, Activation\n",
        "\n",
        "input_layer = Input(shape=(128, 128, 128, 1))\n",
        "\n",
        "x = Conv3D(32, (3, 3, 3), padding='same')(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
        "\n",
        "x = Conv3D(64, (3, 3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
        "\n",
        "x = Conv3D(128, (3, 3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = GlobalAveragePooling3D()(x)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(7, activation='softmax')(x)  # 7 classes for mRS 0-6\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeJbehE0FKyv",
        "outputId": "bc4d650a-bef6-4c0e-8fef-d7efb5f1a52a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27s/step - accuracy: 0.6933 - loss: 1.6183 - val_accuracy: 0.6667 - val_loss: 1.6065\n",
            "Epoch 2/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 26s/step - accuracy: 0.9419 - loss: 0.7040 - val_accuracy: 0.6667 - val_loss: 1.2050\n",
            "Epoch 3/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26s/step - accuracy: 0.9740 - loss: 0.1598 - val_accuracy: 0.6667 - val_loss: 1.0623\n",
            "Epoch 4/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 30s/step - accuracy: 0.8824 - loss: 0.4860 - val_accuracy: 0.6667 - val_loss: 1.0986\n",
            "Epoch 5/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 26s/step - accuracy: 0.8824 - loss: 0.5768 - val_accuracy: 0.6667 - val_loss: 1.2842\n",
            "Epoch 6/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 27s/step - accuracy: 0.9419 - loss: 0.2895 - val_accuracy: 0.6667 - val_loss: 1.3757\n",
            "Epoch 7/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 27s/step - accuracy: 0.8824 - loss: 0.3638 - val_accuracy: 0.6667 - val_loss: 1.3597\n",
            "Epoch 8/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 28s/step - accuracy: 0.9597 - loss: 0.2209 - val_accuracy: 0.6667 - val_loss: 1.2668\n",
            "Epoch 9/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 26s/step - accuracy: 0.8109 - loss: 0.3848 - val_accuracy: 0.6667 - val_loss: 1.1937\n",
            "Epoch 10/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 26s/step - accuracy: 0.9597 - loss: 0.2776 - val_accuracy: 0.6667 - val_loss: 1.0857\n",
            "Epoch 11/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 29s/step - accuracy: 0.9181 - loss: 0.2551 - val_accuracy: 0.6667 - val_loss: 1.0508\n",
            "Epoch 12/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 27s/step - accuracy: 0.9740 - loss: 0.1567 - val_accuracy: 0.6667 - val_loss: 0.9836\n",
            "Epoch 13/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 28s/step - accuracy: 0.9597 - loss: 0.1997 - val_accuracy: 0.6667 - val_loss: 0.9845\n",
            "Epoch 14/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 29s/step - accuracy: 0.8824 - loss: 0.4265 - val_accuracy: 0.6667 - val_loss: 1.0011\n",
            "Epoch 15/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26s/step - accuracy: 0.9419 - loss: 0.1731 - val_accuracy: 0.6667 - val_loss: 0.9345\n",
            "Epoch 16/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 26s/step - accuracy: 0.8109 - loss: 0.4889 - val_accuracy: 0.6667 - val_loss: 0.8816\n",
            "Epoch 17/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26s/step - accuracy: 0.8109 - loss: 0.4496 - val_accuracy: 0.6667 - val_loss: 0.8129\n",
            "Epoch 18/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 28s/step - accuracy: 0.9181 - loss: 0.4602 - val_accuracy: 0.6667 - val_loss: 0.8030\n",
            "Epoch 19/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 30s/step - accuracy: 0.9419 - loss: 0.1827 - val_accuracy: 0.6667 - val_loss: 0.7921\n",
            "Epoch 20/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 30s/step - accuracy: 0.7707 - loss: 0.5678 - val_accuracy: 0.6667 - val_loss: 0.7884\n",
            "Epoch 21/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 31s/step - accuracy: 0.9597 - loss: 0.1944 - val_accuracy: 0.6667 - val_loss: 0.7690\n",
            "Epoch 22/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 29s/step - accuracy: 0.8824 - loss: 0.3112 - val_accuracy: 0.6667 - val_loss: 0.7749\n",
            "Epoch 23/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 29s/step - accuracy: 0.9419 - loss: 0.1695 - val_accuracy: 0.6667 - val_loss: 0.7754\n",
            "Epoch 24/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 30s/step - accuracy: 0.9740 - loss: 0.1331 - val_accuracy: 0.6667 - val_loss: 0.7801\n",
            "Epoch 25/25\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 30s/step - accuracy: 0.9419 - loss: 0.2089 - val_accuracy: 0.6667 - val_loss: 0.8048\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=25,\n",
        "    batch_size=2,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7GNoO_WXevD",
        "outputId": "252174d7-2606-485f-9c4c-172e267c9ce9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/final_project/modelA_3d_cnn_mrs.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8zqWnP4Xie_",
        "outputId": "310dd42b-885b-4b6e-9959-57a77f4f855b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
            "Sample 1: Predicted mRS = 1 ➜ Favorable\n",
            "Sample 2: Predicted mRS = 1 ➜ Favorable\n",
            "Sample 3: Predicted mRS = 1 ➜ Favorable\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Predict on validation data (or new CT data)\n",
        "y_pred_probs = model.predict(X_val)  # shape: (num_samples, 7)\n",
        "\n",
        "# Get predicted mRS score (0 to 6)\n",
        "y_pred_mrs = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Define favorable (0-1) vs unfavorable (2-6)\n",
        "favorable_mask = y_pred_mrs <= 1\n",
        "unfavorable_mask = y_pred_mrs >= 2\n",
        "\n",
        "# Print predictions\n",
        "for i, score in enumerate(y_pred_mrs):\n",
        "    outcome = \"Favorable\" if score <= 1 else \"Unfavorable\"\n",
        "    print(f\"Sample {i+1}: Predicted mRS = {score} ➜ {outcome}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLnHB3uvazUg",
        "outputId": "aad19f18-b4fe-47d7-c170-3b88586b2a23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnHBtabya2UC",
        "outputId": "aeef40b5-702d-4a9e-f63f-d832bc0f6586"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJK_cgcta7SC",
        "outputId": "874f8e8b-36a8-4c70-e9e3-3720e4218e55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "Predicted mRS = 1 ➜ Favorable\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load and sort new CT scan slices from a folder\n",
        "def load_ct_volume_from_folder(folder_path, size=(128, 128)):\n",
        "    slice_files = sorted(os.listdir(folder_path))\n",
        "    volume = []\n",
        "\n",
        "    for fname in slice_files:\n",
        "        if fname.endswith(('.jpg', '.png')):\n",
        "            img_path = os.path.join(folder_path, fname)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, size)\n",
        "            img = img.astype('float32') / 255.0\n",
        "            volume.append(img)\n",
        "\n",
        "    volume = np.array(volume)\n",
        "\n",
        "    # Pad or crop to exactly 128 slices\n",
        "    if volume.shape[0] < 128:\n",
        "        pad_amt = 128 - volume.shape[0]\n",
        "        volume = np.pad(volume, ((0, pad_amt), (0, 0)), mode='constant')\n",
        "    elif volume.shape[0] > 128:\n",
        "        volume = volume[:128]\n",
        "\n",
        "    volume = np.expand_dims(volume, axis=-1)  # Shape: (128, 128, 1)\n",
        "    volume = np.transpose(volume, (1, 2, 0, 3))  # Final shape: (128, 128, 128, 1)\n",
        "    return volume\n",
        "\n",
        "# Step 2: Load your trained model\n",
        "model = load_model('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n",
        "\n",
        "# Step 3: Predict and interpret result\n",
        "def predict_mrs_and_classify(volume):\n",
        "    volume = np.expand_dims(volume, axis=0)  # Add batch dim: (1, 128, 128, 128, 1)\n",
        "    prediction = model.predict(volume)\n",
        "    mrs_score = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    result = \"Favorable\" if mrs_score <= 1 else \"Unfavorable\"\n",
        "    print(f\"Predicted mRS = {mrs_score} ➜ {result}\")\n",
        "    return mrs_score, result\n",
        "\n",
        "# Step 4: Use with your folder of new scan slices\n",
        "folder_path = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'  # Replace with your folder\n",
        "new_volume = load_ct_volume_from_folder(folder_path)\n",
        "mrs_score, result = predict_mrs_and_classify(new_volume)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_uI15tX6uLx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIr7c6nf75Bs",
        "outputId": "027374bb-b4dd-489b-9d01-e3b37a097ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter Patient Clinical Details for Model B Prediction:\n",
            "Enter Age: 58\n",
            "Enter BMI: 27.3\n",
            "Hypertension? (1: Yes, 0: No): 1\n",
            "Heart Disease? (1: Yes, 0: No): 1\n",
            "Enter Average Glucose Level: 228.96\n",
            "Gender? (1: Male, 0: Female): 1\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "Stroke History? (1: Yes, 0: No): 1\n",
            "\n",
            "Predicted Model B mRS Value: 3\n",
            "\n",
            "Outcome Interpretation: Unfavourable (3–6)\n",
            "\n",
            "Re-enter for Final Stroke Check:\n",
            "Enter Predicted Model B mRS Value: 3\n",
            "Enter Age : 58\n",
            "Enter BMI : 27.3\n",
            "Hypertension? (1: Yes, 0: No): 1\n",
            "\n",
            "Final Prediction for Patient (After Re-Check):\n",
            "Predicted Final mRS Value: 3\n",
            "Outcome Interpretation: 3 - Unfavourable (3–6)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ✅ Step 1: Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "\n",
        "# ✅ Step 1.5: Encode categorical variables\n",
        "data['gender'] = data['gender'].map({'Male': 1, 'Female': 0})\n",
        "data['smoking_status'] = data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# ✅ Step 2: Define Model B features\n",
        "model_b_features = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_modelb = data[model_b_features]\n",
        "y_modelb = data['mrs']\n",
        "\n",
        "# ✅ Step 3: Train Model B\n",
        "model_b = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_b.fit(X_modelb, y_modelb)\n",
        "\n",
        "# ✅ Step 4: Take Clinical Input from User\n",
        "print(\"\\nEnter Patient Clinical Details for Model B Prediction:\")\n",
        "age = float(input(\"Enter Age: \"))\n",
        "bmi = float(input(\"Enter BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Enter Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "stroke_history = int(input(\"Stroke History? (1: Yes, 0: No): \"))  # Optional for now\n",
        "\n",
        "# ✅ Step 5: Prepare input for Model B\n",
        "patient_input_modelb = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# ✅ Step 6: Predict Model B mRS\n",
        "modelb_mrs_predicted = model_b.predict(patient_input_modelb)[0]\n",
        "print(f\"\\nPredicted Model B mRS Value: {modelb_mrs_predicted}\")\n",
        "\n",
        "# ✅ Step 7: Decision based on Model B result\n",
        "if modelb_mrs_predicted <= 2:\n",
        "    print(\"\\nOutcome Interpretation: Favourable (0–2)\")\n",
        "else:\n",
        "    print(\"\\nOutcome Interpretation: Unfavourable (3–6)\")\n",
        "\n",
        "    # ✅ Step 8: Ask user to re-enter\n",
        "    print(\"\\nRe-enter for Final Stroke Check:\")\n",
        "    entered_modelb_mrs = int(input(\"Enter Predicted Model B mRS Value: \"))\n",
        "    entered_age = float(input(\"Enter Age : \"))\n",
        "    entered_bmi = float(input(\"Enter BMI : \"))\n",
        "    entered_hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "\n",
        "    # ✅ Step 9: Prepare Final Input\n",
        "    final_patient_input = pd.DataFrame([{\n",
        "        'ModelB_mRS': entered_modelb_mrs,\n",
        "        'age': entered_age,\n",
        "        'bmi': entered_bmi,\n",
        "        'hypertension': entered_hypertension\n",
        "    }])\n",
        "\n",
        "    # ✅ Step 10: Train Final Model using Model B's predictions\n",
        "    data['ModelB_mRS'] = model_b.predict(X_modelb)\n",
        "    final_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_final = data[final_features]\n",
        "    y_final = data['mrs']\n",
        "\n",
        "    final_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    final_model.fit(X_final, y_final)\n",
        "\n",
        "    # ✅ Step 11: Predict Final mRS\n",
        "    predicted_final_mrs = final_model.predict(final_patient_input)[0]\n",
        "\n",
        "    # ✅ Step 12: Interpret final result\n",
        "    def interpret_mrs(mrs_value):\n",
        "        return f\"{mrs_value} - {'Favourable (0–2)' if mrs_value <= 2 else 'Unfavourable (3–6)'}\"\n",
        "\n",
        "    # ✅ Step 13: Display final result\n",
        "    print(\"\\nFinal Prediction for Patient (After Re-Check):\")\n",
        "    print(f\"Predicted Final mRS Value: {predicted_final_mrs}\")\n",
        "    print(f\"Outcome Interpretation: {interpret_mrs(predicted_final_mrs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-nWWJgo9jgD",
        "outputId": "eb461f48-6c93-4414-eba5-ad5ff2957d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter Clinical Details for Model B:\n",
            "Age: 54\n",
            "BMI: 27.3\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 104.51\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 1\n",
            "[Model B] Predicted mRS: 2 ➜ Favourable\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "[Model A] Predicted mRS: 1 ➜ Favourable\n",
            "\n",
            "[Final Decision] mRS = 2 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ================================\n",
        "# Part 1: Load and Predict using Model A (3D DenseNet)\n",
        "# ================================\n",
        "def load_ct_volume_from_folder(folder_path, size=(128, 128)):\n",
        "    slice_files = sorted(os.listdir(folder_path))\n",
        "    volume = []\n",
        "\n",
        "    for fname in slice_files:\n",
        "        if fname.endswith(('.jpg', '.png')):\n",
        "            img_path = os.path.join(folder_path, fname)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, size)\n",
        "            img = img.astype('float32') / 255.0\n",
        "            volume.append(img)\n",
        "\n",
        "    volume = np.array(volume)\n",
        "\n",
        "    # Pad or crop to exactly 128 slices\n",
        "    if volume.shape[0] < 128:\n",
        "        pad_amt = 128 - volume.shape[0]\n",
        "        volume = np.pad(volume, ((0, pad_amt), (0, 0)), mode='constant')\n",
        "    elif volume.shape[0] > 128:\n",
        "        volume = volume[:128]\n",
        "\n",
        "    volume = np.expand_dims(volume, axis=-1)\n",
        "    volume = np.transpose(volume, (1, 2, 0, 3))  # Shape: (128, 128, 128, 1)\n",
        "    return volume\n",
        "\n",
        "# Load Model A (3D DenseNet)\n",
        "modelA = load_model('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n",
        "\n",
        "def predict_modelA_mrs(volume):\n",
        "    volume = np.expand_dims(volume, axis=0)  # Shape: (1, 128, 128, 128, 1)\n",
        "    prediction = modelA.predict(volume)\n",
        "    mrs_score = np.argmax(prediction, axis=1)[0]\n",
        "    print(f\"[Model A] Predicted mRS: {mrs_score} ➜ {'Favourable' if mrs_score <= 2 else 'Unfavourable'}\")\n",
        "    return mrs_score\n",
        "\n",
        "# ================================\n",
        "# Part 2: Predict using Model B (Clinical Data)\n",
        "# ================================\n",
        "# Load dataset for training Model B and Final Fusion Model\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# Take clinical input from user\n",
        "print(\"\\nEnter Clinical Details for Model B:\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age, 'bmi': bmi, 'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease, 'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender, 'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"[Model B] Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# ================================\n",
        "# Part 3: Combine Model A + B + Final Check\n",
        "# ================================\n",
        "\n",
        "# Load new CT scan\n",
        "folder_path = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'  # Update as needed\n",
        "new_volume = load_ct_volume_from_folder(folder_path)\n",
        "modelA_mrs = predict_modelA_mrs(new_volume)\n",
        "\n",
        "# Fusion Decision Logic\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n[Conflict Detected] Model A is Unfavourable but Model B is Favourable.\")\n",
        "    print(\"Rechecking based on Age, BMI, and Hypertension...\")\n",
        "\n",
        "    # Prepare fusion model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Input for fusion\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n[Final Decision after Recheck] mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "else:\n",
        "    # If no conflict or both agree\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n[Final Decision] mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "VCoGLR5qPibM",
        "outputId": "e8100649-d281-42cc-9601-1757fe23e111"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fcc75898-67d2-47e7-907d-3035624acf0d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fcc75898-67d2-47e7-907d-3035624acf0d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load and preprocess a single CT scan slice and create a 3D volume\n",
        "def load_single_ct_image(image_path, size=(128, 128), depth=128):\n",
        "    # Load the single slice image\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, size)\n",
        "    img = img.astype('float32') / 255.0\n",
        "\n",
        "    # Expand dimensions to add the channel dimension (128, 128, 1)\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "    # Repeat the image along the depth axis to create a 3D volume\n",
        "    # This assumes the single image is repeated to form a depth of 128 (could be adjusted based on your needs)\n",
        "    volume = np.repeat(img, depth, axis=-1)  # Shape will be (128, 128, 128, 1)\n",
        "\n",
        "    # Add batch dimension for model input (1, 128, 128, 128, 1)\n",
        "    volume = np.expand_dims(volume, axis=0)\n",
        "\n",
        "    return volume\n",
        "\n",
        "# Step 2: Load the trained 3D DenseNet model\n",
        "model = load_model('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n",
        "\n",
        "# Step 3: Predict mRS scale value\n",
        "def predict_mrs_and_classify(image_path):\n",
        "    image = load_single_ct_image(image_path)\n",
        "\n",
        "    # Prediction from 3D DenseNet model\n",
        "    prediction = model.predict(image)\n",
        "    mrs_score = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Determine the result based on the mRS score\n",
        "    if mrs_score <= 1:\n",
        "        result = \"Favorable\"\n",
        "    else:\n",
        "        result = \"Unfavorable\"\n",
        "\n",
        "    print(f\"Predicted mRS = {mrs_score} ➜ {result}\")\n",
        "    return mrs_score, result\n",
        "\n",
        "# Step 4: Upload and predict mRS\n",
        "def upload_and_predict():\n",
        "    # Upload file using Google Colab interface\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get the file name (assume single image uploaded)\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Uploaded file: {filename}\")\n",
        "\n",
        "        # Run the prediction on the uploaded file\n",
        "        mrs_score, result = predict_mrs_and_classify(filename)\n",
        "        print(f\"Final mRS Prediction: {mrs_score} ➜ {result}\")\n",
        "\n",
        "# Step 5: Call the upload and predict function\n",
        "upload_and_predict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTOHr_JJETE8",
        "outputId": "1ab4f7f3-76f9-4a05-9001-1b10d361364b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter Patient Clinical Details for Model B Prediction:\n",
            "Enter Age: 20\n",
            "Enter BMI: 40\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Enter Average Glucose Level: 120\n",
            "Gender? (1: Male, 0: Female): 1\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "Stroke History? (1: Yes, 0: No): 0\n",
            "\n",
            "Predicted Model B mRS Value: 1\n",
            "\n",
            "Outcome Interpretation: Favourable (0–2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ✅ Step 1: Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "\n",
        "# ✅ Step 1.5: Encode categorical variables\n",
        "data['gender'] = data['gender'].map({'Male': 1, 'Female': 0})\n",
        "data['smoking_status'] = data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# ✅ Step 2: Define Model B features\n",
        "model_b_features = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_modelb = data[model_b_features]\n",
        "y_modelb = data['mrs']\n",
        "\n",
        "# ✅ Step 3: Train Model B\n",
        "model_b = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_b.fit(X_modelb, y_modelb)\n",
        "\n",
        "# ✅ Step 4: Take Clinical Input from User\n",
        "print(\"\\nEnter Patient Clinical Details for Model B Prediction:\")\n",
        "age = float(input(\"Enter Age: \"))\n",
        "bmi = float(input(\"Enter BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Enter Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "stroke_history = int(input(\"Stroke History? (1: Yes, 0: No): \"))  # Optional for now\n",
        "\n",
        "# ✅ Step 5: Prepare input for Model B\n",
        "patient_input_modelb = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# ✅ Step 6: Predict Model B mRS\n",
        "modelb_mrs_predicted = model_b.predict(patient_input_modelb)[0]\n",
        "print(f\"\\nPredicted Model B mRS Value: {modelb_mrs_predicted}\")\n",
        "\n",
        "# ✅ Step 7: Decision based on Model B result\n",
        "if modelb_mrs_predicted <= 2:\n",
        "    print(\"\\nOutcome Interpretation: Favourable (0–2)\")\n",
        "else:\n",
        "    print(\"\\nOutcome Interpretation: Unfavourable (3–6)\")\n",
        "\n",
        "    # ✅ Step 8: Ask user to re-enter\n",
        "    print(\"\\nRe-enter for Final Stroke Check:\")\n",
        "    entered_modelb_mrs = int(input(\"Enter Predicted Model B mRS Value: \"))\n",
        "    entered_age = float(input(\"Enter Age : \"))\n",
        "    entered_bmi = float(input(\"Enter BMI : \"))\n",
        "    entered_hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "\n",
        "    # ✅ Step 9: Prepare Final Input\n",
        "    final_patient_input = pd.DataFrame([{\n",
        "        'ModelB_mRS': entered_modelb_mrs,\n",
        "        'age': entered_age,\n",
        "        'bmi': entered_bmi,\n",
        "        'hypertension': entered_hypertension\n",
        "    }])\n",
        "\n",
        "    # ✅ Step 10: Train Final Model using Model B's predictions\n",
        "    data['ModelB_mRS'] = model_b.predict(X_modelb)\n",
        "    final_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_final = data[final_features]\n",
        "    y_final = data['mrs']\n",
        "\n",
        "    final_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    final_model.fit(X_final, y_final)\n",
        "\n",
        "    # ✅ Step 11: Predict Final mRS\n",
        "    predicted_final_mrs = final_model.predict(final_patient_input)[0]\n",
        "\n",
        "    # ✅ Step 12: Interpret final result\n",
        "\n",
        "    def interpret_mrs(mrs_value):\n",
        "        return f\"{mrs_value} - {'Favourable (0–2)' if mrs_value <= 2 else 'Unfavourable (3–6)'}\"\n",
        "\n",
        "    # ✅ Step 13: Display final result\n",
        "    print(\"\\nFinal Prediction for Patient (After Re-Check):\")\n",
        "    print(f\"Predicted Final mRS Value: {predicted_final_mrs}\")\n",
        "    print(f\"Outcome Interpretation: {interpret_mrs(predicted_final_mrs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRswn_YcD511"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2L1rgbtGrIS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class BrainImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.labels[idx]\n",
        "\n",
        "def get_balanced_dataset(normal_dir, stroke_dir):\n",
        "    normal_paths = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith('.jpg')]\n",
        "    stroke_paths = [os.path.join(stroke_dir, f) for f in os.listdir(stroke_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    # Balance by undersampling normal\n",
        "    random.seed(42)\n",
        "    normal_paths = random.sample(normal_paths, len(stroke_paths))\n",
        "\n",
        "    image_paths = normal_paths + stroke_paths\n",
        "    labels = [0]*len(normal_paths) + [1]*len(stroke_paths)\n",
        "\n",
        "    # Shuffle\n",
        "    combined = list(zip(image_paths, labels))\n",
        "    random.shuffle(combined)\n",
        "    image_paths, labels = zip(*combined)\n",
        "\n",
        "    return list(image_paths), list(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeCUJGQmHVOj",
        "outputId": "4810f70f-fd82-4582-f2a3-e582f0cb8d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "tGM-_T-bHeeI",
        "outputId": "ea4a28fc-cc8c-4f6a-c0b8-12195a844f9a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_balanced_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-59841d6ac378>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_balanced_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_balanced_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "image_paths, labels = get_balanced_dataset('/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal', '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "train_dataset = BrainImageDataset(train_paths, train_labels, transform=transform)\n",
        "test_dataset = BrainImageDataset(test_paths, test_labels, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dERo2_2bHpBD",
        "outputId": "96249466-9bca-4908-a952-f7a4f5f52876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n",
            "100%|██████████| 54.7M/54.7M [00:01<00:00, 54.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "model = models.densenet169(pretrained=True)\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(model.classifier.in_features, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf8tMtT9Hueb",
        "outputId": "10b41c09-2d46-470e-e1f5-e3ecf0affa19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 12.1310\n",
            "Epoch 2, Loss: 2.9319\n",
            "Epoch 3, Loss: 1.6813\n",
            "Epoch 4, Loss: 2.3398\n",
            "Epoch 5, Loss: 0.8486\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch in range(5):  # adjust epochs\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8Pa2bIukNxxE",
        "outputId": "032b2981-d823-4745-9369-eb7d16388176"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_loader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1f5a0cf7575e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = (outputs > 0.5).int().cpu().numpy().flatten()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=['Normal (0-2)', 'Stroke (3-6)']))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFfPlYSWOHnY"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'modelA_densenet169.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dojo6x7aOLhJ",
        "outputId": "b1256008-1bac-4e37-f07e-25e00823ce8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer25): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer26): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer27): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer28): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer29): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer30): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer31): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer32): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer25): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer26): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer27): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer28): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer29): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer30): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer31): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer32): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1664, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('modelA_densenet169.pth'))\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxnZ-CIAOPMK"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob > threshold:\n",
        "        return f\"Unfavourable Outcome (mRS 3–6) [Probability: {prob:.2f}]\"\n",
        "    else:\n",
        "        return f\"Favourable Outcome (mRS 0–2) [Probability: {1 - prob:.2f}]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rKSpF6Bw6RIm",
        "outputId": "88146c56-d6d5-4fb9-bbb4-955d6f1516b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b119ee61-d98d-45e5-8af1-31ff13fce514\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b119ee61-d98d-45e5-8af1-31ff13fce514\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 66 (7).jpg to 66 (7).jpg\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This opens a file upload window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QacvQOyH8ItB"
      },
      "outputs": [],
      "source": [
        "def predict_outcome(image_path, model, transform, threshold=0.6):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    print(f\"🧠 Stroke (Unfavourable) Probability: {prob:.4f}\")\n",
        "\n",
        "    if prob > threshold:\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6)\"\n",
        "    else:\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStbSzX38S2q",
        "outputId": "677b7b21-5429-41e1-a331-c0b28140afd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧠 Stroke (Unfavourable) Probability: 0.5393\n",
            "🟩 Favourable Outcome (mRS 0–2)\n"
          ]
        }
      ],
      "source": [
        "# Get uploaded image name\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Run prediction\n",
        "result = predict_outcome(image_path, model, transform)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpsQX0hM8NWH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "3vnesxdg94c3",
        "outputId": "bbb40842-bef8-4bd1-9fa8-af0082f360d1"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-bfc1f7aed5f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Get balanced dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_balanced_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstroke_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Split dataset into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-bfc1f7aed5f4>\u001b[0m in \u001b[0;36mget_balanced_dataset\u001b[0;34m(normal_dir, stroke_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Get image paths for normal and stroke images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_balanced_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstroke_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mnormal_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mstroke_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstroke_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Custom dataset class\n",
        "class BrainImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Get image paths for normal and stroke images\n",
        "def get_balanced_dataset(normal_dir, stroke_dir):\n",
        "    normal_paths = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith('.jpg')]\n",
        "    stroke_paths = [os.path.join(stroke_dir, f) for f in os.listdir(stroke_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    # Balance the dataset by downsampling the larger class\n",
        "    min_len = min(len(normal_paths), len(stroke_paths))\n",
        "    normal_paths = normal_paths[:min_len]\n",
        "    stroke_paths = stroke_paths[:min_len]\n",
        "\n",
        "    image_paths = normal_paths + stroke_paths\n",
        "    labels = [0] * len(normal_paths) + [1] * len(stroke_paths)\n",
        "\n",
        "    return image_paths, labels\n",
        "\n",
        "# Transformations to resize and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pre-trained model standardization\n",
        "])\n",
        "\n",
        "# Define paths to your normal and stroke directories\n",
        "normal_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'\n",
        "stroke_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'\n",
        "\n",
        "# Get balanced dataset\n",
        "image_paths, labels = get_balanced_dataset(normal_dir, stroke_dir)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = BrainImageDataset(train_paths, train_labels, transform=transform)\n",
        "test_dataset = BrainImageDataset(test_paths, test_labels, transform=transform)\n",
        "\n",
        "# Create DataLoader objects for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsv9mWfDAcHR",
        "outputId": "91f29f39-97a3-4373-ac04-37cdf5f41f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C_QYrMNAkn7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Custom dataset class\n",
        "class BrainImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Get image paths for normal and stroke images\n",
        "def get_balanced_dataset(normal_dir, stroke_dir):\n",
        "    normal_paths = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith('.jpg')]\n",
        "    stroke_paths = [os.path.join(stroke_dir, f) for f in os.listdir(stroke_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    # Balance the dataset by downsampling the larger class\n",
        "    min_len = min(len(normal_paths), len(stroke_paths))\n",
        "    normal_paths = normal_paths[:min_len]\n",
        "    stroke_paths = stroke_paths[:min_len]\n",
        "\n",
        "    image_paths = normal_paths + stroke_paths\n",
        "    labels = [0] * len(normal_paths) + [1] * len(stroke_paths)\n",
        "\n",
        "    return image_paths, labels\n",
        "\n",
        "# Transformations to resize and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pre-trained model standardization\n",
        "])\n",
        "\n",
        "# Define paths to your normal and stroke directories\n",
        "normal_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'\n",
        "stroke_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'\n",
        "\n",
        "# Get balanced dataset\n",
        "image_paths, labels = get_balanced_dataset(normal_dir, stroke_dir)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = BrainImageDataset(train_paths, train_labels, transform=transform)\n",
        "test_dataset = BrainImageDataset(test_paths, test_labels, transform=transform)\n",
        "\n",
        "# Create DataLoader objects for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NqXhhXaA61p",
        "outputId": "d96f993a-f9ce-4d84-890d-89b3acbce20d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.5106, Accuracy: 73.85%\n",
            "Epoch [2/10], Loss: 0.2548, Accuracy: 90.60%\n",
            "Epoch [3/10], Loss: 0.1466, Accuracy: 95.64%\n",
            "Epoch [4/10], Loss: 0.0970, Accuracy: 96.56%\n",
            "Epoch [5/10], Loss: 0.0455, Accuracy: 98.39%\n",
            "Epoch [6/10], Loss: 0.1828, Accuracy: 93.12%\n",
            "Epoch [7/10], Loss: 0.0453, Accuracy: 98.39%\n",
            "Epoch [8/10], Loss: 0.0175, Accuracy: 99.77%\n",
            "Epoch [9/10], Loss: 0.0112, Accuracy: 99.77%\n",
            "Epoch [10/10], Loss: 0.0139, Accuracy: 99.77%\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load DenseNet-169 pre-trained weights and modify the classifier for binary classification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(pretrained=True)  # Load pre-trained weights\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), labels.float())\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            predicted = (outputs.squeeze() > 0.5).float()\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = correct_predictions / total_predictions * 100\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogQoFBNwNN54"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'modelA_densenet169.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGfk0OXqNs0U",
        "outputId": "1e2aedbf-acb3-425e-b65b-a500fc272c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 97.27%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        outputs = model(images)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jrZLEwXbmRA",
        "outputId": "1a09061a-a788-43d7-f8fa-720b5181517f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O9UyuTPN9Fq",
        "outputId": "fabceb05-091d-4c80-e1c5-955a740e93b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd20b131-5add-477d-ad68-3b92a5702b1f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd20b131-5add-477d-ad68-3b92a5702b1f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Prediction function\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob > threshold:\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) [Probability: {prob:.2f}]\"\n",
        "    else:\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) [Probability: {1 - prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run prediction\n",
        "result = predict_outcome(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQslK3HiOhzD",
        "outputId": "a22af711-24fb-4fd1-96ba-a4936dd5c67e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter Clinical Details for Model B:\n",
            "Age: 21\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 130\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "[Model B] Predicted mRS: 1 ➜ Favourable\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "[Model A] Predicted mRS: 1 ➜ Favourable\n",
            "\n",
            "[Final Decision] mRS = 1 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ================================\n",
        "# Part 1: Load and Predict using Model A (3D DenseNet)\n",
        "# ================================\n",
        "def load_ct_volume_from_folder(folder_path, size=(128, 128)):\n",
        "    slice_files = sorted(os.listdir(folder_path))\n",
        "    volume = []\n",
        "\n",
        "    for fname in slice_files:\n",
        "        if fname.endswith(('.jpg', '.png')):\n",
        "            img_path = os.path.join(folder_path, fname)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, size)\n",
        "            img = img.astype('float32') / 255.0\n",
        "            volume.append(img)\n",
        "\n",
        "    volume = np.array(volume)\n",
        "\n",
        "    # Pad or crop to exactly 128 slices\n",
        "    if volume.shape[0] < 128:\n",
        "        pad_amt = 128 - volume.shape[0]\n",
        "        volume = np.pad(volume, ((0, pad_amt), (0, 0)), mode='constant')\n",
        "    elif volume.shape[0] > 128:\n",
        "        volume = volume[:128]\n",
        "\n",
        "    volume = np.expand_dims(volume, axis=-1)\n",
        "    volume = np.transpose(volume, (1, 2, 0, 3))  # Shape: (128, 128, 128, 1)\n",
        "    return volume\n",
        "\n",
        "# Load Model A (3D DenseNet)\n",
        "modelA = load_model('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n",
        "\n",
        "def predict_modelA_mrs(volume):\n",
        "    volume = np.expand_dims(volume, axis=0)  # Shape: (1, 128, 128, 128, 1)\n",
        "    prediction = modelA.predict(volume)\n",
        "    mrs_score = np.argmax(prediction, axis=1)[0]\n",
        "    print(f\"[Model A] Predicted mRS: {mrs_score} ➜ {'Favourable' if mrs_score <= 2 else 'Unfavourable'}\")\n",
        "    return mrs_score\n",
        "\n",
        "# ================================\n",
        "# Part 2: Predict using Model B (Clinical Data)\n",
        "# ================================\n",
        "# Load dataset for training Model B and Final Fusion Model\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# Take clinical input from user\n",
        "print(\"\\nEnter Clinical Details for Model B:\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age, 'bmi': bmi, 'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease, 'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender, 'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"[Model B] Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# ================================\n",
        "# Part 3: Combine Model A + B + Final Check\n",
        "# ================================\n",
        "\n",
        "# Load new CT scan\n",
        "folder_path = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'  # Update as needed\n",
        "new_volume = load_ct_volume_from_folder(folder_path)\n",
        "modelA_mrs = predict_modelA_mrs(new_volume)\n",
        "\n",
        "# Fusion Decision Logic\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n[Conflict Detected] Model A is Unfavourable but Model B is Favourable.\")\n",
        "    print(\"Rechecking based on Age, BMI, and Hypertension...\")\n",
        "\n",
        "    # Prepare fusion model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Input for fusion\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n[Final Decision after Recheck] mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "else:\n",
        "    # If no conflict or both agree\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n[Final Decision] mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "i1ajjbSuQ4ZI",
        "outputId": "9fe6a400-512a-4cf6-e3c1-633e731a09f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔢 Enter Clinical Details for Prediction:\n",
            "[Model B] Predicted mRS: 0 ➜ Favourable\n",
            "\n",
            "📁 Enter folder path for CT scan slices: /content/drive/MyDrive/final_project/Brain_Data_Organised\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (1,2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-280a2e26d71a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# ----------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n📁 Enter folder path for CT scan slices: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ct_volume_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mmodelA_mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_modelA_mrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-280a2e26d71a>\u001b[0m in \u001b[0;36mload_ct_volume_from_folder\u001b[0;34m(folder_path, size)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Ensure 128 slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_arraypad_impl.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_arraypad_impl.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;31m# Converting the array with `tolist` seems to improve performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;31m# when iterating and indexing the result (see usage in `pad`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_stride_tricks_impl.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    420\u001b[0m            [1, 2, 3]])\n\u001b[1;32m    421\u001b[0m     \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_stride_tricks_impl.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    356\u001b[0m                          'negative')\n\u001b[1;32m    357\u001b[0m     \u001b[0mextras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     it = np.nditer(\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'refs_ok'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zerosize_ok'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         op_flags=['readonly'], itershape=shape, order='C')\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (1,2)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ----------------------\n",
        "# Load CT Volume (Model A)\n",
        "# ----------------------\n",
        "def load_ct_volume_from_folder(folder_path, size=(128, 128)):\n",
        "    slice_files = sorted(os.listdir(folder_path))\n",
        "    volume = []\n",
        "\n",
        "    for fname in slice_files:\n",
        "        if fname.endswith(('.jpg', '.png')):\n",
        "            img = cv2.imread(os.path.join(folder_path, fname), cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, size)\n",
        "            img = img.astype('float32') / 255.0\n",
        "            volume.append(img)\n",
        "\n",
        "    volume = np.array(volume)\n",
        "    volume = np.pad(volume, ((0, max(0, 128 - volume.shape[0])), (0, 0)), mode='constant')\n",
        "    volume = volume[:128]  # Ensure 128 slices\n",
        "    volume = np.expand_dims(volume, axis=-1)\n",
        "    volume = np.transpose(volume, (1, 2, 0, 3))  # Shape: (128, 128, 128, 1)\n",
        "    return volume\n",
        "\n",
        "# ----------------------\n",
        "# Load Model A (3D DenseNet)\n",
        "# ----------------------\n",
        "modelA = load_model('/content/drive/MyDrive/final_project/modelA_3d_densenet_mrs.h5')\n",
        "\n",
        "def predict_modelA_mrs(volume):\n",
        "    volume = np.expand_dims(volume, axis=0)  # (1, 128, 128, 128, 1)\n",
        "    prediction = modelA.predict(volume)\n",
        "    mrs_score = np.argmax(prediction, axis=1)[0]\n",
        "    print(f\"[Model A] Predicted mRS: {mrs_score} ➜ {'Favourable' if mrs_score <= 2 else 'Unfavourable'}\")\n",
        "    return mrs_score\n",
        "\n",
        "# ----------------------\n",
        "# Load and Train Model B (Clinical Features)\n",
        "# ----------------------\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# ----------------------\n",
        "# Get User Input for Model B\n",
        "# ----------------------\n",
        "print(\"\\n🔢 Enter Clinical Details for Prediction:\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age, 'bmi': bmi, 'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease, 'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender, 'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"[Model B] Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# ----------------------\n",
        "# Load New CT Scan and Predict with Model A\n",
        "# ----------------------\n",
        "folder_path = input(\"\\n📁 Enter folder path for CT scan slices: \").strip()\n",
        "volume = load_ct_volume_from_folder(folder_path)\n",
        "modelA_mrs = predict_modelA_mrs(volume)\n",
        "\n",
        "# ----------------------\n",
        "# Final Fusion Logic\n",
        "# ----------------------\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict: Model A says Unfavourable, Model B says Favourable. Running Fusion Check...\")\n",
        "\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"✅ [Fusion Decision] mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"✅ [Final Decision] mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "Tiuf_NHuTluJ",
        "outputId": "fa9cc01c-10db-4742-db87-40cd17262f49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a6b1cf7-bef5-4ef1-b613-ef4b55ea1d18\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a6b1cf7-bef5-4ef1-b613-ef4b55ea1d18\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 49 (1).jpg to 49 (1) (2).jpg\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'modelA_densenet169.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-337d98df3a7d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modelA_densenet169.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modelA_densenet169.pth'"
          ]
        }
      ],
      "source": [
        "# --- Model A: CT Scan-based mRS Prediction ---\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Upload a new CT scan image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load trained DenseNet model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
        "model.load_state_dict(torch.load(\"modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transform the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Prediction function\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    pred = 1 if prob > threshold else 0\n",
        "    print(f\"[Model A] Prediction: {'Unfavourable' if pred else 'Favourable'} (Probability: {prob:.2f})\")\n",
        "    return pred  # 1 = Unfavourable, 0 = Favourable\n",
        "\n",
        "# Run Model A prediction\n",
        "modelA_result = predict_outcome(image_path, model, transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQmE3KzGVbam",
        "outputId": "24e7fd02-1bc7-41eb-ef31-4582cd2e11e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 70\n",
            "BMI: 68\n",
            "Hypertension? (1: Yes, 0: No): 1\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 165\n",
            "Gender? (1: Male, 0: Female): 1\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 6 ➜ Unfavourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 0\n",
            "Model A Output ➜ mRS 0 ➜ Favourable\n",
            "\n",
            "✅ Final Decision ➜ mRS = 6 ➜ Unfavourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model (Model B mRS + Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXAjWQNU7jGm",
        "outputId": "3f97b8d8-be69-41ba-8a48-56994b4759bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "1cMLlv9dcRUG",
        "outputId": "dc2df34b-f5c1-472b-8686-8d8d0812af66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f1d3f70-a31e-4da0-aa68-7b2f245475e5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f1d3f70-a31e-4da0-aa68-7b2f245475e5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 58 (1).jpg to 58 (1).jpg\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'modelA_densenet169.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d58b486c23cb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modelA_densenet169.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modelA_densenet169.pth'"
          ]
        }
      ],
      "source": [
        "# --- Model A: CT Scan-based mRS Prediction ---\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Upload a new CT scan image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load trained DenseNet model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
        "model.load_state_dict(torch.load(\"modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transform the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Prediction function\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    # Calculate the mRS based on the probability\n",
        "    mrs_value = 6 if prob > threshold else 2  # Assuming 2 = Favourable, 6 = Unfavourable\n",
        "\n",
        "    # Print the outcome\n",
        "    pred = \"Unfavourable\" if prob > threshold else \"Favourable\"\n",
        "    print(f\"[Model A] Prediction: {pred} (mRS: {mrs_value}) with Probability: {prob:.2f}\")\n",
        "    return pred, mrs_value, prob\n",
        "\n",
        "# Run Model A prediction\n",
        "modelA_result, modelA_mrs, modelA_prob = predict_outcome(image_path, model, transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPlVnkP2cZ1U",
        "outputId": "5150fde6-fc84-45c8-9211-136caadb22c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 21\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 160\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 2 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 2\n",
            "Model A Output ➜ mRS 2 ➜ Favourable\n",
            "\n",
            "✅ Final Decision ➜ mRS = 2 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model (Model B mRS + Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzzQuXSMxwsl",
        "outputId": "f397fb64-7367-4ff3-d717-c9ae5e00a24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfI9SYBI1D7U",
        "outputId": "8c0ac9f3-831d-4e76-fe46-538992164449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isvot53h1ISP",
        "outputId": "708c4c29-d827-41b6-899c-a7fc7784de5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer25): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer26): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer27): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer28): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer29): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer30): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer31): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer32): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer25): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer26): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer27): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer28): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer29): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer30): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer31): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer32): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1664, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"/content/drive/MyDrive/final_project/modelA_densenet169.pth\"\n",
        "\n",
        "# Load model as usual\n",
        "model = models.densenet169(pretrained=False)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DWaaSY0D1Onc",
        "outputId": "7523c50e-0110-46af-ee24-51fadf321944"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4fa4f9ab-1cb4-46e6-a5d9-8850847052ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4fa4f9ab-1cb4-46e6-a5d9-8850847052ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 58 (1).jpg to 58 (1) (2).jpg\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "IOaVCzfI3k_R",
        "outputId": "0c112507-e839-4297-ba3d-d05350c1f249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Unfavorable (Stroke)\n",
            "Probability of Unfavorable: 0.64\n",
            "Predicted mRS Value: 4\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# Define transform (same as training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        prob = output.item()\n",
        "        mrs_value = int(round(prob * 6))  # Convert probability to mRS 0–6\n",
        "        label = \"Unfavorable (Stroke)\" if mrs_value >= 3 else \"Favorable (Normal)\"\n",
        "\n",
        "    print(f\"Prediction: {label}\")\n",
        "    print(f\"Probability of Unfavorable: {prob:.2f}\")\n",
        "    print(f\"Predicted mRS Value: {mrs_value}\")\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"{label} (Prob: {prob:.2f}, mRS: {mrs_value})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Run on uploaded image (replace with your file name)\n",
        "predict_image(\"58 (1).jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtLDCtnz3pM5",
        "outputId": "0a0384dc-2b1f-4efd-8261-08620fa71efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 21\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 135\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 1 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 4\n",
            "Model A Output ➜ mRS 4 ➜ Unfavourable\n",
            "\n",
            "⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\n",
            "🔁 Rechecking with Fusion Model (Model B mRS + Age + BMI + Hypertension)...\n",
            "\n",
            "✅ Final Decision after Recheck ➜ mRS = 1 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model (Model B mRS + Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "z49X-BXX9mxK",
        "outputId": "580d1972-017c-42f9-c80c-a964f8984632"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5cfc084f-c409-42ca-b478-44e0ff772876\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5cfc084f-c409-42ca-b478-44e0ff772876\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 51 (4).jpg to 51 (4).jpg\n",
            "Prediction Result: 🟥 Unfavourable Outcome (mRS 3–6) [Probability: 0.63]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]  # Get the image path\n",
        "\n",
        "# Step 2: Load the trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load DenseNet169 model and modify for binary classification (Favorable vs Unfavorable)\n",
        "model = models.densenet169(weights=None)  # Load model without pre-trained weights\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),  # 1 output for binary classification\n",
        "    nn.Sigmoid()  # Sigmoid activation for binary classification\n",
        ")\n",
        "\n",
        "# Load the trained model weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/final_project/modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Step 3: Define transformation for the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize image to 224x224\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Step 4: Prediction function\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')  # Open image and convert to RGB\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)  # Apply transform and add batch dimension\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        prob = model(img_tensor).item()  # Get the model's output probability\n",
        "\n",
        "    # Decision based on the probability\n",
        "    if prob > threshold:\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) [Probability: {prob:.2f}]\"\n",
        "    else:\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) [Probability: {1 - prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run the prediction\n",
        "result = predict_outcome(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acs7MUWH_NVk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEFSYRGt_Nwx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29w3dc03_N_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BwuR_YN_OFd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5MKYCUz-bys"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Custom dataset class\n",
        "class BrainImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Get image paths for normal and stroke images\n",
        "def get_balanced_dataset(normal_dir, stroke_dir):\n",
        "    normal_paths = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith('.jpg')]\n",
        "    stroke_paths = [os.path.join(stroke_dir, f) for f in os.listdir(stroke_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    # Balance the dataset by downsampling the larger class\n",
        "    min_len = min(len(normal_paths), len(stroke_paths))\n",
        "    normal_paths = normal_paths[:min_len]\n",
        "    stroke_paths = stroke_paths[:min_len]\n",
        "\n",
        "    image_paths = normal_paths + stroke_paths\n",
        "    labels = [0] * len(normal_paths) + [1] * len(stroke_paths)\n",
        "\n",
        "    return image_paths, labels\n",
        "\n",
        "# Transformations to resize and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pre-trained model standardization\n",
        "])\n",
        "\n",
        "# Define paths to your normal and stroke directories\n",
        "normal_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Normal'\n",
        "stroke_dir = '/content/drive/MyDrive/final_project/Brain_Data_Organised/Stroke'\n",
        "\n",
        "# Get balanced dataset\n",
        "image_paths, labels = get_balanced_dataset(normal_dir, stroke_dir)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = BrainImageDataset(train_paths, train_labels, transform=transform)\n",
        "test_dataset = BrainImageDataset(test_paths, test_labels, transform=transform)\n",
        "\n",
        "# Create DataLoader objects for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIacTIrw_Pj8",
        "outputId": "2f45a118-4d91-4ee7-e310-adc5a855abe6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.4607, Accuracy: 79.13%\n",
            "Epoch [2/10], Loss: 0.2676, Accuracy: 88.76%\n",
            "Epoch [3/10], Loss: 0.2148, Accuracy: 90.14%\n",
            "Epoch [4/10], Loss: 0.2205, Accuracy: 89.91%\n",
            "Epoch [5/10], Loss: 0.1636, Accuracy: 93.58%\n",
            "Epoch [6/10], Loss: 0.2274, Accuracy: 94.04%\n",
            "Epoch [7/10], Loss: 0.0868, Accuracy: 97.02%\n",
            "Epoch [8/10], Loss: 0.0623, Accuracy: 97.71%\n",
            "Epoch [9/10], Loss: 0.0206, Accuracy: 99.54%\n",
            "Epoch [10/10], Loss: 0.0471, Accuracy: 98.62%\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load DenseNet-169 pre-trained weights and modify the classifier for binary classification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(pretrained=True)  # Load pre-trained weights\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), labels.float())\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            predicted = (outputs.squeeze() > 0.5).float()\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = correct_predictions / total_predictions * 100\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJyzj7uhKUW1"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'modelA_densenet169.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "YpylZXbLKuFb",
        "outputId": "955ae612-bc49-45d0-f203-46113b27a460"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c3053712-41c6-4b4f-9d6a-01f06d7f66d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c3053712-41c6-4b4f-9d6a-01f06d7f66d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 58 (1).jpg to 58 (1) (4).jpg\n",
            "Prediction Result: 🟥 Unfavourable Outcome (mRS 3–6) [Probability: 1.00]\n"
          ]
        }
      ],
      "source": [
        " from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Prediction function\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob > threshold:\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) [Probability: {prob:.2f}]\"\n",
        "    else:\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) [Probability: {1 - prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run prediction\n",
        "result = predict_outcome(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rUcaWg2TBKT"
      },
      "outputs": [],
      "source": [
        "!cp modelA_densenet169.pth /content/drive/MyDrive/final_project/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeIAAJwDTMyq",
        "outputId": "aa420d88-af27-416e-cbf2-97aae432c518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 20\n",
            "BMI: 40\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 140\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 2 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 5\n",
            "Model A Output ➜ mRS 5 ➜ Unfavourable\n",
            "\n",
            "⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\n",
            "🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\n",
            "\n",
            "✅ Final Decision after Recheck ➜ mRS = 2 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swilIkFDP3E_",
        "outputId": "7e1e11bc-c13c-4ad0-9a85-12436b81d0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "o4PM0SEtQurk",
        "outputId": "2b2c1523-d783-4b38-f5f9-1fbaab5dab81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0706a823-6833-449d-aaea-f80dad503fc1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0706a823-6833-449d-aaea-f80dad503fc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 1.jpg to 1 (1).jpg\n",
            "Prediction Result: 🟩 Favourable Outcome (mRS 0–2) [Probability: 0.91]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/final_project/modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Prediction function\n",
        "def predict_outcome(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob > threshold:\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) [Probability: {prob:.2f}]\"\n",
        "    else:\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) [Probability: {1 - prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run prediction\n",
        "result = predict_outcome(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WIpXqfZRG1j",
        "outputId": "8109a9ae-d908-4c47-f433-28c7f01f76c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 20\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 135\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 1 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 2\n",
            "Model A Output ➜ mRS 2 ➜ Favourable\n",
            "\n",
            "✅ Final Decision ➜ mRS = 2 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0NMXP_NvS1d6",
        "outputId": "b562d8d5-8a2e-4c60-b60d-b5164a115033"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21fa3b6f-822d-4f8c-bd73-0ec57ae9cc37\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21fa3b6f-822d-4f8c-bd73-0ec57ae9cc37\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 49 (15).jpg to 49 (15).jpg\n",
            "Prediction Result: 🟥 Unfavourable Outcome (mRS 3–6) → Predicted mRS: 6 [Confidence: 1.00]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the trained binary model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/final_project/modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Predict outcome and approximate mRS\n",
        "def predict_outcome_with_mrs(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob < 0.5:\n",
        "        if prob < 0.2:\n",
        "            mrs = 0\n",
        "        elif prob < 0.35:\n",
        "            mrs = 1\n",
        "        else:\n",
        "            mrs = 2\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) → Predicted mRS: {mrs} [Confidence: {1 - prob:.2f}]\"\n",
        "    else:\n",
        "        if prob < 0.65:\n",
        "            mrs = 3\n",
        "        elif prob < 0.8:\n",
        "            mrs = 4\n",
        "        elif prob < 0.9:\n",
        "            mrs = 5\n",
        "        else:\n",
        "            mrs = 6\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) → Predicted mRS: {mrs} [Confidence: {prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run prediction\n",
        "result = predict_outcome_with_mrs(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cKc1LKeS9I2",
        "outputId": "53f845b1-7c79-425e-9a6d-ea894fd2b426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 21\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 145\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 2 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 0\n",
            "Model A Output ➜ mRS 0 ➜ Favourable\n",
            "\n",
            "✅ Final Decision ➜ mRS = 2 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_cX3_qHq9M2",
        "outputId": "561bde6e-a75a-4ff4-d7b6-7154c52c46a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "GmHaZYoDs9Eb",
        "outputId": "ad144d73-8fae-4dca-a96c-9a7869f5e43b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8002cc82-8319-4f90-8ad3-4ff5a84b2c9c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8002cc82-8319-4f90-8ad3-4ff5a84b2c9c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 58 (1).jpg to 58 (1).jpg\n",
            "Prediction Result: 🟥 Unfavourable Outcome (mRS 3–6) → Predicted mRS: 6 [Confidence: 1.00]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the trained binary model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/final_project/modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Predict outcome and approximate mRS\n",
        "def predict_outcome_with_mrs(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob < 0.5:\n",
        "        if prob < 0.2:\n",
        "            mrs = 0\n",
        "        elif prob < 0.35:\n",
        "            mrs = 1\n",
        "        else:\n",
        "            mrs = 2\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) → Predicted mRS: {mrs} [Confidence: {1 - prob:.2f}]\"\n",
        "    else:\n",
        "        if prob < 0.65:\n",
        "            mrs = 3\n",
        "        elif prob < 0.8:\n",
        "            mrs = 4\n",
        "        elif prob < 0.9:\n",
        "            mrs = 5\n",
        "        else:\n",
        "            mrs = 6\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) → Predicted mRS: {mrs} [Confidence: {prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run prediction\n",
        "result = predict_outcome_with_mrs(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWxiA1iNtNWT",
        "outputId": "19dad925-ec4e-4bd0-9d90-2dd41b32b973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 70\n",
            "BMI: 79\n",
            "Hypertension? (1: Yes, 0: No): 1\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 180\n",
            "Gender? (1: Male, 0: Female): 1\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 6 ➜ Unfavourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 6\n",
            "Model A Output ➜ mRS 6 ➜ Unfavourable\n",
            "\n",
            "✅ Final Decision ➜ mRS = 6 ➜ Unfavourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B53573_Zto1g",
        "outputId": "0944c324-3166-4034-bf32-88665e3cfa3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 21\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 136\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 1 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 6\n",
            "Model A Output ➜ mRS 6 ➜ Unfavourable\n",
            "\n",
            "⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\n",
            "🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\n",
            "\n",
            "✅ Final Decision after Recheck ➜ mRS = 1 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\n⚠️ Conflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"🔁 Rechecking with Fusion Model ( Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVykIt1awIct",
        "outputId": "8fd60347-5cda-4591-bfe0-bb23cf634e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EFVnTVi7s5NN",
        "outputId": "9a9ae89b-852c-4e86-8419-8ae9ea128e2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-641788b6-0813-4f68-8ce3-17eae1715924\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-641788b6-0813-4f68-8ce3-17eae1715924\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1.jpg to 1 (1).jpg\n",
            "Prediction Result: 🟩 Favourable Outcome (mRS 0–2) → Predicted mRS: 0 [Confidence: 0.91]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Step 1: Upload a new image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the trained binary model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet169(weights=None)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/final_project/modelA_densenet169.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Predict outcome and approximate mRS\n",
        "def predict_outcome_with_mrs(image_path, model, transform, threshold=0.5):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prob = model(img_tensor).item()\n",
        "\n",
        "    if prob < 0.5:\n",
        "        if prob < 0.2:\n",
        "            mrs = 0\n",
        "        elif prob < 0.35:\n",
        "            mrs = 1\n",
        "        else:\n",
        "            mrs = 2\n",
        "        return f\"🟩 Favourable Outcome (mRS 0–2) → Predicted mRS: {mrs} [Confidence: {1 - prob:.2f}]\"\n",
        "    else:\n",
        "        if prob < 0.65:\n",
        "            mrs = 3\n",
        "        elif prob < 0.8:\n",
        "            mrs = 4\n",
        "        elif prob < 0.9:\n",
        "            mrs = 5\n",
        "        else:\n",
        "            mrs = 6\n",
        "        return f\"🟥 Unfavourable Outcome (mRS 3–6) → Predicted mRS: {mrs} [Confidence: {prob:.2f}]\"\n",
        "\n",
        "# Step 5: Run prediction\n",
        "result = predict_outcome_with_mrs(image_path, model, transform)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUuz_NiVs6nY",
        "outputId": "e1a5950a-b58c-4ff7-d8b1-96c6b2f1f647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Enter Clinical Data for Prediction\n",
            "Age: 21\n",
            "BMI: 55\n",
            "Hypertension? (1: Yes, 0: No): 0\n",
            "Heart Disease? (1: Yes, 0: No): 0\n",
            "Average Glucose Level: 160\n",
            "Gender? (1: Male, 0: Female): 0\n",
            "Smoking Status? (1: Smoker, 0: Non-Smoker): 0\n",
            "\n",
            "📊 Model B Predicted mRS: 2 ➜ Favourable\n",
            "\n",
            "💡 Enter mRS from Model A (0 to 6): 0\n",
            "Model A Output ➜ mRS 0 ➜ Favourable\n",
            "\n",
            "✅ Final Decision ➜ mRS = 2 ➜ Favourable\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# === Load Clinical Data for Model B and Fusion Recheck ===\n",
        "clinical_data = pd.read_csv('/content/drive/MyDrive/final_project/clinical_data_with_mrs.csv')\n",
        "clinical_data['gender'] = clinical_data['gender'].map({'Male': 1, 'Female': 0})\n",
        "clinical_data['smoking_status'] = clinical_data['smoking_status'].map({'Smoker': 1, 'Non-Smoker': 0})\n",
        "\n",
        "# === Model B Features and Labels ===\n",
        "features_B = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender', 'smoking_status']\n",
        "X_B = clinical_data[features_B]\n",
        "y_B = clinical_data['mrs']\n",
        "\n",
        "# === Train Model B ===\n",
        "modelB = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelB.fit(X_B, y_B)\n",
        "\n",
        "# === Get User Clinical Input ===\n",
        "print(\"🔍 Enter Clinical Data for Prediction\")\n",
        "age = float(input(\"Age: \"))\n",
        "bmi = float(input(\"BMI: \"))\n",
        "hypertension = int(input(\"Hypertension? (1: Yes, 0: No): \"))\n",
        "heart_disease = int(input(\"Heart Disease? (1: Yes, 0: No): \"))\n",
        "avg_glucose_level = float(input(\"Average Glucose Level: \"))\n",
        "gender = int(input(\"Gender? (1: Male, 0: Female): \"))\n",
        "smoking_status = int(input(\"Smoking Status? (1: Smoker, 0: Non-Smoker): \"))\n",
        "\n",
        "input_B = pd.DataFrame([{\n",
        "    'age': age,\n",
        "    'bmi': bmi,\n",
        "    'hypertension': hypertension,\n",
        "    'heart_disease': heart_disease,\n",
        "    'avg_glucose_level': avg_glucose_level,\n",
        "    'gender': gender,\n",
        "    'smoking_status': smoking_status\n",
        "}])\n",
        "\n",
        "# === Predict with Model B ===\n",
        "modelB_mrs = modelB.predict(input_B)[0]\n",
        "print(f\"\\n📊 Model B Predicted mRS: {modelB_mrs} ➜ {'Favourable' if modelB_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Enter Model A Output Manually ===\n",
        "modelA_mrs = int(input(\"\\n💡 Enter mRS from Model A (0 to 6): \"))\n",
        "print(f\"Model A Output ➜ mRS {modelA_mrs} ➜ {'Favourable' if modelA_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "# === Recheck if Conflict Detected ===\n",
        "if modelA_mrs > 2 and modelB_mrs <= 2:\n",
        "    print(\"\\nConflict Detected: Model A = Unfavourable, Model B = Favourable\")\n",
        "    print(\"Rechecking with Fusion Model ( Age + BMI + Hypertension)...\")\n",
        "\n",
        "    # Prepare Fusion Model\n",
        "    clinical_data['ModelB_mRS'] = modelB.predict(X_B)\n",
        "    fusion_features = ['ModelB_mRS', 'age', 'bmi', 'hypertension']\n",
        "    X_fusion = clinical_data[fusion_features]\n",
        "    y_fusion = clinical_data['mrs']\n",
        "\n",
        "    fusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    fusion_model.fit(X_fusion, y_fusion)\n",
        "\n",
        "    # Prepare Fusion Input\n",
        "    input_fusion = pd.DataFrame([{\n",
        "        'ModelB_mRS': modelB_mrs,\n",
        "        'age': age,\n",
        "        'bmi': bmi,\n",
        "        'hypertension': hypertension\n",
        "    }])\n",
        "\n",
        "    final_mrs = fusion_model.predict(input_fusion)[0]\n",
        "    print(f\"\\n✅ Final Decision after Recheck ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n",
        "\n",
        "else:\n",
        "    # Use Model A or B directly if no conflict\n",
        "    final_mrs = modelA_mrs if modelA_mrs == modelB_mrs else max(modelA_mrs, modelB_mrs)\n",
        "    print(f\"\\n✅ Final Decision ➜ mRS = {final_mrs} ➜ {'Favourable' if final_mrs <= 2 else 'Unfavourable'}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}